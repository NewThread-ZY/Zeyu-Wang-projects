{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "78319767-47db-49d2-a38d-8d2f34183e15",
   "metadata": {},
   "source": [
    "## AIM-5007-1\n",
    "## By Zeyu Wang\n",
    "## Fall 2021\n",
    "## Mini Project"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 103,
   "id": "75aa6abe-a323-464f-ba54-0dfe6884941f",
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "import numpy as np"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "51b30475-b5b8-4977-9b1b-034a61e909e4",
   "metadata": {},
   "source": [
    "# 1. Load the data"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "30aeceab-7517-4e19-b9f9-198e8e477d45",
   "metadata": {},
   "source": [
    "This dataset comes from https://archive.ics.uci.edu/ml/datasets/seeds. There are 7 attributes and they are \n",
    "1. area A,\n",
    "2. perimeter P,\n",
    "3. compactness C = 4*pi*A/P^2,\n",
    "4. length of kernel,\n",
    "5. width of kernel,\n",
    "6. asymmetry coefficient\n",
    "7. length of kernel groove."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 186,
   "id": "613651b0-5146-4931-a27c-77e3dbfec9c0",
   "metadata": {},
   "outputs": [],
   "source": [
    "data = pd.read_csv('seeds_dataset.txt', header = None, delim_whitespace = 'Ture', dtype = 'float')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 187,
   "id": "21b7f96f-c3f0-415b-b827-626d948fc0cb",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>area</th>\n",
       "      <th>perimeter</th>\n",
       "      <th>compactness</th>\n",
       "      <th>length of kernel</th>\n",
       "      <th>width of kernel</th>\n",
       "      <th>asymmetry coefficient</th>\n",
       "      <th>length of kernel groove</th>\n",
       "      <th>Category</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>15.26</td>\n",
       "      <td>14.84</td>\n",
       "      <td>0.8710</td>\n",
       "      <td>5.763</td>\n",
       "      <td>3.312</td>\n",
       "      <td>2.221</td>\n",
       "      <td>5.220</td>\n",
       "      <td>1.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>14.88</td>\n",
       "      <td>14.57</td>\n",
       "      <td>0.8811</td>\n",
       "      <td>5.554</td>\n",
       "      <td>3.333</td>\n",
       "      <td>1.018</td>\n",
       "      <td>4.956</td>\n",
       "      <td>1.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>14.29</td>\n",
       "      <td>14.09</td>\n",
       "      <td>0.9050</td>\n",
       "      <td>5.291</td>\n",
       "      <td>3.337</td>\n",
       "      <td>2.699</td>\n",
       "      <td>4.825</td>\n",
       "      <td>1.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>13.84</td>\n",
       "      <td>13.94</td>\n",
       "      <td>0.8955</td>\n",
       "      <td>5.324</td>\n",
       "      <td>3.379</td>\n",
       "      <td>2.259</td>\n",
       "      <td>4.805</td>\n",
       "      <td>1.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>16.14</td>\n",
       "      <td>14.99</td>\n",
       "      <td>0.9034</td>\n",
       "      <td>5.658</td>\n",
       "      <td>3.562</td>\n",
       "      <td>1.355</td>\n",
       "      <td>5.175</td>\n",
       "      <td>1.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>...</th>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>205</th>\n",
       "      <td>12.19</td>\n",
       "      <td>13.20</td>\n",
       "      <td>0.8783</td>\n",
       "      <td>5.137</td>\n",
       "      <td>2.981</td>\n",
       "      <td>3.631</td>\n",
       "      <td>4.870</td>\n",
       "      <td>3.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>206</th>\n",
       "      <td>11.23</td>\n",
       "      <td>12.88</td>\n",
       "      <td>0.8511</td>\n",
       "      <td>5.140</td>\n",
       "      <td>2.795</td>\n",
       "      <td>4.325</td>\n",
       "      <td>5.003</td>\n",
       "      <td>3.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>207</th>\n",
       "      <td>13.20</td>\n",
       "      <td>13.66</td>\n",
       "      <td>0.8883</td>\n",
       "      <td>5.236</td>\n",
       "      <td>3.232</td>\n",
       "      <td>8.315</td>\n",
       "      <td>5.056</td>\n",
       "      <td>3.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>208</th>\n",
       "      <td>11.84</td>\n",
       "      <td>13.21</td>\n",
       "      <td>0.8521</td>\n",
       "      <td>5.175</td>\n",
       "      <td>2.836</td>\n",
       "      <td>3.598</td>\n",
       "      <td>5.044</td>\n",
       "      <td>3.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>209</th>\n",
       "      <td>12.30</td>\n",
       "      <td>13.34</td>\n",
       "      <td>0.8684</td>\n",
       "      <td>5.243</td>\n",
       "      <td>2.974</td>\n",
       "      <td>5.637</td>\n",
       "      <td>5.063</td>\n",
       "      <td>3.0</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>210 rows Ã— 8 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "      area  perimeter  compactness  length of kernel  width of kernel  \\\n",
       "0    15.26      14.84       0.8710             5.763            3.312   \n",
       "1    14.88      14.57       0.8811             5.554            3.333   \n",
       "2    14.29      14.09       0.9050             5.291            3.337   \n",
       "3    13.84      13.94       0.8955             5.324            3.379   \n",
       "4    16.14      14.99       0.9034             5.658            3.562   \n",
       "..     ...        ...          ...               ...              ...   \n",
       "205  12.19      13.20       0.8783             5.137            2.981   \n",
       "206  11.23      12.88       0.8511             5.140            2.795   \n",
       "207  13.20      13.66       0.8883             5.236            3.232   \n",
       "208  11.84      13.21       0.8521             5.175            2.836   \n",
       "209  12.30      13.34       0.8684             5.243            2.974   \n",
       "\n",
       "     asymmetry coefficient  length of kernel groove  Category  \n",
       "0                    2.221                    5.220       1.0  \n",
       "1                    1.018                    4.956       1.0  \n",
       "2                    2.699                    4.825       1.0  \n",
       "3                    2.259                    4.805       1.0  \n",
       "4                    1.355                    5.175       1.0  \n",
       "..                     ...                      ...       ...  \n",
       "205                  3.631                    4.870       3.0  \n",
       "206                  4.325                    5.003       3.0  \n",
       "207                  8.315                    5.056       3.0  \n",
       "208                  3.598                    5.044       3.0  \n",
       "209                  5.637                    5.063       3.0  \n",
       "\n",
       "[210 rows x 8 columns]"
      ]
     },
     "execution_count": 187,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "data.columns = ['area', 'perimeter', 'compactness', 'length of kernel', 'width of kernel', 'asymmetry coefficient', 'length of kernel groove', 'Category']\n",
    "data"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "92c0dcd5-cb4b-405f-b217-a37b3142c66a",
   "metadata": {},
   "source": [
    "# 2. Clean data\n",
    "In this part, we'll find out the nan and null data in the dataset and remove them."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 188,
   "id": "8d94f0fc-8909-4d7e-8524-baf161bda9d3",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "False"
      ]
     },
     "execution_count": 188,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "data.isna().values.any()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 189,
   "id": "500399cf-3983-425e-b2e8-47d0734c05eb",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "False"
      ]
     },
     "execution_count": 189,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "data.isnull().values.any()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 190,
   "id": "7a881360-596c-44b4-9879-08230c28d595",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "area                       0.0\n",
       "perimeter                  0.0\n",
       "compactness                0.0\n",
       "length of kernel           0.0\n",
       "width of kernel            0.0\n",
       "asymmetry coefficient      0.0\n",
       "length of kernel groove    0.0\n",
       "Category                   0.0\n",
       "dtype: float64"
      ]
     },
     "execution_count": 190,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "data[data==' '].sum()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "2119687a-328c-4f49-b6d8-69152a0b337b",
   "metadata": {},
   "source": [
    "In this dataset, there isn't any null and nan data."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "843e4ace-2eab-40b9-b674-8ff5baa0c991",
   "metadata": {},
   "source": [
    "# 3. Split into train and test dataset\n",
    "Here my idea is to use NumPy.random to pick up 150 data from the dataset and let them be trained data and then use np.setdiff1d to choose the rest of the data as the test data."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 191,
   "id": "8f65d299-b66d-41cf-a66e-e667e6c2120f",
   "metadata": {},
   "outputs": [],
   "source": [
    "#Because our network has three outputs, so we need to use one-hot encoding to encode the Category before splitting the data.\n",
    "one_hot = pd.get_dummies(data.Category)\n",
    "one_hot.columns = ['A', 'B', 'C']\n",
    "data = data.drop('Category', axis = 1)\n",
    "data = data.join(one_hot)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 192,
   "id": "f33afd30-2130-4ba1-9c40-6c2676250d5e",
   "metadata": {},
   "outputs": [],
   "source": [
    "np.random.seed(2021)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 193,
   "id": "892a0ed2-3c07-444b-b930-dc97cfbe4fd4",
   "metadata": {},
   "outputs": [],
   "source": [
    "list_index = np.array([i for i in range(len(data))])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 194,
   "id": "576c6b00-75e0-4e00-926e-fbed8fb12d40",
   "metadata": {},
   "outputs": [],
   "source": [
    "#I random choose 150 data from list_index and let them not replace\n",
    "train_index = np.random.choice(list_index, 150, replace = False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 195,
   "id": "c087835b-88d6-4b7d-85eb-2e77ea8add5b",
   "metadata": {},
   "outputs": [],
   "source": [
    "#The rest of data as test data\n",
    "test_index = np.setdiff1d(list_index, train_index)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "cce7bbb9-1fa3-4d1f-a82f-9f27afe438c7",
   "metadata": {},
   "source": [
    "Reset index of training and testing data in order to avoid the error later"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 196,
   "id": "20a5d59f-22dd-476d-a361-10e4ea070175",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>area</th>\n",
       "      <th>perimeter</th>\n",
       "      <th>compactness</th>\n",
       "      <th>length of kernel</th>\n",
       "      <th>width of kernel</th>\n",
       "      <th>asymmetry coefficient</th>\n",
       "      <th>length of kernel groove</th>\n",
       "      <th>A</th>\n",
       "      <th>B</th>\n",
       "      <th>C</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>14.49</td>\n",
       "      <td>14.61</td>\n",
       "      <td>0.8538</td>\n",
       "      <td>5.715</td>\n",
       "      <td>3.113</td>\n",
       "      <td>4.116</td>\n",
       "      <td>5.396</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>16.12</td>\n",
       "      <td>15.00</td>\n",
       "      <td>0.9000</td>\n",
       "      <td>5.709</td>\n",
       "      <td>3.485</td>\n",
       "      <td>2.270</td>\n",
       "      <td>5.443</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>18.30</td>\n",
       "      <td>15.89</td>\n",
       "      <td>0.9108</td>\n",
       "      <td>5.979</td>\n",
       "      <td>3.755</td>\n",
       "      <td>2.837</td>\n",
       "      <td>5.962</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>15.78</td>\n",
       "      <td>14.91</td>\n",
       "      <td>0.8923</td>\n",
       "      <td>5.674</td>\n",
       "      <td>3.434</td>\n",
       "      <td>5.593</td>\n",
       "      <td>5.136</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>12.30</td>\n",
       "      <td>13.34</td>\n",
       "      <td>0.8684</td>\n",
       "      <td>5.243</td>\n",
       "      <td>2.974</td>\n",
       "      <td>5.637</td>\n",
       "      <td>5.063</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "    area  perimeter  compactness  length of kernel  width of kernel  \\\n",
       "0  14.49      14.61       0.8538             5.715            3.113   \n",
       "1  16.12      15.00       0.9000             5.709            3.485   \n",
       "2  18.30      15.89       0.9108             5.979            3.755   \n",
       "3  15.78      14.91       0.8923             5.674            3.434   \n",
       "4  12.30      13.34       0.8684             5.243            2.974   \n",
       "\n",
       "   asymmetry coefficient  length of kernel groove  A  B  C  \n",
       "0                  4.116                    5.396  1  0  0  \n",
       "1                  2.270                    5.443  1  0  0  \n",
       "2                  2.837                    5.962  0  1  0  \n",
       "3                  5.593                    5.136  1  0  0  \n",
       "4                  5.637                    5.063  0  0  1  "
      ]
     },
     "execution_count": 196,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "train = data.loc[train_index]\n",
    "train = train.reset_index(drop = True)\n",
    "train.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 197,
   "id": "e933d2c6-e7bd-42e7-8529-f07f14f57e66",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>area</th>\n",
       "      <th>perimeter</th>\n",
       "      <th>compactness</th>\n",
       "      <th>length of kernel</th>\n",
       "      <th>width of kernel</th>\n",
       "      <th>asymmetry coefficient</th>\n",
       "      <th>length of kernel groove</th>\n",
       "      <th>A</th>\n",
       "      <th>B</th>\n",
       "      <th>C</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>14.88</td>\n",
       "      <td>14.57</td>\n",
       "      <td>0.8811</td>\n",
       "      <td>5.554</td>\n",
       "      <td>3.333</td>\n",
       "      <td>1.018</td>\n",
       "      <td>4.956</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>14.38</td>\n",
       "      <td>14.21</td>\n",
       "      <td>0.8951</td>\n",
       "      <td>5.386</td>\n",
       "      <td>3.312</td>\n",
       "      <td>2.462</td>\n",
       "      <td>4.956</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>14.11</td>\n",
       "      <td>14.10</td>\n",
       "      <td>0.8911</td>\n",
       "      <td>5.420</td>\n",
       "      <td>3.302</td>\n",
       "      <td>2.700</td>\n",
       "      <td>5.000</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>14.03</td>\n",
       "      <td>14.16</td>\n",
       "      <td>0.8796</td>\n",
       "      <td>5.438</td>\n",
       "      <td>3.201</td>\n",
       "      <td>1.717</td>\n",
       "      <td>5.001</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>15.69</td>\n",
       "      <td>14.75</td>\n",
       "      <td>0.9058</td>\n",
       "      <td>5.527</td>\n",
       "      <td>3.514</td>\n",
       "      <td>1.599</td>\n",
       "      <td>5.046</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "    area  perimeter  compactness  length of kernel  width of kernel  \\\n",
       "0  14.88      14.57       0.8811             5.554            3.333   \n",
       "1  14.38      14.21       0.8951             5.386            3.312   \n",
       "2  14.11      14.10       0.8911             5.420            3.302   \n",
       "3  14.03      14.16       0.8796             5.438            3.201   \n",
       "4  15.69      14.75       0.9058             5.527            3.514   \n",
       "\n",
       "   asymmetry coefficient  length of kernel groove  A  B  C  \n",
       "0                  1.018                    4.956  1  0  0  \n",
       "1                  2.462                    4.956  1  0  0  \n",
       "2                  2.700                    5.000  1  0  0  \n",
       "3                  1.717                    5.001  1  0  0  \n",
       "4                  1.599                    5.046  1  0  0  "
      ]
     },
     "execution_count": 197,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "test = data.loc[test_index]\n",
    "test = test.reset_index(drop = True)\n",
    "test.head()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "5247c981-63a7-411b-af1b-00f495589263",
   "metadata": {},
   "source": [
    "# 4.Build model"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "4e7948c7-984f-4a89-9fc1-7edb792b55a5",
   "metadata": {},
   "source": [
    "I copy some code from my homework3 and use them to form a complete model. This function includes initiating weight, calculating output, gradient, and so on."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 198,
   "id": "29881082-379e-4289-b6a8-d04747fbbb8b",
   "metadata": {},
   "outputs": [],
   "source": [
    "def weight(inputs, hiddends, outputs):\n",
    "    '''\n",
    "    This function will create  weights for DL and you need to give it the numbers of input, hiddents and outputs.\n",
    "    -------------------------------------------------------------------------------------------------\n",
    "    This function will return you two matrix that including the weight_input and weight_output\n",
    "    '''\n",
    "    W_int = np.random.randint(-5, 5, (inputs,hiddends))/10\n",
    "    bias_input = list(np.random.random(1))\n",
    "    bias_inputs = np.array(bias_input*hiddends)\n",
    "    W_int = np.concatenate((W_int, [bias_inputs]), axis=0)\n",
    "    \n",
    "    W_out = np.random.randint(-5, 5, (hiddends,outputs))/10\n",
    "    bias_out = list(np.random.random(1))\n",
    "    bias_outs = np.array(bias_out*outputs)\n",
    "    W_out = np.concatenate((W_out, [bias_outs]), axis=0)\n",
    "    return W_int, W_out"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 199,
   "id": "11a9712b-ecda-4e4f-aaa2-179f61b4f000",
   "metadata": {},
   "outputs": [],
   "source": [
    "def appendVector(vector):\n",
    "    '''\n",
    "    This function is used to extend 1 dimension for vector.\n",
    "    '''\n",
    "    vector1 = vector.copy()\n",
    "    vector1.append(1)\n",
    "    return vector1"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 200,
   "id": "268e0c4b-8f73-4e9b-adc1-ff1913ff889e",
   "metadata": {},
   "outputs": [],
   "source": [
    "def obtainRawHidden(W_int, W_out, inpis):\n",
    "    '''\n",
    "    This function is used to calculate the hidden layer's raw data in a network.\n",
    "    '''\n",
    "    inputs_nodes = len(inpis)\n",
    "    append_f = np.array(appendVector(inpis))\n",
    "    hraw = append_f.T@W_int\n",
    "    return hraw"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 201,
   "id": "cce125f4-983a-4ad2-bf50-bde6aa601852",
   "metadata": {},
   "outputs": [],
   "source": [
    "def sigmoidFun(raw):\n",
    "    '''\n",
    "    This function is the activate function that is used to transfer the raw data to out data.\n",
    "    '''\n",
    "    return 1/(1+(np.exp(-raw)))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 202,
   "id": "f3a6ad0a-8f27-4240-a22b-7d64aa8b6b69",
   "metadata": {},
   "outputs": [],
   "source": [
    "def obtainOutput(W_int, W_out, inpis):\n",
    "    '''\n",
    "    This function will be used to calculate the function final output by using the output of hidden layer data times the weight.\n",
    "    '''\n",
    "    hraw = obtainRawHidden(W_int, W_out, inpis)\n",
    "    hact = sigmoidFun(hraw)\n",
    "    hact1 = np.array(appendVector(list(hact)))\n",
    "    outraw = hact1.T@W_out\n",
    "    out = sigmoidFun(outraw)\n",
    "    return out, hact"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 203,
   "id": "73fb6afc-b3f1-4459-80bf-d17064028de3",
   "metadata": {},
   "outputs": [],
   "source": [
    "def gradient_E_Wjk(output, targk, hact):\n",
    "    '''\n",
    "    This function will be used to calculate the gradient of weight between the hidden layer and output.\n",
    "    '''\n",
    "    gradient_out = []\n",
    "    gradient_a = (output-targk)*output*(1-output)\n",
    "    for i in gradient_a:\n",
    "        gradient_out.append(i*hact)\n",
    "    gradient_out = np.array(gradient_out)\n",
    "    gradient_out = gradient_out.T\n",
    "    return gradient_out"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 204,
   "id": "b600a97b-5ea3-4ff4-9270-a22a4a7040ca",
   "metadata": {},
   "outputs": [],
   "source": [
    "def gradient_E_biasO(output, targk):\n",
    "    '''\n",
    "    This function is used to calculate the gradient of bias between the hidden layer and output.\n",
    "    '''\n",
    "    gradient_a = ((output-targk)*output*(1-output)).sum()\n",
    "    return gradient_a"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 205,
   "id": "6da04a21-0b2b-46d9-9609-46e380214084",
   "metadata": {},
   "outputs": [],
   "source": [
    "def gradient_E_wij(output, targk, W_out, hact, inpis):\n",
    "    '''\n",
    "    This function will be used to calculate the gradient of weight between the input and hidden layer.\n",
    "    '''\n",
    "    gradient_a = ((output-targk)*output*(1-output)*W_out).sum()*hact*(1-hact)\n",
    "    \n",
    "    gradient_int = []\n",
    "    int_np = np.array(inpis)\n",
    "    for i in gradient_a:\n",
    "        gradient_int.append(i*int_np)\n",
    "    gradient_int = np.array(gradient_int)\n",
    "    gradient_int = gradient_int.T\n",
    "    return gradient_int"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 206,
   "id": "db51463a-e8ea-4232-9024-a3cbf8fff57d",
   "metadata": {},
   "outputs": [],
   "source": [
    "def gradient_E_biasH(output, targk, W_out, hact):\n",
    "    '''\n",
    "    This function is used to calculate the gradient of bias between the input and hidden layer.\n",
    "    '''\n",
    "    gradient_a = (((output-targk)*output*(1-output)*W_out).sum()*hact*(1-hact)).sum()\n",
    "    return gradient_a"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 207,
   "id": "753befb0-720b-48af-b50b-076cb7ae1615",
   "metadata": {},
   "outputs": [],
   "source": [
    "def update_wij(output, targk, W_out, hact, W_int, inpis, alpha):\n",
    "    '''\n",
    "    This function will be used to update the weight between the input and hidden layer.\n",
    "    '''\n",
    "    g_e_biasH_list = []\n",
    "    g_E_wij = gradient_E_wij(output, targk, W_out, hact, inpis)\n",
    "    g_E_biasH = gradient_E_biasH(output, targk, W_out, hact)\n",
    "    g_E_wij_rows, g_E_wij_columns = g_E_wij.shape\n",
    "    g_e_biasH_list.append(g_E_biasH)\n",
    "    g_e_biasH_list = g_e_biasH_list*g_E_wij_columns\n",
    "    g_E_ij = np.concatenate((g_E_wij, [g_e_biasH_list]), axis = 0)\n",
    "    new_wij = W_int-alpha*g_E_ij\n",
    "    return new_wij"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 208,
   "id": "5ca1a43c-3ef6-4735-ae68-e7dd01e8ae51",
   "metadata": {},
   "outputs": [],
   "source": [
    "def update_Wjk(output, targk, hact, W_out, alpha):\n",
    "    '''\n",
    "    This function will be used to update the weight between the hidden layer and output.\n",
    "    '''\n",
    "    g_e_biasO_list = []\n",
    "    g_E_Wjk = gradient_E_Wjk(output, targk, hact)\n",
    "    g_E_biasO = gradient_E_biasO(output, targk)\n",
    "    g_E_Wjk_rows, g_E_Wjk_columns = g_E_Wjk.shape\n",
    "    g_e_biasO_list.append(g_E_biasO)\n",
    "    g_e_biasO_list = g_e_biasO_list*g_E_Wjk_columns\n",
    "    g_E_jk = np.concatenate((g_E_Wjk, [g_e_biasO_list]), axis = 0)\n",
    "    new_Wjk = W_out-alpha*g_E_jk\n",
    "    return new_Wjk"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 332,
   "id": "7de20dad-f59f-4786-881f-d792aa85e8fa",
   "metadata": {},
   "outputs": [],
   "source": [
    "def encode_output(output):\n",
    "    '''\n",
    "    This function is used to encode the output and let they become the one-hot encoding.\n",
    "    In this function, the highest values will become 1 and the others become 0\n",
    "    '''\n",
    "    new_output = []\n",
    "    maximun_index = np.argmax(np.array(output))\n",
    "    for i in range(len(output)):\n",
    "        if i==maximun_index:\n",
    "            new_output.append(1)\n",
    "        else:\n",
    "            new_output.append(0)\n",
    "    return new_output"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 413,
   "id": "3e8ea68a-a61c-4258-bf36-3f88e4f69860",
   "metadata": {},
   "outputs": [],
   "source": [
    "def createOutput_pandas(data_dl, W_int, W_out, inpis):\n",
    "    '''\n",
    "    This is function will be used to create a big output panda.\n",
    "    In this function, I will calculate the output and then put them back to the pandas \n",
    "    and use Out_A, Out_B and Out_C as the new columns.\n",
    "    '''\n",
    "    #save data\n",
    "    output_data = data_dl.copy()\n",
    "    \n",
    "    #Save output data\n",
    "    Out_A = []\n",
    "    Out_B = []\n",
    "    Out_C = []\n",
    "    hact_list = []\n",
    "    \n",
    "    #calculate output\n",
    "    for i in range(len(data_dl)):\n",
    "        inpis = list(data_dl.iloc[i,:-3])\n",
    "        out, hact = obtainOutput(W_int, W_out, inpis)\n",
    "        #Use one-hot encoding to encode the output\n",
    "        out_onehot = encode_output(out)\n",
    "        Out_A.append(out[0])\n",
    "        Out_B.append(out[1])\n",
    "        Out_C.append(out[2])\n",
    "        hact_list.append(hact)\n",
    "    output_data['Out_A'] = Out_A\n",
    "    output_data['Out_B'] = Out_B\n",
    "    output_data['Out_C'] = Out_C\n",
    "    output_data['hact_list'] = hact_list\n",
    "    output_data['error'] = 0.5*(((output_data.Out_A-output_data.A)**2)+((output_data.Out_B-output_data.B)**2)+((output_data.Out_C-output_data.C)**2))\n",
    "    \n",
    "    return output_data"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "85449cd3-7877-4ed4-b827-519dacbf662a",
   "metadata": {},
   "source": [
    "# 5. Train model"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "46efeab2-3b9f-488f-8290-51d1d3f41932",
   "metadata": {},
   "source": [
    "Here is to start to combine several functions above and train the training data. By the way, the model has the best performance with the hyperparameter alpha = 0.06, hidden_nodes = 7 and output_nodes = 3. But this model still has a probability to fail in train and I suppose maybe there is an outlier in the data and needs to be removed. But this model will have a about 1/3 probability to run successfully. And the best error is greater than 11 and the higher accuracy is less than 92. The fail running means is the model is hard to convergence."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "cc6499da-b442-4061-842e-e5910cbd6042",
   "metadata": {},
   "source": [
    "In this process, I will imitate the perception algorithm. Firstly, I will randomly pick up data to calculate and the result. Then use this result to calculate gradient, output, and error. Then calculate all other rows data's predict output. Select those data that are different from the target data. Randomly choose one of the rows of data from this error prediction result data and use this row data to calculate and update the weight. Calculate the accuracy after each 100 training process. If the accuracy, steps, and error meet the requirement, stop training and output the weight of the input and hidden layer. Then use this weight list to test and calculate some information about the test."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 530,
   "id": "181ad858-6569-4903-a532-229c41eb9cf2",
   "metadata": {},
   "outputs": [],
   "source": [
    "def DeelLearning(data_dl):\n",
    "    '''\n",
    "    This function will use all of the functions above to learning and update the weight.\n",
    "    -------------------------------------------------------------------------------------\n",
    "    This function will return the two new weights. We can use these two weights to predict.\n",
    "    '''\n",
    "    # Hyperparameter\n",
    "    hidden_nodes = 7\n",
    "    output_nodes = 3\n",
    "    #alpha = 0.04 error>30\n",
    "    #alpha = 0.06 error>11 accuracy <92\n",
    "    #alpha = 0.08 error>29\n",
    "    alpha = 0.06\n",
    "    \n",
    "    ##get target list\n",
    "    onehot_targe_list = []\n",
    "    for i in range(len(data_dl)):\n",
    "        targe_onthot = data_dl.iloc[i, -3:]\n",
    "        onehot_targe_list.append(list(targe_onthot))\n",
    "    onehot_targe_list = np.array(onehot_targe_list)\n",
    "    \n",
    "    # randomly extract data from dataset and use it to start\n",
    "    randon_data = data_dl.sample().values[0]\n",
    "    targk = list(randon_data[-3:])\n",
    "    inpis = list(randon_data[:-3])\n",
    "    inputs_nodes = len(inpis)\n",
    "    \n",
    "    #Get the first weight of input and hidden layer\n",
    "    W_int, W_out = weight(inputs_nodes, hidden_nodes, output_nodes)\n",
    "    \n",
    "    #calculate the output data\n",
    "    output_data = createOutput_pandas(data_dl, W_int, W_out, inpis)\n",
    "    \n",
    "    #Calculate_error\n",
    "    error = output_data.error.sum()\n",
    "    \n",
    "    step = 1\n",
    "    accuracy = 0\n",
    "    # If the error>3 and doesn't reach 100000 and accuracy less than 0.9, keep training\n",
    "    while error>3 and step<100000 and accuracy<.90:\n",
    "        #Pick up data which its result is incorrect\n",
    "        incorrct_result = output_data[output_data.error!=0]\n",
    "        incorrct_result = incorrct_result.reset_index(drop = True)\n",
    "        \n",
    "        #Random pick up one row incorrect result data\n",
    "        one_row_data = incorrct_result.sample().values[0]\n",
    "        #Extract input and output\n",
    "        targk = list(one_row_data[7:10])\n",
    "        inpis = list(one_row_data[:7])\n",
    "        hact = one_row_data[-2]\n",
    "        out = []\n",
    "        out.append(one_row_data[-5])\n",
    "        out.append(one_row_data[-4])\n",
    "        out.append(one_row_data[-3])\n",
    "        \n",
    "        #update weight and bias\n",
    "        new_wij = update_wij(np.array(out), np.array(targk), W_out, hact, W_int, inpis, alpha)\n",
    "        new_Wjk = update_Wjk(np.array(out), np.array(targk), hact, W_out, alpha)\n",
    "        W_int, W_out = new_wij, new_Wjk\n",
    "        \n",
    "        #Get calculate output result and calculate the error\n",
    "        output_data = createOutput_pandas(data_dl, W_int, W_out, inpis)\n",
    "        error = output_data.error.sum()\n",
    "        step+=1\n",
    "        \n",
    "        #calculate accuracy and print accuracy after each 100 trainning, so the epoch=100\n",
    "        if step%100 == 0:\n",
    "            #calculate accuray\n",
    "            ##get onehot output\n",
    "            onehot_output_list = []\n",
    "            for i in range(len(output_data)):\n",
    "                out_onthot = output_data.iloc[i, -5:-2]\n",
    "                out_onthot = encode_output(out_onthot)\n",
    "                onehot_output_list.append(out_onthot)\n",
    "            compare_list = np.equal(onehot_targe_list,onehot_output_list)\n",
    "            compare_result = []\n",
    "            for i in compare_list:\n",
    "                if list(i)==[True, True, True]:\n",
    "                    compare_result.append(1)\n",
    "                else:\n",
    "                    compare_result.append(0)\n",
    "            compare_result = np.array(compare_result)\n",
    "            accuracy = len(compare_result[compare_result==1])/len(compare_result)\n",
    "            print(f'error = {error}, accuracy = {accuracy}')\n",
    "            \n",
    "    #If the accuracy>=0.9, calculate its Confusion Matrix, Precision, Recall and F1 score\n",
    "    if accuracy>=0.9:\n",
    "        Confusion_Matrix_test = [[0, 0, 0],[0, 0, 0], [0, 0, 0]]\n",
    "        for i in range(len(onehot_targe_list)):\n",
    "            if onehot_targe_list[i][0]==1:\n",
    "                if onehot_output_list[i][0] == 1:\n",
    "                    Confusion_Matrix_test[0][0]+=1\n",
    "                elif onehot_output_list[i][1] == 1:\n",
    "                    Confusion_Matrix_test[0][1]+=1\n",
    "                else:\n",
    "                    Confusion_Matrix_test[0][2]+=1\n",
    "            elif onehot_targe_list[i][1]==1:\n",
    "                if onehot_output_list[i][0] == 1:\n",
    "                    Confusion_Matrix_test[1][0]+=1\n",
    "                elif onehot_output_list[i][1] == 1:\n",
    "                    Confusion_Matrix_test[1][1]+=1\n",
    "                else:\n",
    "                    Confusion_Matrix_test[1][2]+=1\n",
    "            elif onehot_targe_list[i][2]==1:\n",
    "                if onehot_output_list[i][0] == 1:\n",
    "                    Confusion_Matrix_test[2][0]+=1\n",
    "                elif onehot_output_list[i][1] == 1:\n",
    "                    Confusion_Matrix_test[2][1]+=1\n",
    "                else:\n",
    "                    Confusion_Matrix_test[2][2]+=1\n",
    "            \n",
    "        print(f'W_int = {W_int}, W_out = {W_out}')\n",
    "        print(f'Train {step} steps, the epochs={100}, final error = {error}, accuracy = {accuracy}')\n",
    "        print(f'Confusion_Matrix_test = {Confusion_Matrix_test}')\n",
    "        #for class1\n",
    "        calss1_Precision = Confusion_Matrix_test[0][0]/(Confusion_Matrix_test[0][0]+Confusion_Matrix_test[0][1]+Confusion_Matrix_test[0][2])\n",
    "        class1_Recall = Confusion_Matrix_test[0][0]/(Confusion_Matrix_test[0][0]+Confusion_Matrix_test[1][0]+Confusion_Matrix_test[2][0])\n",
    "        print(f'For calss1, Precision = {calss1_Precision}')\n",
    "        print(f'For calss1, Recall = {class1_Recall}')\n",
    "        print(f'For calss1, F1_score = {(2*calss1_Precision*class1_Recall)/(calss1_Precision+class1_Recall)}')\n",
    "        \n",
    "        #for class2\n",
    "        calss2_Precision = Confusion_Matrix_test[1][1]/(Confusion_Matrix_test[1][0]+Confusion_Matrix_test[1][1]+Confusion_Matrix_test[1][2])\n",
    "        class2_Recall = Confusion_Matrix_test[1][1]/(Confusion_Matrix_test[0][1]+Confusion_Matrix_test[1][1]+Confusion_Matrix_test[2][1])\n",
    "        print(f'For calss1, Precision = {calss2_Precision}')\n",
    "        print(f'For calss1, Recall = {class2_Recall}')\n",
    "        print(f'For calss1, F1_score = {(2*calss2_Precision*class2_Recall)/(calss2_Precision+class2_Recall)}')\n",
    "        \n",
    "        #for class3\n",
    "        calss3_Precision = Confusion_Matrix_test[2][2]/(Confusion_Matrix_test[2][0]+Confusion_Matrix_test[2][1]+Confusion_Matrix_test[2][2])\n",
    "        class3_Recall = Confusion_Matrix_test[2][2]/(Confusion_Matrix_test[0][2]+Confusion_Matrix_test[1][2]+Confusion_Matrix_test[2][2])\n",
    "        print(f'For calss1, Precision = {calss3_Precision}')\n",
    "        print(f'For calss1, Recall = {class3_Recall}')\n",
    "        print(f'For calss1, F1_score = {(2*calss3_Precision*class3_Recall)/(calss3_Precision+class3_Recall)}')\n",
    "        \n",
    "    return W_int, W_out"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 531,
   "id": "02f929a0-cc16-4990-96db-90949aabf1fc",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "error = 51.27531351445661, accuracy = 0.32666666666666666\n",
      "error = 49.9494469544596, accuracy = 0.32666666666666666\n",
      "error = 48.9921646100386, accuracy = 0.64\n",
      "error = 49.70002358441548, accuracy = 0.3466666666666667\n",
      "error = 49.94225774318171, accuracy = 0.3466666666666667\n",
      "error = 50.35473390923373, accuracy = 0.3466666666666667\n",
      "error = 48.18186639822803, accuracy = 0.36666666666666664\n",
      "error = 48.49189500248838, accuracy = 0.52\n",
      "error = 47.10027532477841, accuracy = 0.3466666666666667\n",
      "error = 46.341341522459395, accuracy = 0.4266666666666667\n",
      "error = 45.612039790800836, accuracy = 0.5333333333333333\n",
      "error = 46.265800801860784, accuracy = 0.4266666666666667\n",
      "error = 43.60669336057228, accuracy = 0.6266666666666667\n",
      "error = 43.6325431535637, accuracy = 0.6733333333333333\n",
      "error = 44.747099890489494, accuracy = 0.8\n",
      "error = 46.150145802307804, accuracy = 0.38666666666666666\n",
      "error = 44.194227716897174, accuracy = 0.54\n",
      "error = 44.33816058887176, accuracy = 0.43333333333333335\n",
      "error = 47.85645827728635, accuracy = 0.4266666666666667\n",
      "error = 45.109362021830236, accuracy = 0.4533333333333333\n",
      "error = 46.184604371195505, accuracy = 0.3933333333333333\n",
      "error = 45.712420020731024, accuracy = 0.41333333333333333\n",
      "error = 49.39734111952117, accuracy = 0.56\n",
      "error = 43.86441538266483, accuracy = 0.6266666666666667\n",
      "error = 42.9263860650488, accuracy = 0.6866666666666666\n",
      "error = 44.632430937462885, accuracy = 0.5866666666666667\n",
      "error = 43.002083494931526, accuracy = 0.5733333333333334\n",
      "error = 40.54911634799987, accuracy = 0.6133333333333333\n",
      "error = 41.84694847185543, accuracy = 0.5866666666666667\n",
      "error = 46.13969031644455, accuracy = 0.44666666666666666\n",
      "error = 37.70474431010297, accuracy = 0.7266666666666667\n",
      "error = 39.87146952727889, accuracy = 0.66\n",
      "error = 36.79093659627715, accuracy = 0.7333333333333333\n",
      "error = 41.533469534291825, accuracy = 0.5933333333333334\n",
      "error = 43.40921383031068, accuracy = 0.5133333333333333\n",
      "error = 41.636342307826986, accuracy = 0.56\n",
      "error = 41.98036460986101, accuracy = 0.58\n",
      "error = 45.21842086774812, accuracy = 0.5266666666666666\n",
      "error = 46.38769477857272, accuracy = 0.47333333333333333\n",
      "error = 39.57770902775033, accuracy = 0.5933333333333334\n",
      "error = 50.44041031561535, accuracy = 0.4266666666666667\n",
      "error = 46.62232172008696, accuracy = 0.47333333333333333\n",
      "error = 34.63956517311216, accuracy = 0.7066666666666667\n",
      "error = 53.686663232620276, accuracy = 0.34\n",
      "error = 40.23873202920541, accuracy = 0.6133333333333333\n",
      "error = 48.540709152062966, accuracy = 0.47333333333333333\n",
      "error = 38.82228377576297, accuracy = 0.64\n",
      "error = 39.14305959527054, accuracy = 0.62\n",
      "error = 36.398167476669514, accuracy = 0.7066666666666667\n",
      "error = 34.00314580406708, accuracy = 0.7333333333333333\n",
      "error = 39.72894761413553, accuracy = 0.6133333333333333\n",
      "error = 33.63427695558457, accuracy = 0.7\n",
      "error = 39.4141419067459, accuracy = 0.6066666666666667\n",
      "error = 38.27258087170635, accuracy = 0.62\n",
      "error = 38.40763045406932, accuracy = 0.6066666666666667\n",
      "error = 35.955817823692115, accuracy = 0.6666666666666666\n",
      "error = 37.14295772461094, accuracy = 0.6533333333333333\n",
      "error = 35.48505077429275, accuracy = 0.6733333333333333\n",
      "error = 44.331604274490175, accuracy = 0.5133333333333333\n",
      "error = 32.162958059975, accuracy = 0.7333333333333333\n",
      "error = 35.604625819095354, accuracy = 0.6333333333333333\n",
      "error = 38.33743689711636, accuracy = 0.6266666666666667\n",
      "error = 37.35415404033813, accuracy = 0.6266666666666667\n",
      "error = 30.112339947214785, accuracy = 0.7466666666666667\n",
      "error = 31.387123413416468, accuracy = 0.7533333333333333\n",
      "error = 38.65172039681702, accuracy = 0.6\n",
      "error = 30.476782538728813, accuracy = 0.76\n",
      "error = 29.55957687455615, accuracy = 0.7666666666666667\n",
      "error = 36.39944516802419, accuracy = 0.62\n",
      "error = 31.283306016566314, accuracy = 0.7266666666666667\n",
      "error = 32.92056839077818, accuracy = 0.6533333333333333\n",
      "error = 30.194394041100402, accuracy = 0.7466666666666667\n",
      "error = 30.89208312897688, accuracy = 0.72\n",
      "error = 33.528132223425, accuracy = 0.7\n",
      "error = 28.737801284998298, accuracy = 0.7733333333333333\n",
      "error = 31.745480981969532, accuracy = 0.6866666666666666\n",
      "error = 36.67953251013194, accuracy = 0.6266666666666667\n",
      "error = 29.89607084325532, accuracy = 0.7266666666666667\n",
      "error = 33.61429257735904, accuracy = 0.5933333333333334\n",
      "error = 35.19105909223192, accuracy = 0.62\n",
      "error = 30.28125537328274, accuracy = 0.74\n",
      "error = 39.86055836075772, accuracy = 0.5933333333333334\n",
      "error = 43.79446689081139, accuracy = 0.5733333333333334\n",
      "error = 31.635352029277016, accuracy = 0.72\n",
      "error = 44.586249658472894, accuracy = 0.49333333333333335\n",
      "error = 41.5596453615775, accuracy = 0.5733333333333334\n",
      "error = 47.181508526797245, accuracy = 0.44\n",
      "error = 36.18523638748581, accuracy = 0.66\n",
      "error = 29.349396912751534, accuracy = 0.7666666666666667\n",
      "error = 29.744478678322583, accuracy = 0.7666666666666667\n",
      "error = 32.20020932826064, accuracy = 0.7133333333333334\n",
      "error = 33.57680981213114, accuracy = 0.6733333333333333\n",
      "error = 29.280723503215846, accuracy = 0.76\n",
      "error = 28.380008234458902, accuracy = 0.74\n",
      "error = 33.86387008216839, accuracy = 0.6333333333333333\n",
      "error = 25.750883466510537, accuracy = 0.7866666666666666\n",
      "error = 32.47654244133793, accuracy = 0.68\n",
      "error = 34.212823331429625, accuracy = 0.6466666666666666\n",
      "error = 25.360214209314954, accuracy = 0.78\n",
      "error = 32.03010705067179, accuracy = 0.6333333333333333\n",
      "error = 27.8879395988736, accuracy = 0.7533333333333333\n",
      "error = 58.70795026342966, accuracy = 0.4266666666666667\n",
      "error = 24.287378981367098, accuracy = 0.8133333333333334\n",
      "error = 32.17499154252718, accuracy = 0.68\n",
      "error = 29.419096583880567, accuracy = 0.74\n",
      "error = 25.534338999845268, accuracy = 0.7866666666666666\n",
      "error = 51.08338288797485, accuracy = 0.4533333333333333\n",
      "error = 40.08845129140619, accuracy = 0.58\n",
      "error = 52.565743500004224, accuracy = 0.4666666666666667\n",
      "error = 27.247513438320183, accuracy = 0.8066666666666666\n",
      "error = 29.276725254944296, accuracy = 0.8\n",
      "error = 25.729952344131334, accuracy = 0.8133333333333334\n",
      "error = 27.08452923303402, accuracy = 0.8066666666666666\n",
      "error = 28.184012536753215, accuracy = 0.7333333333333333\n",
      "error = 28.020333483116424, accuracy = 0.74\n",
      "error = 23.71936367056024, accuracy = 0.82\n",
      "error = 29.408101677107194, accuracy = 0.78\n",
      "error = 24.642113230942364, accuracy = 0.8266666666666667\n",
      "error = 26.62058290030945, accuracy = 0.8\n",
      "error = 24.754189473904013, accuracy = 0.8\n",
      "error = 31.427441046433376, accuracy = 0.68\n",
      "error = 25.80438845548977, accuracy = 0.8066666666666666\n",
      "error = 25.207179614095878, accuracy = 0.7933333333333333\n",
      "error = 23.257818839865777, accuracy = 0.8\n",
      "error = 23.348107039545177, accuracy = 0.82\n",
      "error = 22.731659048175786, accuracy = 0.8333333333333334\n",
      "error = 28.964114942233714, accuracy = 0.7333333333333333\n",
      "error = 29.056375672561874, accuracy = 0.7466666666666667\n",
      "error = 21.564302050021873, accuracy = 0.8333333333333334\n",
      "error = 22.331002874686448, accuracy = 0.8333333333333334\n",
      "error = 27.878855488325392, accuracy = 0.78\n",
      "error = 24.458766256627342, accuracy = 0.7933333333333333\n",
      "error = 30.921856564504992, accuracy = 0.7133333333333334\n",
      "error = 22.818710286127597, accuracy = 0.8066666666666666\n",
      "error = 21.442885307050513, accuracy = 0.8466666666666667\n",
      "error = 20.28152226395108, accuracy = 0.84\n",
      "error = 26.965900345721206, accuracy = 0.74\n",
      "error = 20.59334154721366, accuracy = 0.84\n",
      "error = 29.134169164327986, accuracy = 0.7066666666666667\n",
      "error = 21.721650720009407, accuracy = 0.8333333333333334\n",
      "error = 27.513303907951546, accuracy = 0.76\n",
      "error = 22.04947255301243, accuracy = 0.8266666666666667\n",
      "error = 19.633930770349288, accuracy = 0.86\n",
      "error = 43.1597287249042, accuracy = 0.5733333333333334\n",
      "error = 19.927297219157794, accuracy = 0.8466666666666667\n",
      "error = 23.315598660208956, accuracy = 0.7866666666666666\n",
      "error = 20.478915574619393, accuracy = 0.84\n",
      "error = 22.753739499333186, accuracy = 0.8133333333333334\n",
      "error = 24.825844214691024, accuracy = 0.8066666666666666\n",
      "error = 21.33360482370226, accuracy = 0.8333333333333334\n",
      "error = 19.03930939165122, accuracy = 0.8666666666666667\n",
      "error = 20.895338276758984, accuracy = 0.84\n",
      "error = 20.654727703387692, accuracy = 0.8266666666666667\n",
      "error = 21.804633999091266, accuracy = 0.8266666666666667\n",
      "error = 21.21815256470839, accuracy = 0.8266666666666667\n",
      "error = 20.10279451962193, accuracy = 0.8533333333333334\n",
      "error = 19.0360573908594, accuracy = 0.8466666666666667\n",
      "error = 18.387565296341684, accuracy = 0.8666666666666667\n",
      "error = 23.0282029190562, accuracy = 0.8066666666666666\n",
      "error = 27.633629735266705, accuracy = 0.7266666666666667\n",
      "error = 22.033244400170652, accuracy = 0.8133333333333334\n",
      "error = 20.421222533387777, accuracy = 0.8266666666666667\n",
      "error = 34.9559631282663, accuracy = 0.6866666666666666\n",
      "error = 31.24973090422759, accuracy = 0.7066666666666667\n",
      "error = 20.154570126633974, accuracy = 0.8466666666666667\n",
      "error = 20.53070031178838, accuracy = 0.8333333333333334\n",
      "error = 27.85179009078315, accuracy = 0.72\n",
      "error = 22.32649345812988, accuracy = 0.8133333333333334\n",
      "error = 18.96209733942329, accuracy = 0.8533333333333334\n",
      "error = 27.96288732191659, accuracy = 0.72\n",
      "error = 16.946195734954493, accuracy = 0.8733333333333333\n",
      "error = 18.952825692691988, accuracy = 0.8333333333333334\n",
      "error = 18.935488932569147, accuracy = 0.8466666666666667\n",
      "error = 22.35440798169592, accuracy = 0.8133333333333334\n",
      "error = 18.94438711186606, accuracy = 0.8333333333333334\n",
      "error = 21.7247775313742, accuracy = 0.8133333333333334\n",
      "error = 19.97770372455322, accuracy = 0.8333333333333334\n",
      "error = 24.97175651744163, accuracy = 0.7466666666666667\n",
      "error = 17.456229588120728, accuracy = 0.8733333333333333\n",
      "error = 17.94615786944835, accuracy = 0.8666666666666667\n",
      "error = 24.981851557881534, accuracy = 0.7466666666666667\n",
      "error = 23.18226388198694, accuracy = 0.78\n",
      "error = 18.750286340261592, accuracy = 0.86\n",
      "error = 37.15061832765003, accuracy = 0.64\n",
      "error = 24.532261508091715, accuracy = 0.7933333333333333\n",
      "error = 45.548606544489445, accuracy = 0.5933333333333334\n",
      "error = 15.74842225713824, accuracy = 0.8866666666666667\n",
      "error = 20.820576975625194, accuracy = 0.8266666666666667\n",
      "error = 24.37995035726256, accuracy = 0.8\n",
      "error = 19.061980254194836, accuracy = 0.8333333333333334\n",
      "error = 18.690491915251577, accuracy = 0.8333333333333334\n",
      "error = 17.55246452819511, accuracy = 0.8466666666666667\n",
      "error = 15.219305963561988, accuracy = 0.8933333333333333\n",
      "error = 19.613509085004402, accuracy = 0.8333333333333334\n",
      "error = 18.37435466389883, accuracy = 0.84\n",
      "error = 19.898911913536594, accuracy = 0.8266666666666667\n",
      "error = 16.95464887115797, accuracy = 0.8733333333333333\n",
      "error = 17.42300371902852, accuracy = 0.8533333333333334\n",
      "error = 16.15627037953882, accuracy = 0.8666666666666667\n",
      "error = 46.37556447380039, accuracy = 0.5866666666666667\n",
      "error = 16.596825071155543, accuracy = 0.8733333333333333\n",
      "error = 16.47479118610211, accuracy = 0.8666666666666667\n",
      "error = 14.560893358376774, accuracy = 0.9\n",
      "W_int = [[-2.79410326e+00  2.86094243e+00 -3.33721350e-01 -1.05607658e+00\n",
      "  -5.06310314e-01 -1.90208597e-01 -9.56754646e-02]\n",
      " [ 3.47859367e+00 -7.92083238e-01 -4.40615652e-01  2.36467012e+00\n",
      "  -3.07809729e-01  6.16114554e-01 -3.96605412e-01]\n",
      " [ 9.25908557e-01 -2.54504156e-01  9.73645193e-02  4.86274602e-01\n",
      "   3.99490825e-01 -4.86118651e-01  2.03490942e-04]\n",
      " [ 1.50332871e+00 -1.31772503e+00 -4.16381061e-01  1.15473336e+00\n",
      "  -4.03168448e-01  1.82710787e-01 -3.98811378e-01]\n",
      " [ 1.37739079e+00  8.93313455e-01 -5.08358340e-01  7.15672379e-01\n",
      "  -1.01579381e-01 -2.49875773e-01 -2.99063027e-01]\n",
      " [-2.65842922e+00 -2.49908889e+00  1.82807638e-01 -3.03017744e+00\n",
      "  -3.29407189e-03  4.23113727e-01 -3.00547166e-01]\n",
      " [-2.75553033e+00 -2.89564993e+00  2.83280314e-01 -1.18626480e+00\n",
      "  -3.29580107e-03  2.71476529e-01 -2.99321781e-01]\n",
      " [ 1.56150101e+00  1.56150101e+00  1.56150101e+00  1.56150101e+00\n",
      "   1.56150101e+00  1.56150101e+00  1.56150101e+00]], W_out = [[ 2.59431271 -3.57457346  0.8029079 ]\n",
      " [ 2.07581077  3.92851387 -4.72583309]\n",
      " [ 0.09876414  0.19802303  0.40306642]\n",
      " [ 0.21142722 -0.31045295  0.11107769]\n",
      " [ 0.39978491 -0.10039715 -0.49943297]\n",
      " [-3.08794578 -1.18533853  2.54050808]\n",
      " [-0.29989316 -0.30044355 -0.29967489]\n",
      " [-0.70674344 -0.70674344 -0.70674344]]\n",
      "Train 20300 steps, the epochs=100, final error = 14.560893358376774, accuracy = 0.9\n",
      "Confusion_Matrix_test = [[41, 5, 6], [1, 48, 0], [3, 0, 46]]\n",
      "For calss1, Precision = 0.7884615384615384\n",
      "For calss1, Recall = 0.9111111111111111\n",
      "For calss1, F1_score = 0.845360824742268\n",
      "For calss1, Precision = 0.9795918367346939\n",
      "For calss1, Recall = 0.9056603773584906\n",
      "For calss1, F1_score = 0.9411764705882353\n",
      "For calss1, Precision = 0.9387755102040817\n",
      "For calss1, Recall = 0.8846153846153846\n",
      "For calss1, F1_score = 0.9108910891089108\n"
     ]
    }
   ],
   "source": [
    "W_in, W_out = DeelLearning(train)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "0534de9d-be72-405a-83e8-cc6e7ddd7dd1",
   "metadata": {},
   "source": [
    "# 6. Test the testing data"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "dbaa7284-5c87-4564-880e-bd74ef971549",
   "metadata": {},
   "source": [
    "After I ran part 5, I got the weight of the input and hidden layer. I used these parameters to calculate the output result of the test dataset. "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 574,
   "id": "dbf11944-0f57-45d6-803a-ce0ee42cd5ed",
   "metadata": {},
   "outputs": [],
   "source": [
    "def test_testdate(test, W_int, W_out):\n",
    "    hidden_nodes = 7\n",
    "    output_nodes = 3\n",
    "    output_data = createOutput_pandas(test, W_int, W_out, 1)\n",
    "    error = output_data.error.sum()\n",
    "    \n",
    "    ##get target data list from test dataset \n",
    "    onehot_targe_list = []\n",
    "    for i in range(len(test)):\n",
    "        targe_onthot = test.iloc[i, -3:]\n",
    "        onehot_targe_list.append(list(targe_onthot))\n",
    "    onehot_targe_list = np.array(onehot_targe_list)\n",
    "    \n",
    "    ## Calculate and get the predict output\n",
    "    onehot_output_list = []\n",
    "    for i in range(len(output_data)):\n",
    "        out_onthot = output_data.iloc[i, -5:-2]\n",
    "        out_onthot = encode_output(out_onthot)\n",
    "        onehot_output_list.append(out_onthot)\n",
    "    compare_list = np.equal(onehot_targe_list,onehot_output_list)\n",
    "    compare_result = []\n",
    "    for i in compare_list:\n",
    "        if list(i)==[True, True, True]:\n",
    "            compare_result.append(1)\n",
    "        else:\n",
    "            compare_result.append(0)\n",
    "    compare_result = np.array(compare_result)\n",
    "    accuracy = len(compare_result[compare_result==1])/len(compare_result)\n",
    "    \n",
    "    #Calculate the Confusion Matrix, Precision, Recall and F1 score.\n",
    "    Confusion_Matrix_test = [[0, 0, 0],[0, 0, 0], [0, 0, 0]]\n",
    "    for i in range(len(onehot_targe_list)):\n",
    "        if onehot_targe_list[i][0]==1:\n",
    "            if onehot_output_list[i][0] == 1:\n",
    "                Confusion_Matrix_test[0][0]+=1\n",
    "            elif onehot_output_list[i][1] == 1:\n",
    "                Confusion_Matrix_test[0][1]+=1\n",
    "            else:\n",
    "                Confusion_Matrix_test[0][2]+=1\n",
    "        elif onehot_targe_list[i][1]==1:\n",
    "            if onehot_output_list[i][0] == 1:\n",
    "                Confusion_Matrix_test[1][0]+=1\n",
    "            elif onehot_output_list[i][1] == 1:\n",
    "                Confusion_Matrix_test[1][1]+=1\n",
    "            else:\n",
    "                Confusion_Matrix_test[1][2]+=1\n",
    "        elif onehot_targe_list[i][2]==1:\n",
    "            if onehot_output_list[i][0] == 1:\n",
    "                Confusion_Matrix_test[2][0]+=1\n",
    "            elif onehot_output_list[i][1] == 1:\n",
    "                Confusion_Matrix_test[2][1]+=1\n",
    "            else:\n",
    "                Confusion_Matrix_test[2][2]+=1\n",
    "            \n",
    "    print(f'W_int = {W_int}')\n",
    "    print(f'W_out = {W_out}')\n",
    "    print(f'the epochs={100}, final error = {error}, accuracy = {accuracy}')\n",
    "    print(f'Confusion_Matrix_test = {Confusion_Matrix_test}')\n",
    "    #for class1\n",
    "    calss1_Precision = Confusion_Matrix_test[0][0]/(Confusion_Matrix_test[0][0]+Confusion_Matrix_test[0][1]+Confusion_Matrix_test[0][2])\n",
    "    class1_Recall = Confusion_Matrix_test[0][0]/(Confusion_Matrix_test[0][0]+Confusion_Matrix_test[1][0]+Confusion_Matrix_test[2][0])\n",
    "    print(f'For calss1, Precision = {calss1_Precision}')\n",
    "    print(f'For calss1, Recall = {class1_Recall}')\n",
    "    print(f'For calss1, F1_score = {(2*calss1_Precision*class1_Recall)/(calss1_Precision+class1_Recall)}')\n",
    "\n",
    "    #for class2\n",
    "    calss2_Precision = Confusion_Matrix_test[1][1]/(Confusion_Matrix_test[1][0]+Confusion_Matrix_test[1][1]+Confusion_Matrix_test[1][2])\n",
    "    class2_Recall = Confusion_Matrix_test[1][1]/(Confusion_Matrix_test[0][1]+Confusion_Matrix_test[1][1]+Confusion_Matrix_test[2][1])\n",
    "    print(f'For calss1, Precision = {calss2_Precision}')\n",
    "    print(f'For calss1, Recall = {class2_Recall}')\n",
    "    print(f'For calss1, F1_score = {(2*calss2_Precision*class2_Recall)/(calss2_Precision+class2_Recall)}')\n",
    "\n",
    "    #for class3\n",
    "    calss3_Precision = Confusion_Matrix_test[2][2]/(Confusion_Matrix_test[2][0]+Confusion_Matrix_test[2][1]+Confusion_Matrix_test[2][2])\n",
    "    class3_Recall = Confusion_Matrix_test[2][2]/(Confusion_Matrix_test[0][2]+Confusion_Matrix_test[1][2]+Confusion_Matrix_test[2][2])\n",
    "    print(f'For calss1, Precision = {calss3_Precision}')\n",
    "    print(f'For calss1, Recall = {class3_Recall}')\n",
    "    print(f'For calss1, F1_score = {(2*calss3_Precision*class3_Recall)/(calss3_Precision+class3_Recall)}')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 575,
   "id": "17846219-cb2d-4b93-8e16-d62a1107b4cb",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "W_int = [[-2.79410326e+00  2.86094243e+00 -3.33721350e-01 -1.05607658e+00\n",
      "  -5.06310314e-01 -1.90208597e-01 -9.56754646e-02]\n",
      " [ 3.47859367e+00 -7.92083238e-01 -4.40615652e-01  2.36467012e+00\n",
      "  -3.07809729e-01  6.16114554e-01 -3.96605412e-01]\n",
      " [ 9.25908557e-01 -2.54504156e-01  9.73645193e-02  4.86274602e-01\n",
      "   3.99490825e-01 -4.86118651e-01  2.03490942e-04]\n",
      " [ 1.50332871e+00 -1.31772503e+00 -4.16381061e-01  1.15473336e+00\n",
      "  -4.03168448e-01  1.82710787e-01 -3.98811378e-01]\n",
      " [ 1.37739079e+00  8.93313455e-01 -5.08358340e-01  7.15672379e-01\n",
      "  -1.01579381e-01 -2.49875773e-01 -2.99063027e-01]\n",
      " [-2.65842922e+00 -2.49908889e+00  1.82807638e-01 -3.03017744e+00\n",
      "  -3.29407189e-03  4.23113727e-01 -3.00547166e-01]\n",
      " [-2.75553033e+00 -2.89564993e+00  2.83280314e-01 -1.18626480e+00\n",
      "  -3.29580107e-03  2.71476529e-01 -2.99321781e-01]\n",
      " [ 1.56150101e+00  1.56150101e+00  1.56150101e+00  1.56150101e+00\n",
      "   1.56150101e+00  1.56150101e+00  1.56150101e+00]]\n",
      "W_out = [[ 2.59431271 -3.57457346  0.8029079 ]\n",
      " [ 2.07581077  3.92851387 -4.72583309]\n",
      " [ 0.09876414  0.19802303  0.40306642]\n",
      " [ 0.21142722 -0.31045295  0.11107769]\n",
      " [ 0.39978491 -0.10039715 -0.49943297]\n",
      " [-3.08794578 -1.18533853  2.54050808]\n",
      " [-0.29989316 -0.30044355 -0.29967489]\n",
      " [-0.70674344 -0.70674344 -0.70674344]]\n",
      "the epochs=100, final error = 5.143261137957557, accuracy = 0.9166666666666666\n",
      "Confusion_Matrix_test = [[16, 0, 2], [2, 19, 0], [1, 0, 20]]\n",
      "For calss1, Precision = 0.8888888888888888\n",
      "For calss1, Recall = 0.8421052631578947\n",
      "For calss1, F1_score = 0.8648648648648649\n",
      "For calss1, Precision = 0.9047619047619048\n",
      "For calss1, Recall = 1.0\n",
      "For calss1, F1_score = 0.9500000000000001\n",
      "For calss1, Precision = 0.9523809523809523\n",
      "For calss1, Recall = 0.9090909090909091\n",
      "For calss1, F1_score = 0.9302325581395349\n"
     ]
    }
   ],
   "source": [
    "test_testdate(test, W_in, W_out)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "6972f7ca-67f6-436a-8c6c-43efaf5807bb",
   "metadata": {},
   "source": [
    "Finally, We got a not bad accuracy Precision, Recall and F1_score on test dataset."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "17721d81-ce1b-4876-ba64-ae6472215987",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.11"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
