{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "78319767-47db-49d2-a38d-8d2f34183e15",
   "metadata": {},
   "source": [
    "## AIM-5007-1\n",
    "## By Zeyu Wang\n",
    "## Fall 2021\n",
    "## Mini Project"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "75aa6abe-a323-464f-ba54-0dfe6884941f",
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "import numpy as np"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "51b30475-b5b8-4977-9b1b-034a61e909e4",
   "metadata": {},
   "source": [
    "# 1. Load the data"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "30aeceab-7517-4e19-b9f9-198e8e477d45",
   "metadata": {},
   "source": [
    "This dataset comes from https://archive.ics.uci.edu/ml/datasets/seeds. There are 7 attributes and they are \n",
    "1. area A,\n",
    "2. perimeter P,\n",
    "3. compactness C = 4*pi*A/P^2,\n",
    "4. length of kernel,\n",
    "5. width of kernel,\n",
    "6. asymmetry coefficient\n",
    "7. length of kernel groove."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "613651b0-5146-4931-a27c-77e3dbfec9c0",
   "metadata": {},
   "outputs": [],
   "source": [
    "data = pd.read_csv('seeds_dataset.txt', header = None, delim_whitespace = True, dtype = 'float')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "21b7f96f-c3f0-415b-b827-626d948fc0cb",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>area</th>\n",
       "      <th>perimeter</th>\n",
       "      <th>compactness</th>\n",
       "      <th>length of kernel</th>\n",
       "      <th>width of kernel</th>\n",
       "      <th>asymmetry coefficient</th>\n",
       "      <th>length of kernel groove</th>\n",
       "      <th>Category</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>15.26</td>\n",
       "      <td>14.84</td>\n",
       "      <td>0.8710</td>\n",
       "      <td>5.763</td>\n",
       "      <td>3.312</td>\n",
       "      <td>2.221</td>\n",
       "      <td>5.220</td>\n",
       "      <td>1.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>14.88</td>\n",
       "      <td>14.57</td>\n",
       "      <td>0.8811</td>\n",
       "      <td>5.554</td>\n",
       "      <td>3.333</td>\n",
       "      <td>1.018</td>\n",
       "      <td>4.956</td>\n",
       "      <td>1.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>14.29</td>\n",
       "      <td>14.09</td>\n",
       "      <td>0.9050</td>\n",
       "      <td>5.291</td>\n",
       "      <td>3.337</td>\n",
       "      <td>2.699</td>\n",
       "      <td>4.825</td>\n",
       "      <td>1.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>13.84</td>\n",
       "      <td>13.94</td>\n",
       "      <td>0.8955</td>\n",
       "      <td>5.324</td>\n",
       "      <td>3.379</td>\n",
       "      <td>2.259</td>\n",
       "      <td>4.805</td>\n",
       "      <td>1.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>16.14</td>\n",
       "      <td>14.99</td>\n",
       "      <td>0.9034</td>\n",
       "      <td>5.658</td>\n",
       "      <td>3.562</td>\n",
       "      <td>1.355</td>\n",
       "      <td>5.175</td>\n",
       "      <td>1.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>...</th>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>205</th>\n",
       "      <td>12.19</td>\n",
       "      <td>13.20</td>\n",
       "      <td>0.8783</td>\n",
       "      <td>5.137</td>\n",
       "      <td>2.981</td>\n",
       "      <td>3.631</td>\n",
       "      <td>4.870</td>\n",
       "      <td>3.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>206</th>\n",
       "      <td>11.23</td>\n",
       "      <td>12.88</td>\n",
       "      <td>0.8511</td>\n",
       "      <td>5.140</td>\n",
       "      <td>2.795</td>\n",
       "      <td>4.325</td>\n",
       "      <td>5.003</td>\n",
       "      <td>3.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>207</th>\n",
       "      <td>13.20</td>\n",
       "      <td>13.66</td>\n",
       "      <td>0.8883</td>\n",
       "      <td>5.236</td>\n",
       "      <td>3.232</td>\n",
       "      <td>8.315</td>\n",
       "      <td>5.056</td>\n",
       "      <td>3.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>208</th>\n",
       "      <td>11.84</td>\n",
       "      <td>13.21</td>\n",
       "      <td>0.8521</td>\n",
       "      <td>5.175</td>\n",
       "      <td>2.836</td>\n",
       "      <td>3.598</td>\n",
       "      <td>5.044</td>\n",
       "      <td>3.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>209</th>\n",
       "      <td>12.30</td>\n",
       "      <td>13.34</td>\n",
       "      <td>0.8684</td>\n",
       "      <td>5.243</td>\n",
       "      <td>2.974</td>\n",
       "      <td>5.637</td>\n",
       "      <td>5.063</td>\n",
       "      <td>3.0</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>210 rows Ã— 8 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "      area  perimeter  compactness  length of kernel  width of kernel  \\\n",
       "0    15.26      14.84       0.8710             5.763            3.312   \n",
       "1    14.88      14.57       0.8811             5.554            3.333   \n",
       "2    14.29      14.09       0.9050             5.291            3.337   \n",
       "3    13.84      13.94       0.8955             5.324            3.379   \n",
       "4    16.14      14.99       0.9034             5.658            3.562   \n",
       "..     ...        ...          ...               ...              ...   \n",
       "205  12.19      13.20       0.8783             5.137            2.981   \n",
       "206  11.23      12.88       0.8511             5.140            2.795   \n",
       "207  13.20      13.66       0.8883             5.236            3.232   \n",
       "208  11.84      13.21       0.8521             5.175            2.836   \n",
       "209  12.30      13.34       0.8684             5.243            2.974   \n",
       "\n",
       "     asymmetry coefficient  length of kernel groove  Category  \n",
       "0                    2.221                    5.220       1.0  \n",
       "1                    1.018                    4.956       1.0  \n",
       "2                    2.699                    4.825       1.0  \n",
       "3                    2.259                    4.805       1.0  \n",
       "4                    1.355                    5.175       1.0  \n",
       "..                     ...                      ...       ...  \n",
       "205                  3.631                    4.870       3.0  \n",
       "206                  4.325                    5.003       3.0  \n",
       "207                  8.315                    5.056       3.0  \n",
       "208                  3.598                    5.044       3.0  \n",
       "209                  5.637                    5.063       3.0  \n",
       "\n",
       "[210 rows x 8 columns]"
      ]
     },
     "execution_count": 3,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "data.columns = ['area', 'perimeter', 'compactness', 'length of kernel', 'width of kernel', 'asymmetry coefficient', 'length of kernel groove', 'Category']\n",
    "data"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "92c0dcd5-cb4b-405f-b217-a37b3142c66a",
   "metadata": {},
   "source": [
    "# 2. Clean data\n",
    "In this part, we'll find out the nan and null data in the dataset and remove them."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "8d94f0fc-8909-4d7e-8524-baf161bda9d3",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "False"
      ]
     },
     "execution_count": 4,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "data.isna().values.any()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "500399cf-3983-425e-b2e8-47d0734c05eb",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "False"
      ]
     },
     "execution_count": 5,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "data.isnull().values.any()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "7a881360-596c-44b4-9879-08230c28d595",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "area                       0.0\n",
       "perimeter                  0.0\n",
       "compactness                0.0\n",
       "length of kernel           0.0\n",
       "width of kernel            0.0\n",
       "asymmetry coefficient      0.0\n",
       "length of kernel groove    0.0\n",
       "Category                   0.0\n",
       "dtype: float64"
      ]
     },
     "execution_count": 6,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "data[data==' '].sum()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "2119687a-328c-4f49-b6d8-69152a0b337b",
   "metadata": {},
   "source": [
    "In this dataset, there isn't any null and nan data."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "843e4ace-2eab-40b9-b674-8ff5baa0c991",
   "metadata": {},
   "source": [
    "# 3. Split into train and test dataset\n",
    "Here my idea is to use NumPy.random to pick up 150 data from the dataset and let them be trained data and then use np.setdiff1d to choose the rest of the data as the test data."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "8f65d299-b66d-41cf-a66e-e667e6c2120f",
   "metadata": {},
   "outputs": [],
   "source": [
    "#Because our network has three outputs, so we need to use one-hot encoding to encode the Category before splitting the data.\n",
    "one_hot = pd.get_dummies(data.Category)\n",
    "one_hot.columns = ['A', 'B', 'C']\n",
    "data = data.drop('Category', axis = 1)\n",
    "data = data.join(one_hot)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "f33afd30-2130-4ba1-9c40-6c2676250d5e",
   "metadata": {},
   "outputs": [],
   "source": [
    "np.random.seed(2022)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "id": "892a0ed2-3c07-444b-b930-dc97cfbe4fd4",
   "metadata": {},
   "outputs": [],
   "source": [
    "list_index = np.array([i for i in range(len(data))])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "id": "576c6b00-75e0-4e00-926e-fbed8fb12d40",
   "metadata": {},
   "outputs": [],
   "source": [
    "#I random choose 150 data from list_index and let them not replace\n",
    "train_index = np.random.choice(list_index, 150, replace = False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "id": "c087835b-88d6-4b7d-85eb-2e77ea8add5b",
   "metadata": {},
   "outputs": [],
   "source": [
    "#The rest of data as test data\n",
    "test_index = np.setdiff1d(list_index, train_index)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "cce7bbb9-1fa3-4d1f-a82f-9f27afe438c7",
   "metadata": {},
   "source": [
    "Reset index of training and testing data in order to avoid the error later"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "id": "20a5d59f-22dd-476d-a361-10e4ea070175",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>area</th>\n",
       "      <th>perimeter</th>\n",
       "      <th>compactness</th>\n",
       "      <th>length of kernel</th>\n",
       "      <th>width of kernel</th>\n",
       "      <th>asymmetry coefficient</th>\n",
       "      <th>length of kernel groove</th>\n",
       "      <th>A</th>\n",
       "      <th>B</th>\n",
       "      <th>C</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>19.38</td>\n",
       "      <td>16.72</td>\n",
       "      <td>0.8716</td>\n",
       "      <td>6.303</td>\n",
       "      <td>3.791</td>\n",
       "      <td>3.678</td>\n",
       "      <td>5.965</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>11.56</td>\n",
       "      <td>13.31</td>\n",
       "      <td>0.8198</td>\n",
       "      <td>5.363</td>\n",
       "      <td>2.683</td>\n",
       "      <td>4.062</td>\n",
       "      <td>5.182</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>14.80</td>\n",
       "      <td>14.52</td>\n",
       "      <td>0.8823</td>\n",
       "      <td>5.656</td>\n",
       "      <td>3.288</td>\n",
       "      <td>3.112</td>\n",
       "      <td>5.309</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>12.67</td>\n",
       "      <td>13.32</td>\n",
       "      <td>0.8977</td>\n",
       "      <td>4.984</td>\n",
       "      <td>3.135</td>\n",
       "      <td>2.300</td>\n",
       "      <td>4.745</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>11.02</td>\n",
       "      <td>13.00</td>\n",
       "      <td>0.8189</td>\n",
       "      <td>5.325</td>\n",
       "      <td>2.701</td>\n",
       "      <td>6.735</td>\n",
       "      <td>5.163</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "    area  perimeter  compactness  length of kernel  width of kernel  \\\n",
       "0  19.38      16.72       0.8716             6.303            3.791   \n",
       "1  11.56      13.31       0.8198             5.363            2.683   \n",
       "2  14.80      14.52       0.8823             5.656            3.288   \n",
       "3  12.67      13.32       0.8977             4.984            3.135   \n",
       "4  11.02      13.00       0.8189             5.325            2.701   \n",
       "\n",
       "   asymmetry coefficient  length of kernel groove  A  B  C  \n",
       "0                  3.678                    5.965  0  1  0  \n",
       "1                  4.062                    5.182  0  0  1  \n",
       "2                  3.112                    5.309  1  0  0  \n",
       "3                  2.300                    4.745  0  0  1  \n",
       "4                  6.735                    5.163  0  0  1  "
      ]
     },
     "execution_count": 12,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "train = data.loc[train_index]\n",
    "train = train.reset_index(drop = True)\n",
    "train.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "id": "e933d2c6-e7bd-42e7-8529-f07f14f57e66",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>area</th>\n",
       "      <th>perimeter</th>\n",
       "      <th>compactness</th>\n",
       "      <th>length of kernel</th>\n",
       "      <th>width of kernel</th>\n",
       "      <th>asymmetry coefficient</th>\n",
       "      <th>length of kernel groove</th>\n",
       "      <th>A</th>\n",
       "      <th>B</th>\n",
       "      <th>C</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>14.03</td>\n",
       "      <td>14.16</td>\n",
       "      <td>0.8796</td>\n",
       "      <td>5.438</td>\n",
       "      <td>3.201</td>\n",
       "      <td>1.717</td>\n",
       "      <td>5.001</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>13.89</td>\n",
       "      <td>14.02</td>\n",
       "      <td>0.8880</td>\n",
       "      <td>5.439</td>\n",
       "      <td>3.199</td>\n",
       "      <td>3.986</td>\n",
       "      <td>4.738</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>13.78</td>\n",
       "      <td>14.06</td>\n",
       "      <td>0.8759</td>\n",
       "      <td>5.479</td>\n",
       "      <td>3.156</td>\n",
       "      <td>3.136</td>\n",
       "      <td>4.872</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>14.59</td>\n",
       "      <td>14.28</td>\n",
       "      <td>0.8993</td>\n",
       "      <td>5.351</td>\n",
       "      <td>3.333</td>\n",
       "      <td>4.185</td>\n",
       "      <td>4.781</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>13.99</td>\n",
       "      <td>13.83</td>\n",
       "      <td>0.9183</td>\n",
       "      <td>5.119</td>\n",
       "      <td>3.383</td>\n",
       "      <td>5.234</td>\n",
       "      <td>4.781</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "    area  perimeter  compactness  length of kernel  width of kernel  \\\n",
       "0  14.03      14.16       0.8796             5.438            3.201   \n",
       "1  13.89      14.02       0.8880             5.439            3.199   \n",
       "2  13.78      14.06       0.8759             5.479            3.156   \n",
       "3  14.59      14.28       0.8993             5.351            3.333   \n",
       "4  13.99      13.83       0.9183             5.119            3.383   \n",
       "\n",
       "   asymmetry coefficient  length of kernel groove  A  B  C  \n",
       "0                  1.717                    5.001  1  0  0  \n",
       "1                  3.986                    4.738  1  0  0  \n",
       "2                  3.136                    4.872  1  0  0  \n",
       "3                  4.185                    4.781  1  0  0  \n",
       "4                  5.234                    4.781  1  0  0  "
      ]
     },
     "execution_count": 13,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "test = data.loc[test_index]\n",
    "test = test.reset_index(drop = True)\n",
    "test.head()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "5247c981-63a7-411b-af1b-00f495589263",
   "metadata": {},
   "source": [
    "# 4.Build model"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "4e7948c7-984f-4a89-9fc1-7edb792b55a5",
   "metadata": {},
   "source": [
    "I copy some code from my homework3 and use them to form a complete model. This function includes initiating weight, calculating output, gradient, and so on."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "id": "29881082-379e-4289-b6a8-d04747fbbb8b",
   "metadata": {},
   "outputs": [],
   "source": [
    "def weight(inputs, hiddends, outputs):\n",
    "    '''\n",
    "    This function will create  weights for DL and you need to give it the numbers of input, hiddents and outputs.\n",
    "    -------------------------------------------------------------------------------------------------\n",
    "    This function will return you two matrix that including the weight_input and weight_output\n",
    "    '''\n",
    "    W_int = np.random.randint(-5, 5, (inputs,hiddends))/10\n",
    "    bias_input = list(np.random.random(1))\n",
    "    bias_inputs = np.array(bias_input*hiddends)\n",
    "    W_int = np.concatenate((W_int, [bias_inputs]), axis=0)\n",
    "    \n",
    "    W_out = np.random.randint(-5, 5, (hiddends,outputs))/10\n",
    "    bias_out = list(np.random.random(1))\n",
    "    bias_outs = np.array(bias_out*outputs)\n",
    "    W_out = np.concatenate((W_out, [bias_outs]), axis=0)\n",
    "    return W_int, W_out"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "id": "11a9712b-ecda-4e4f-aaa2-179f61b4f000",
   "metadata": {},
   "outputs": [],
   "source": [
    "def appendVector(vector):\n",
    "    '''\n",
    "    This function is used to extend 1 dimension for vector.\n",
    "    '''\n",
    "    vector1 = vector.copy()\n",
    "    vector1.append(1)\n",
    "    return vector1"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "id": "268e0c4b-8f73-4e9b-adc1-ff1913ff889e",
   "metadata": {},
   "outputs": [],
   "source": [
    "def obtainRawHidden(W_int, W_out, inpis):\n",
    "    '''\n",
    "    This function is used to calculate the hidden layer's raw data in a network.\n",
    "    '''\n",
    "    inputs_nodes = len(inpis)\n",
    "    append_f = np.array(appendVector(inpis))\n",
    "    hraw = append_f.T@W_int\n",
    "    return hraw"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "id": "cce125f4-983a-4ad2-bf50-bde6aa601852",
   "metadata": {},
   "outputs": [],
   "source": [
    "'''Actually, this function is tanh.'''\n",
    "def sigmoidFun(raw):\n",
    "    '''\n",
    "    This function is the activate function that is used to transfer the raw data to out data.\n",
    "    '''\n",
    "    return (np.exp(raw)-np.exp(-raw))/(np.exp(raw)+np.exp(-raw))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "id": "f3a6ad0a-8f27-4240-a22b-7d64aa8b6b69",
   "metadata": {},
   "outputs": [],
   "source": [
    "def obtainOutput(W_int, W_out, inpis):\n",
    "    '''\n",
    "    This function will be used to calculate the function final output by using the output of hidden layer data times the weight.\n",
    "    '''\n",
    "    hraw = obtainRawHidden(W_int, W_out, inpis)\n",
    "    hact = sigmoidFun(hraw)\n",
    "    hact1 = np.array(appendVector(list(hact)))\n",
    "    outraw = hact1.T@W_out\n",
    "    out = sigmoidFun(outraw)\n",
    "    return out, hact"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "id": "73fb6afc-b3f1-4459-80bf-d17064028de3",
   "metadata": {},
   "outputs": [],
   "source": [
    "def gradient_E_Wjk(output, targk, hact):\n",
    "    '''\n",
    "    This function will be used to calculate the gradient of weight between the hidden layer and output.\n",
    "    '''\n",
    "    gradient_out = []\n",
    "    gradient_a = (output-targk)*(1-(output**2))\n",
    "    for i in gradient_a:\n",
    "        gradient_out.append(i*hact)\n",
    "    gradient_out = np.array(gradient_out)\n",
    "    gradient_out = gradient_out.T\n",
    "    return gradient_out"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "id": "b600a97b-5ea3-4ff4-9270-a22a4a7040ca",
   "metadata": {},
   "outputs": [],
   "source": [
    "def gradient_E_biasO(output, targk):\n",
    "    '''\n",
    "    This function is used to calculate the gradient of bias between the hidden layer and output.\n",
    "    '''\n",
    "    gradient_a = ((output-targk)*(1-(output**2))).sum()\n",
    "    return gradient_a"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "id": "6da04a21-0b2b-46d9-9609-46e380214084",
   "metadata": {},
   "outputs": [],
   "source": [
    "def gradient_E_wij(output, targk, W_out, hact, inpis):\n",
    "    '''\n",
    "    This function will be used to calculate the gradient of weight between the input and hidden layer.\n",
    "    '''\n",
    "    gradient_a = ((output-targk)*(1-(output**2))*W_out).sum()*(1-(hact**2))\n",
    "    \n",
    "    gradient_int = []\n",
    "    int_np = np.array(inpis)\n",
    "    for i in gradient_a:\n",
    "        gradient_int.append(i*int_np)\n",
    "    gradient_int = np.array(gradient_int)\n",
    "    gradient_int = gradient_int.T\n",
    "    return gradient_int"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "id": "db51463a-e8ea-4232-9024-a3cbf8fff57d",
   "metadata": {},
   "outputs": [],
   "source": [
    "def gradient_E_biasH(output, targk, W_out, hact):\n",
    "    '''\n",
    "    This function is used to calculate the gradient of bias between the input and hidden layer.\n",
    "    '''\n",
    "    gradient_a = (((output-targk)*(1-(output**2))*W_out).sum()*(1-(hact**2))).sum()\n",
    "    return gradient_a"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "id": "753befb0-720b-48af-b50b-076cb7ae1615",
   "metadata": {},
   "outputs": [],
   "source": [
    "def update_wij(output, targk, W_out, hact, W_int, inpis, alpha):\n",
    "    '''\n",
    "    This function will be used to update the weight between the input and hidden layer.\n",
    "    '''\n",
    "    g_e_biasH_list = []\n",
    "    g_E_wij = gradient_E_wij(output, targk, W_out, hact, inpis)\n",
    "    g_E_biasH = gradient_E_biasH(output, targk, W_out, hact)\n",
    "    g_E_wij_rows, g_E_wij_columns = g_E_wij.shape\n",
    "    g_e_biasH_list.append(g_E_biasH)\n",
    "    g_e_biasH_list = g_e_biasH_list*g_E_wij_columns\n",
    "    g_E_ij = np.concatenate((g_E_wij, [g_e_biasH_list]), axis = 0)\n",
    "    new_wij = W_int-alpha*g_E_ij\n",
    "    return new_wij"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "id": "5ca1a43c-3ef6-4735-ae68-e7dd01e8ae51",
   "metadata": {},
   "outputs": [],
   "source": [
    "def update_Wjk(output, targk, hact, W_out, alpha):\n",
    "    '''\n",
    "    This function will be used to update the weight between the hidden layer and output.\n",
    "    '''\n",
    "    g_e_biasO_list = []\n",
    "    g_E_Wjk = gradient_E_Wjk(output, targk, hact)\n",
    "    g_E_biasO = gradient_E_biasO(output, targk)\n",
    "    g_E_Wjk_rows, g_E_Wjk_columns = g_E_Wjk.shape\n",
    "    g_e_biasO_list.append(g_E_biasO)\n",
    "    g_e_biasO_list = g_e_biasO_list*g_E_Wjk_columns\n",
    "    g_E_jk = np.concatenate((g_E_Wjk, [g_e_biasO_list]), axis = 0)\n",
    "    new_Wjk = W_out-alpha*g_E_jk\n",
    "    return new_Wjk"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 29,
   "id": "7de20dad-f59f-4786-881f-d792aa85e8fa",
   "metadata": {},
   "outputs": [],
   "source": [
    "def encode_output(output):\n",
    "    '''\n",
    "    This function is used to encode the output and let they become the one-hot encoding.\n",
    "    In this function, the highest values will become 1 and the others become 0\n",
    "    '''\n",
    "    new_output = []\n",
    "    maximun_index = np.argmax(np.array(output))\n",
    "    for i in range(len(output)):\n",
    "        if i==maximun_index:\n",
    "            new_output.append(1)\n",
    "        else:\n",
    "            new_output.append(0)\n",
    "    return new_output"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 30,
   "id": "3e8ea68a-a61c-4258-bf36-3f88e4f69860",
   "metadata": {},
   "outputs": [],
   "source": [
    "def createOutput_pandas(data_dl, W_int, W_out, inpis):\n",
    "    '''\n",
    "    This is function will be used to create a big output panda.\n",
    "    In this function, I will calculate the output and then put them back to the pandas \n",
    "    and use Out_A, Out_B and Out_C as the new columns.\n",
    "    '''\n",
    "    #save data\n",
    "    output_data = data_dl.copy()\n",
    "    \n",
    "    #Save output data\n",
    "    Out_A = []\n",
    "    Out_B = []\n",
    "    Out_C = []\n",
    "    hact_list = []\n",
    "    \n",
    "    #calculate output\n",
    "    for i in range(len(data_dl)):\n",
    "        inpis = list(data_dl.iloc[i,:-3])\n",
    "        out, hact = obtainOutput(W_int, W_out, inpis)\n",
    "        #Use one-hot encoding to encode the output\n",
    "        out_onehot = encode_output(out)\n",
    "        Out_A.append(out[0])\n",
    "        Out_B.append(out[1])\n",
    "        Out_C.append(out[2])\n",
    "        hact_list.append(hact)\n",
    "    output_data['Out_A'] = Out_A\n",
    "    output_data['Out_B'] = Out_B\n",
    "    output_data['Out_C'] = Out_C\n",
    "    output_data['hact_list'] = hact_list\n",
    "    output_data['error'] = 0.5*(((output_data.Out_A-output_data.A)**2)+((output_data.Out_B-output_data.B)**2)+((output_data.Out_C-output_data.C)**2))\n",
    "    \n",
    "    return output_data"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "85449cd3-7877-4ed4-b827-519dacbf662a",
   "metadata": {},
   "source": [
    "# 5. Train model"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "46efeab2-3b9f-488f-8290-51d1d3f41932",
   "metadata": {},
   "source": [
    "Here is to start to combine several functions above and train the training data. By the way, the model has the best performance with the hyperparameter alpha = 0.06, hidden_nodes = 7 and output_nodes = 3. But this model still has a probability to fail in train and I suppose maybe there is an outlier in the data and needs to be removed. But this model will have a about 1/3 probability to run successfully. And the best error is greater than 11 and the higher accuracy is less than 92. The fail running means is the model is hard to convergence."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "cc6499da-b442-4061-842e-e5910cbd6042",
   "metadata": {},
   "source": [
    "In this process, I will imitate the perception algorithm. Firstly, I will randomly pick up data to calculate and the result. Then use this result to calculate gradient, output, and error. Then calculate all other rows data's predict output. Select those data that are different from the target data. Randomly choose one of the rows of data from this error prediction result data and use this row data to calculate and update the weight. Calculate the accuracy after each 100 training process. If the accuracy, steps, and error meet the requirement, stop training and output the weight of the input and hidden layer. Then use this weight list to test and calculate some information about the test."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 31,
   "id": "181ad858-6569-4903-a532-229c41eb9cf2",
   "metadata": {},
   "outputs": [],
   "source": [
    "def DeelLearning(data_dl, alpha):\n",
    "    '''\n",
    "    This function will use all of the functions above to learning and update the weight.\n",
    "    -------------------------------------------------------------------------------------\n",
    "    This function will return the two new weights. We can use these two weights to predict.\n",
    "    '''\n",
    "    # Hyperparameter\n",
    "    hidden_nodes = 7\n",
    "    output_nodes = 3\n",
    "    #alpha = 0.04 error>30\n",
    "    #alpha = 0.06 error>11 accuracy <92\n",
    "    #alpha = 0.08 error>29\n",
    "    alpha = alpha\n",
    "    \n",
    "    ##get target list\n",
    "    onehot_targe_list = []\n",
    "    for i in range(len(data_dl)):\n",
    "        targe_onthot = data_dl.iloc[i, -3:]\n",
    "        onehot_targe_list.append(list(targe_onthot))\n",
    "    onehot_targe_list = np.array(onehot_targe_list)\n",
    "    \n",
    "    # randomly extract data from dataset and use it to start\n",
    "    randon_data = data_dl.sample().values[0]\n",
    "    targk = list(randon_data[-3:])\n",
    "    inpis = list(randon_data[:-3])\n",
    "    inputs_nodes = len(inpis)\n",
    "    \n",
    "    #Get the first weight of input and hidden layer\n",
    "    W_int, W_out = weight(inputs_nodes, hidden_nodes, output_nodes)\n",
    "    \n",
    "    #calculate the output data\n",
    "    output_data = createOutput_pandas(data_dl, W_int, W_out, inpis)\n",
    "    \n",
    "    #Calculate_error\n",
    "    error = output_data.error.sum()\n",
    "    \n",
    "    step = 1\n",
    "    accuracy = 0\n",
    "    # If the error>3 and doesn't reach 100000 and accuracy less than 0.9, keep training\n",
    "    while error>3 and step<100000 and accuracy<.90 and step != 9600:\n",
    "        #Pick up data which its result is incorrect\n",
    "        incorrct_result = output_data[output_data.error!=0]\n",
    "        incorrct_result = incorrct_result.reset_index(drop = True)\n",
    "        \n",
    "        #Random pick up one row incorrect result data\n",
    "        one_row_data = incorrct_result.sample().values[0]\n",
    "        #Extract input and output\n",
    "        targk = list(one_row_data[7:10])\n",
    "        inpis = list(one_row_data[:7])\n",
    "        hact = one_row_data[-2]\n",
    "        out = []\n",
    "        out.append(one_row_data[-5])\n",
    "        out.append(one_row_data[-4])\n",
    "        out.append(one_row_data[-3])\n",
    "        \n",
    "        #update weight and bias\n",
    "        new_wij = update_wij(np.array(out), np.array(targk), W_out, hact, W_int, inpis, alpha)\n",
    "        new_Wjk = update_Wjk(np.array(out), np.array(targk), hact, W_out, alpha)\n",
    "        W_int, W_out = new_wij, new_Wjk\n",
    "        \n",
    "        #Get calculate output result and calculate the error\n",
    "        output_data = createOutput_pandas(data_dl, W_int, W_out, inpis)\n",
    "        error = output_data.error.sum()\n",
    "        step+=1\n",
    "        \n",
    "        #calculate accuracy and print accuracy after each 100 trainning, so the epoch=100\n",
    "        if step%100 == 0:\n",
    "            #calculate accuray\n",
    "            ##get onehot output\n",
    "            onehot_output_list = []\n",
    "            for i in range(len(output_data)):\n",
    "                out_onthot = output_data.iloc[i, -5:-2]\n",
    "                out_onthot = encode_output(out_onthot)\n",
    "                onehot_output_list.append(out_onthot)\n",
    "            compare_list = np.equal(onehot_targe_list,onehot_output_list)\n",
    "            compare_result = []\n",
    "            for i in compare_list:\n",
    "                if list(i)==[True, True, True]:\n",
    "                    compare_result.append(1)\n",
    "                else:\n",
    "                    compare_result.append(0)\n",
    "            compare_result = np.array(compare_result)\n",
    "            accuracy = len(compare_result[compare_result==1])/len(compare_result)\n",
    "            print(f'Train {step} steps, the epochs={np.round(step/len(output_data))}, error = {error/len(output_data)}, accuracy = {accuracy}')\n",
    "            #print(f'error = {error}, accuracy = {accuracy}')\n",
    "            \n",
    "    #If the accuracy>=0.9, calculate its Confusion Matrix, Precision, Recall and F1 score\n",
    "    if accuracy>=0.9:\n",
    "        Confusion_Matrix_test = [[0, 0, 0],[0, 0, 0], [0, 0, 0]]\n",
    "        for i in range(len(onehot_targe_list)):\n",
    "            if onehot_targe_list[i][0]==1:\n",
    "                if onehot_output_list[i][0] == 1:\n",
    "                    Confusion_Matrix_test[0][0]+=1\n",
    "                elif onehot_output_list[i][1] == 1:\n",
    "                    Confusion_Matrix_test[0][1]+=1\n",
    "                else:\n",
    "                    Confusion_Matrix_test[0][2]+=1\n",
    "            elif onehot_targe_list[i][1]==1:\n",
    "                if onehot_output_list[i][0] == 1:\n",
    "                    Confusion_Matrix_test[1][0]+=1\n",
    "                elif onehot_output_list[i][1] == 1:\n",
    "                    Confusion_Matrix_test[1][1]+=1\n",
    "                else:\n",
    "                    Confusion_Matrix_test[1][2]+=1\n",
    "            elif onehot_targe_list[i][2]==1:\n",
    "                if onehot_output_list[i][0] == 1:\n",
    "                    Confusion_Matrix_test[2][0]+=1\n",
    "                elif onehot_output_list[i][1] == 1:\n",
    "                    Confusion_Matrix_test[2][1]+=1\n",
    "                else:\n",
    "                    Confusion_Matrix_test[2][2]+=1\n",
    "            \n",
    "        print(f'W_int = {W_int}, W_out = {W_out}')\n",
    "        print(f'Train {step} steps, the epochs={np.round(step/len(output_data))}, final error = {error/len(output_data)}, accuracy = {accuracy}')\n",
    "        print(f'Confusion_Matrix_test = {Confusion_Matrix_test}')\n",
    "        #for class1\n",
    "        calss1_Precision = Confusion_Matrix_test[0][0]/(Confusion_Matrix_test[0][0]+Confusion_Matrix_test[0][1]+Confusion_Matrix_test[0][2])\n",
    "        class1_Recall = Confusion_Matrix_test[0][0]/(Confusion_Matrix_test[0][0]+Confusion_Matrix_test[1][0]+Confusion_Matrix_test[2][0])\n",
    "        print(f'For calss1, Precision = {calss1_Precision}')\n",
    "        print(f'For calss1, Recall = {class1_Recall}')\n",
    "        print(f'For calss1, F1_score = {(2*calss1_Precision*class1_Recall)/(calss1_Precision+class1_Recall)}')\n",
    "        \n",
    "        #for class2\n",
    "        calss2_Precision = Confusion_Matrix_test[1][1]/(Confusion_Matrix_test[1][0]+Confusion_Matrix_test[1][1]+Confusion_Matrix_test[1][2])\n",
    "        class2_Recall = Confusion_Matrix_test[1][1]/(Confusion_Matrix_test[0][1]+Confusion_Matrix_test[1][1]+Confusion_Matrix_test[2][1])\n",
    "        print(f'For calss1, Precision = {calss2_Precision}')\n",
    "        print(f'For calss1, Recall = {class2_Recall}')\n",
    "        print(f'For calss1, F1_score = {(2*calss2_Precision*class2_Recall)/(calss2_Precision+class2_Recall)}')\n",
    "        \n",
    "        #for class3\n",
    "        calss3_Precision = Confusion_Matrix_test[2][2]/(Confusion_Matrix_test[2][0]+Confusion_Matrix_test[2][1]+Confusion_Matrix_test[2][2])\n",
    "        class3_Recall = Confusion_Matrix_test[2][2]/(Confusion_Matrix_test[0][2]+Confusion_Matrix_test[1][2]+Confusion_Matrix_test[2][2])\n",
    "        print(f'For calss1, Precision = {calss3_Precision}')\n",
    "        print(f'For calss1, Recall = {class3_Recall}')\n",
    "        print(f'For calss1, F1_score = {(2*calss3_Precision*class3_Recall)/(calss3_Precision+class3_Recall)}')\n",
    "        \n",
    "    return W_int, W_out"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 32,
   "id": "02f929a0-cc16-4990-96db-90949aabf1fc",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Train 100 steps, the epochs=1.0, error = 0.41516119438085275, accuracy = 0.34\n",
      "Train 200 steps, the epochs=1.0, error = 0.4439101715933911, accuracy = 0.32\n",
      "Train 300 steps, the epochs=2.0, error = 0.4240515427184368, accuracy = 0.34\n",
      "Train 400 steps, the epochs=3.0, error = 0.42108599884073794, accuracy = 0.32\n",
      "Train 500 steps, the epochs=3.0, error = 0.40397264933365434, accuracy = 0.32\n",
      "Train 600 steps, the epochs=4.0, error = 0.44804137734061783, accuracy = 0.32\n",
      "Train 700 steps, the epochs=5.0, error = 0.4377080662284645, accuracy = 0.32\n",
      "Train 800 steps, the epochs=5.0, error = 0.35044925928557585, accuracy = 0.34\n",
      "Train 900 steps, the epochs=6.0, error = 0.37092942403193585, accuracy = 0.34\n",
      "Train 1000 steps, the epochs=7.0, error = 0.34409540786879234, accuracy = 0.34\n",
      "Train 1100 steps, the epochs=7.0, error = 0.3509305780462663, accuracy = 0.34\n",
      "Train 1200 steps, the epochs=8.0, error = 0.34862827687326586, accuracy = 0.34\n",
      "Train 1300 steps, the epochs=9.0, error = 0.4209700952770474, accuracy = 0.34\n",
      "Train 1400 steps, the epochs=9.0, error = 0.40548654732025907, accuracy = 0.32\n",
      "Train 1500 steps, the epochs=10.0, error = 0.36170055556971825, accuracy = 0.32\n",
      "Train 1600 steps, the epochs=11.0, error = 0.35824473512409083, accuracy = 0.34\n",
      "Train 1700 steps, the epochs=11.0, error = 0.4520066305777643, accuracy = 0.32\n",
      "Train 1800 steps, the epochs=12.0, error = 0.44515131799001495, accuracy = 0.32\n",
      "Train 1900 steps, the epochs=13.0, error = 0.3861885159501541, accuracy = 0.34\n",
      "Train 2000 steps, the epochs=13.0, error = 0.35932628275472406, accuracy = 0.34\n",
      "Train 2100 steps, the epochs=14.0, error = 0.43288441371607583, accuracy = 0.32\n",
      "Train 2200 steps, the epochs=15.0, error = 0.40231749951788404, accuracy = 0.34\n",
      "Train 2300 steps, the epochs=15.0, error = 0.4308629805916073, accuracy = 0.34\n",
      "Train 2400 steps, the epochs=16.0, error = 0.3602220392829372, accuracy = 0.34\n",
      "Train 2500 steps, the epochs=17.0, error = 0.41970436258781957, accuracy = 0.32\n",
      "Train 2600 steps, the epochs=17.0, error = 0.40839806413819674, accuracy = 0.32\n",
      "Train 2700 steps, the epochs=18.0, error = 0.3860830427758298, accuracy = 0.34\n",
      "Train 2800 steps, the epochs=19.0, error = 0.47356663590798465, accuracy = 0.34\n",
      "Train 2900 steps, the epochs=19.0, error = 0.36221034446117834, accuracy = 0.32\n",
      "Train 3000 steps, the epochs=20.0, error = 0.38038100115585094, accuracy = 0.34\n",
      "Train 3100 steps, the epochs=21.0, error = 0.3852368276866352, accuracy = 0.34\n",
      "Train 3200 steps, the epochs=21.0, error = 0.3608021584441762, accuracy = 0.34\n",
      "Train 3300 steps, the epochs=22.0, error = 0.3485716957017036, accuracy = 0.34\n",
      "Train 3400 steps, the epochs=23.0, error = 0.348107529415214, accuracy = 0.32\n",
      "Train 3500 steps, the epochs=23.0, error = 0.3730263036281814, accuracy = 0.34\n",
      "Train 3600 steps, the epochs=24.0, error = 0.3947018762227408, accuracy = 0.34\n",
      "Train 3700 steps, the epochs=25.0, error = 0.42086788543632964, accuracy = 0.34\n",
      "Train 3800 steps, the epochs=25.0, error = 0.4198388709338964, accuracy = 0.32\n",
      "Train 3900 steps, the epochs=26.0, error = 0.4098795982209873, accuracy = 0.34\n",
      "Train 4000 steps, the epochs=27.0, error = 0.4038434912562483, accuracy = 0.34\n",
      "Train 4100 steps, the epochs=27.0, error = 0.3654439110312823, accuracy = 0.34\n",
      "Train 4200 steps, the epochs=28.0, error = 0.3811635418227885, accuracy = 0.32\n",
      "Train 4300 steps, the epochs=29.0, error = 0.3520535443055452, accuracy = 0.34\n",
      "Train 4400 steps, the epochs=29.0, error = 0.37373933356086175, accuracy = 0.34\n",
      "Train 4500 steps, the epochs=30.0, error = 0.4141217182935608, accuracy = 0.34\n",
      "Train 4600 steps, the epochs=31.0, error = 0.4064784823588832, accuracy = 0.34\n",
      "Train 4700 steps, the epochs=31.0, error = 0.42837544905537916, accuracy = 0.34\n",
      "Train 4800 steps, the epochs=32.0, error = 0.395428117869308, accuracy = 0.32\n",
      "Train 4900 steps, the epochs=33.0, error = 0.34952531481701393, accuracy = 0.32\n",
      "Train 5000 steps, the epochs=33.0, error = 0.3933519110588291, accuracy = 0.32\n",
      "Train 5100 steps, the epochs=34.0, error = 0.3768661641433693, accuracy = 0.34\n",
      "Train 5200 steps, the epochs=35.0, error = 0.34519152707992967, accuracy = 0.34\n",
      "Train 5300 steps, the epochs=35.0, error = 0.42552855239926096, accuracy = 0.34\n",
      "Train 5400 steps, the epochs=36.0, error = 0.34718123364195225, accuracy = 0.34\n",
      "Train 5500 steps, the epochs=37.0, error = 0.44457495255312796, accuracy = 0.32\n",
      "Train 5600 steps, the epochs=37.0, error = 0.3762473310593676, accuracy = 0.34\n",
      "Train 5700 steps, the epochs=38.0, error = 0.34953669400815535, accuracy = 0.34\n",
      "Train 5800 steps, the epochs=39.0, error = 0.3522996747260546, accuracy = 0.34\n",
      "Train 5900 steps, the epochs=39.0, error = 0.41664932430291585, accuracy = 0.34\n",
      "Train 6000 steps, the epochs=40.0, error = 0.3688310297065328, accuracy = 0.34\n",
      "Train 6100 steps, the epochs=41.0, error = 0.3528407128653417, accuracy = 0.34\n",
      "Train 6200 steps, the epochs=41.0, error = 0.44368473627351535, accuracy = 0.32\n",
      "Train 6300 steps, the epochs=42.0, error = 0.37498159665051123, accuracy = 0.32\n",
      "Train 6400 steps, the epochs=43.0, error = 0.4413819700981564, accuracy = 0.34\n",
      "Train 6500 steps, the epochs=43.0, error = 0.3902609964688711, accuracy = 0.32\n",
      "Train 6600 steps, the epochs=44.0, error = 0.37610985316451573, accuracy = 0.32\n",
      "Train 6700 steps, the epochs=45.0, error = 0.37929647274136946, accuracy = 0.32\n",
      "Train 6800 steps, the epochs=45.0, error = 0.4076485412025473, accuracy = 0.34\n",
      "Train 6900 steps, the epochs=46.0, error = 0.4167447456895623, accuracy = 0.32\n",
      "Train 7000 steps, the epochs=47.0, error = 0.4385305396470318, accuracy = 0.34\n",
      "Train 7100 steps, the epochs=47.0, error = 0.38604218984979716, accuracy = 0.32\n",
      "Train 7200 steps, the epochs=48.0, error = 0.3631055886375352, accuracy = 0.32\n",
      "Train 7300 steps, the epochs=49.0, error = 0.43323582632092383, accuracy = 0.34\n",
      "Train 7400 steps, the epochs=49.0, error = 0.3774382833140437, accuracy = 0.34\n",
      "Train 7500 steps, the epochs=50.0, error = 0.41554997058336424, accuracy = 0.34\n",
      "Train 7600 steps, the epochs=51.0, error = 0.4623787341689203, accuracy = 0.34\n",
      "Train 7700 steps, the epochs=51.0, error = 0.3500221061670205, accuracy = 0.34\n",
      "Train 7800 steps, the epochs=52.0, error = 0.44319227009153894, accuracy = 0.34\n",
      "Train 7900 steps, the epochs=53.0, error = 0.3888194394354807, accuracy = 0.32\n",
      "Train 8000 steps, the epochs=53.0, error = 0.36334863585993643, accuracy = 0.34\n",
      "Train 8100 steps, the epochs=54.0, error = 0.42770214373225135, accuracy = 0.34\n",
      "Train 8200 steps, the epochs=55.0, error = 0.4144383877387298, accuracy = 0.34\n",
      "Train 8300 steps, the epochs=55.0, error = 0.39794617435493784, accuracy = 0.34\n",
      "Train 8400 steps, the epochs=56.0, error = 0.44057910632700287, accuracy = 0.34\n",
      "Train 8500 steps, the epochs=57.0, error = 0.42230773751914047, accuracy = 0.32\n",
      "Train 8600 steps, the epochs=57.0, error = 0.35946615836283524, accuracy = 0.32\n",
      "Train 8700 steps, the epochs=58.0, error = 0.37444134435935383, accuracy = 0.34\n",
      "Train 8800 steps, the epochs=59.0, error = 0.5072201512964316, accuracy = 0.32\n",
      "Train 8900 steps, the epochs=59.0, error = 0.4189065623805627, accuracy = 0.34\n",
      "Train 9000 steps, the epochs=60.0, error = 0.41859610742815256, accuracy = 0.32\n",
      "Train 9100 steps, the epochs=61.0, error = 0.43912962233568387, accuracy = 0.34\n",
      "Train 9200 steps, the epochs=61.0, error = 0.4644489307724402, accuracy = 0.34\n",
      "Train 9300 steps, the epochs=62.0, error = 0.4636842836688597, accuracy = 0.32\n",
      "Train 9400 steps, the epochs=63.0, error = 0.4154358570506471, accuracy = 0.34\n",
      "Train 9500 steps, the epochs=63.0, error = 0.3960319715867203, accuracy = 0.34\n",
      "Train 9600 steps, the epochs=64.0, error = 0.3726985806778181, accuracy = 0.34\n"
     ]
    }
   ],
   "source": [
    "W_in, W_out = DeelLearning(train, alpha = 0.06)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "0534de9d-be72-405a-83e8-cc6e7ddd7dd1",
   "metadata": {},
   "source": [
    "# 6. Test the testing data"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "dbaa7284-5c87-4564-880e-bd74ef971549",
   "metadata": {},
   "source": [
    "After I ran part 5, I got the weight of the input and hidden layer. I used these parameters to calculate the output result of the test dataset. "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 99,
   "id": "dbf11944-0f57-45d6-803a-ce0ee42cd5ed",
   "metadata": {},
   "outputs": [],
   "source": [
    "def test_testdate(test, W_int, W_out):\n",
    "    hidden_nodes = 7\n",
    "    output_nodes = 3\n",
    "    output_data = createOutput_pandas(test, W_int, W_out, 1)\n",
    "    error = output_data.error.sum()\n",
    "    \n",
    "    ##get target data list from test dataset \n",
    "    onehot_targe_list = []\n",
    "    for i in range(len(test)):\n",
    "        targe_onthot = test.iloc[i, -3:]\n",
    "        onehot_targe_list.append(list(targe_onthot))\n",
    "    onehot_targe_list = np.array(onehot_targe_list)\n",
    "    \n",
    "    ## Calculate and get the predict output\n",
    "    onehot_output_list = []\n",
    "    for i in range(len(output_data)):\n",
    "        out_onthot = output_data.iloc[i, -5:-2]\n",
    "        out_onthot = encode_output(out_onthot)\n",
    "        onehot_output_list.append(out_onthot)\n",
    "    compare_list = np.equal(onehot_targe_list,onehot_output_list)\n",
    "    compare_result = []\n",
    "    for i in compare_list:\n",
    "        if list(i)==[True, True, True]:\n",
    "            compare_result.append(1)\n",
    "        else:\n",
    "            compare_result.append(0)\n",
    "    compare_result = np.array(compare_result)\n",
    "    accuracy = len(compare_result[compare_result==1])/len(compare_result)\n",
    "    \n",
    "    #Calculate the Confusion Matrix, Precision, Recall and F1 score.\n",
    "    Confusion_Matrix_test = [[0, 0, 0],[0, 0, 0], [0, 0, 0]]\n",
    "    for i in range(len(onehot_targe_list)):\n",
    "        if onehot_targe_list[i][0]==1:\n",
    "            if onehot_output_list[i][0] == 1:\n",
    "                Confusion_Matrix_test[0][0]+=1\n",
    "            elif onehot_output_list[i][1] == 1:\n",
    "                Confusion_Matrix_test[0][1]+=1\n",
    "            else:\n",
    "                Confusion_Matrix_test[0][2]+=1\n",
    "        elif onehot_targe_list[i][1]==1:\n",
    "            if onehot_output_list[i][0] == 1:\n",
    "                Confusion_Matrix_test[1][0]+=1\n",
    "            elif onehot_output_list[i][1] == 1:\n",
    "                Confusion_Matrix_test[1][1]+=1\n",
    "            else:\n",
    "                Confusion_Matrix_test[1][2]+=1\n",
    "        elif onehot_targe_list[i][2]==1:\n",
    "            if onehot_output_list[i][0] == 1:\n",
    "                Confusion_Matrix_test[2][0]+=1\n",
    "            elif onehot_output_list[i][1] == 1:\n",
    "                Confusion_Matrix_test[2][1]+=1\n",
    "            else:\n",
    "                Confusion_Matrix_test[2][2]+=1\n",
    "    try:        \n",
    "        print(f'W_int = {W_int}')\n",
    "        print(f'W_out = {W_out}')\n",
    "        print(f'final error = {error/len(output_data)}, accuracy = {accuracy}')\n",
    "        print(f'Confusion_Matrix_test = {Confusion_Matrix_test}')\n",
    "        #for class1\n",
    "        calss1_Precision = Confusion_Matrix_test[0][0]/(Confusion_Matrix_test[0][0]+Confusion_Matrix_test[0][1]+Confusion_Matrix_test[0][2])\n",
    "        class1_Recall = Confusion_Matrix_test[0][0]/(Confusion_Matrix_test[0][0]+Confusion_Matrix_test[1][0]+Confusion_Matrix_test[2][0])\n",
    "        print(f'For calss1, Precision = {calss1_Precision}')\n",
    "        print(f'For calss1, Recall = {class1_Recall}')\n",
    "        print(f'For calss1, F1_score = {(2*calss1_Precision*class1_Recall)/(calss1_Precision+class1_Recall)}')\n",
    "\n",
    "        #for class2\n",
    "        calss2_Precision = Confusion_Matrix_test[1][1]/(Confusion_Matrix_test[1][0]+Confusion_Matrix_test[1][1]+Confusion_Matrix_test[1][2])\n",
    "        class2_Recall = Confusion_Matrix_test[1][1]/(Confusion_Matrix_test[0][1]+Confusion_Matrix_test[1][1]+Confusion_Matrix_test[2][1])\n",
    "        print(f'For calss1, Precision = {calss2_Precision}')\n",
    "        print(f'For calss1, Recall = {class2_Recall}')\n",
    "        print(f'For calss1, F1_score = {(2*calss2_Precision*class2_Recall)/(calss2_Precision+class2_Recall)}')\n",
    "\n",
    "        #for class3\n",
    "        calss3_Precision = Confusion_Matrix_test[2][2]/(Confusion_Matrix_test[2][0]+Confusion_Matrix_test[2][1]+Confusion_Matrix_test[2][2])\n",
    "        class3_Recall = Confusion_Matrix_test[2][2]/(Confusion_Matrix_test[0][2]+Confusion_Matrix_test[1][2]+Confusion_Matrix_test[2][2])\n",
    "        print(f'For calss1, Precision = {calss3_Precision}')\n",
    "        print(f'For calss1, Recall = {class3_Recall}')\n",
    "        print(f'For calss1, F1_score = {(2*calss3_Precision*class3_Recall)/(calss3_Precision+class3_Recall)}')\n",
    "    except:\n",
    "        print('Can\\'t divide by 0')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 100,
   "id": "17846219-cb2d-4b93-8e16-d62a1107b4cb",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "W_int = [[ 0.3614965  -0.03199934 -0.1786012   0.18955643 -0.37359501  0.44797253\n",
      "   0.09993276]\n",
      " [ 0.05860407 -0.03854939 -0.35595588  0.46528531 -0.19788544  0.23094047\n",
      "   0.39991482]\n",
      " [ 0.02858778 -0.50250368 -0.20687365 -0.49411398 -0.01276608 -0.49182402\n",
      "   0.3999944 ]\n",
      " [ 0.27529428 -0.51555495  0.23539621  0.11696298  0.22182507 -0.05209779\n",
      "   0.09996526]\n",
      " [-0.19447324 -0.5079946   0.37058637  0.02683533 -0.54226214 -0.06678496\n",
      "  -0.50001711]\n",
      " [-0.32711232  0.37700435 -0.22193736 -0.31208397  0.3150433  -0.13626612\n",
      "  -0.20005728]\n",
      " [ 0.5489105  -0.51617555 -0.47865382 -0.50273227 -0.07734296  0.14144875\n",
      "   0.39996281]\n",
      " [ 0.71353047  0.71353047  0.71353047  0.71353047  0.71353047  0.71353047\n",
      "   0.71353047]]\n",
      "W_out = [[-0.30005797 -0.23933901  0.32998057]\n",
      " [ 0.09838087 -0.0110359   0.09060941]\n",
      " [ 0.08216632  0.07014221  0.07734277]\n",
      " [ 0.07736434 -0.19639397 -0.12066331]\n",
      " [-0.13718102  0.04541719 -0.21568628]\n",
      " [ 0.39136791  0.12030444 -0.59126457]\n",
      " [-0.1081823  -0.30171215  0.03224384]\n",
      " [ 0.78329693  0.78329693  0.78329693]]\n",
      "final error = 0.41785816048123936, accuracy = 0.36666666666666664\n",
      "Confusion_Matrix_test = [[22, 0, 0], [19, 0, 0], [19, 0, 0]]\n",
      "For calss1, Precision = 1.0\n",
      "For calss1, Recall = 0.36666666666666664\n",
      "For calss1, F1_score = 0.5365853658536585\n",
      "Can't divide by 0\n"
     ]
    }
   ],
   "source": [
    "test_testdate(test, W_in, W_out)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "6972f7ca-67f6-436a-8c6c-43efaf5807bb",
   "metadata": {},
   "source": [
    "Finally, We got a not bad accuracy Precision, Recall and F1_score on test dataset."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "17721d81-ce1b-4876-ba64-ae6472215987",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "a894f03a-cfc6-4cbb-bc5a-5bcbde0afce4",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.11"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
