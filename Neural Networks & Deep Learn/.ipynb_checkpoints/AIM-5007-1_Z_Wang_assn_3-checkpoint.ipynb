{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "2695acc5-e963-4521-a92b-ebf194a53d10",
   "metadata": {},
   "source": [
    "## AIM-5007-1\n",
    "## By Zeyu Wang\n",
    "## Fall 2021"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "2328e6dd-a753-4956-9bda-d97274da7b9b",
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "import pandas as pd"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "d58cc4f7-9ac9-4b2f-ba6b-3d5675f1026c",
   "metadata": {},
   "source": [
    "Problem0:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "8f2fda10-8284-4d3d-a85b-e7a3fe9b64fd",
   "metadata": {},
   "outputs": [],
   "source": [
    "def weight(inputs, hiddends, outputs):\n",
    "    '''\n",
    "    This function will create  weights for DL and you need to give it the numbers of input, hiddents and outputs.\n",
    "    -------------------------------------------------------------------------------------------------\n",
    "    This function will return you two matrix that including the weight_input and weight_output\n",
    "    '''\n",
    "    W_int = np.random.randint(-5, 5, (inputs,hiddends))/10\n",
    "    bias_input = list(np.random.random(1))\n",
    "    bias_inputs = np.array(bias_input*hiddends)\n",
    "    W_int = np.concatenate((W_int, [bias_inputs]), axis=0)\n",
    "    \n",
    "    W_out = np.random.randint(-5, 5, (hiddends,outputs))/10\n",
    "    bias_out = list(np.random.random(1))\n",
    "    bias_outs = np.array(bias_out*outputs)\n",
    "    W_out = np.concatenate((W_out, [bias_outs]), axis=0)\n",
    "    return W_int, W_out"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "a5c07ca8-7bda-4068-b10d-da4233672bdf",
   "metadata": {},
   "source": [
    "Problem1:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "f4f5ac00-f12f-453d-a6a0-da6473059a5f",
   "metadata": {},
   "outputs": [],
   "source": [
    "def appendVector(vector):\n",
    "    '''\n",
    "    This function is used to extend 1 dimension for vector.\n",
    "    '''\n",
    "    vector1 = vector.copy()\n",
    "    vector1.append(1)\n",
    "    return vector1"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "8e875cb3-96ef-4511-8568-c8813efd910b",
   "metadata": {},
   "source": [
    "Problem2:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "c302eb90-69de-4ef1-8fdd-02ad04d7d186",
   "metadata": {},
   "outputs": [],
   "source": [
    "def obtainRawHidden(W_int, W_out, inpis):\n",
    "    '''\n",
    "    This function is used to calculate the hidden layer's raw data in a network.\n",
    "    '''\n",
    "    inputs_nodes = len(inpis)\n",
    "    append_f = np.array(appendVector(inpis))\n",
    "    hraw = append_f.T@W_int\n",
    "    return hraw"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "2e3cef83-8195-4a7e-9bdb-e10199c5c21c",
   "metadata": {},
   "source": [
    "Problem3:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "id": "110c94ad-5722-44fa-8250-3eb716029359",
   "metadata": {},
   "outputs": [],
   "source": [
    "def sigmoidFun(raw):\n",
    "    '''\n",
    "    This function is the activate function that is used to transfer the raw data to out data.\n",
    "    '''\n",
    "    return 1/(1+(np.exp(-raw)))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "id": "324f4a74-6323-4289-9cf0-ce9c1b0e6f80",
   "metadata": {},
   "outputs": [],
   "source": [
    "def obtainOutput(W_int, W_out, inpis):\n",
    "    '''\n",
    "    This function will be used to calculate the function final output by using the output of hidden layer data times the weight.\n",
    "    '''\n",
    "    hraw = obtainRawHidden(W_int, W_out, inpis)\n",
    "    hact = sigmoidFun(hraw)\n",
    "    hact1 = np.array(appendVector(list(hact)))\n",
    "    outraw = hact1.T@W_out\n",
    "    out = sigmoidFun(outraw)\n",
    "    return out, hact"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "60e391e3-0f50-45c2-a738-974303cfc2bc",
   "metadata": {},
   "source": [
    "Problem5:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "id": "7ae8effc-7826-4a55-b0cb-35ed6901d510",
   "metadata": {},
   "outputs": [],
   "source": [
    "def gradient_E_Wjk(output, targk, hact):\n",
    "    '''\n",
    "    This function will be used to calculate the gradient of weight between the hidden layer and output.\n",
    "    '''\n",
    "    gradient_out = []\n",
    "    gradient_a = (output-targk)*output*(1-output)\n",
    "    for i in gradient_a:\n",
    "        gradient_out.append(i*hact)\n",
    "    gradient_out = np.array(gradient_out)\n",
    "    gradient_out = gradient_out.T\n",
    "    return gradient_out"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "8f92f682-c72f-4ccd-81d7-6e0e9f0fc54a",
   "metadata": {},
   "source": [
    "Problem6:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "id": "9130b09d-380d-46bc-b94b-4085669e2aca",
   "metadata": {},
   "outputs": [],
   "source": [
    "def gradient_E_biasO(output, targk):\n",
    "    '''\n",
    "    This function is used to calculate the gradient of bias between the hidden layer and output.\n",
    "    '''\n",
    "    gradient_a = ((output-targk)*output*(1-output)).sum()\n",
    "    return gradient_a"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "6f4baae0-7353-4145-aba2-370c80c72e61",
   "metadata": {},
   "source": [
    "Problem7:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "id": "7d3673d2-2374-4eb1-8447-715b0293d15c",
   "metadata": {},
   "outputs": [],
   "source": [
    "def gradient_E_wij(output, targk, W_out, hact, inpis):\n",
    "    '''\n",
    "    This function will be used to calculate the gradient of weight between the input and hidden layer.\n",
    "    '''\n",
    "    gradient_a = ((output-targk)*output*(1-output)*W_out).sum()*hact*(1-hact)\n",
    "    \n",
    "    gradient_int = []\n",
    "    int_np = np.array(inpis)\n",
    "    for i in gradient_a:\n",
    "        gradient_int.append(i*int_np)\n",
    "    gradient_int = np.array(gradient_int)\n",
    "    gradient_int = gradient_int.T\n",
    "    return gradient_int"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "9c3ec13c-d4f4-48e3-96b3-97500dab5ebc",
   "metadata": {},
   "source": [
    "Problem8:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "id": "15379813-ec3b-4375-aea3-1091a6d25af3",
   "metadata": {},
   "outputs": [],
   "source": [
    "def gradient_E_biasH(output, targk, W_out, hact):\n",
    "    '''\n",
    "    This function is used to calculate the gradient of bias between the input and hidden layer.\n",
    "    '''\n",
    "    gradient_a = (((output-targk)*output*(1-output)*W_out).sum()*hact*(1-hact)).sum()\n",
    "    return gradient_a"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "e66794bc-37ad-4ad8-b00d-b9d0003a21af",
   "metadata": {},
   "source": [
    "Problem9-10:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "id": "29c21cf5-350f-46b9-bb0f-8e785cb493e8",
   "metadata": {},
   "outputs": [],
   "source": [
    "def update_wij(output, targk, W_out, hact, W_int, inpis, alpha):\n",
    "    '''\n",
    "    This function will be used to update the weight between the input and hidden layer.\n",
    "    '''\n",
    "    g_e_biasH_list = []\n",
    "    g_E_wij = gradient_E_wij(output, targk, W_out, hact, inpis)\n",
    "    g_E_biasH = gradient_E_biasH(output, targk, W_out, hact)\n",
    "    g_E_wij_rows, g_E_wij_columns = g_E_wij.shape\n",
    "    g_e_biasH_list.append(g_E_biasH)\n",
    "    g_e_biasH_list = g_e_biasH_list*g_E_wij_columns\n",
    "    g_E_ij = np.concatenate((g_E_wij, [g_e_biasH_list]), axis = 0)\n",
    "    new_wij = W_int-alpha*g_E_ij\n",
    "    return new_wij"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "id": "a6ae0e1e-311c-48f3-80f7-2e7908885be5",
   "metadata": {},
   "outputs": [],
   "source": [
    "def update_Wjk(output, targk, hact, W_out, alpha):\n",
    "    '''\n",
    "    This function will be used to update the weight between the hidden layer and output.\n",
    "    '''\n",
    "    g_e_biasO_list = []\n",
    "    g_E_Wjk = gradient_E_Wjk(output, targk, hact)\n",
    "    g_E_biasO = gradient_E_biasO(output, targk)\n",
    "    g_E_Wjk_rows, g_E_Wjk_columns = g_E_Wjk.shape\n",
    "    g_e_biasO_list.append(g_E_biasO)\n",
    "    g_e_biasO_list = g_e_biasO_list*g_E_Wjk_columns\n",
    "    g_E_jk = np.concatenate((g_E_Wjk, [g_e_biasO_list]), axis = 0)\n",
    "    new_Wjk = W_out-alpha*g_E_jk\n",
    "    return new_Wjk"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "90cf95f1-60fe-404d-908e-4693ed558766",
   "metadata": {},
   "source": [
    "Problem11:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 45,
   "id": "01449710-1a9c-45e1-ba92-c8a1a9fc94dd",
   "metadata": {},
   "outputs": [],
   "source": [
    "def DeelLearning(data):\n",
    "    '''\n",
    "    This function will use all of the functions above to learning and update the weight.\n",
    "    -------------------------------------------------------------------------------------\n",
    "    This function will return the two new weights. We can use these two weights to predict.\n",
    "    '''\n",
    "    hidden_nodes = 7\n",
    "    output_nodes = 3\n",
    "    \n",
    "    targk = list(data.target)[0]\n",
    "    inpis = list(data.input)[0]\n",
    "    alpha = 0.1\n",
    "    inputs_nodes = len(inpis)\n",
    "    \n",
    "    W_int, W_out = weight(inputs_nodes, hidden_nodes, output_nodes)\n",
    "    out, hact = obtainOutput(W_int, W_out, inpis)\n",
    "    error = 0.5*((targk-out)**2).sum()\n",
    "    #print(error)\n",
    "    \n",
    "    step = 1\n",
    "    while error>0.01 and step<100:\n",
    "        new_wij = update_wij(out, targk, W_out, hact, W_int, inpis, alpha)\n",
    "        new_Wjk = update_Wjk(out, targk, hact, W_out, alpha)\n",
    "        W_int, W_out = new_wij, new_Wjk\n",
    "        out, hact = obtainOutput(W_int, W_out, inpis)\n",
    "        error = 0.5*((targk-out)**2).sum()\n",
    "        print(hact)\n",
    "        #print(error)\n",
    "        step+=1\n",
    "    #return W_int, W_out"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 46,
   "id": "63986008-6b3a-4945-8563-1eb9eafa65e6",
   "metadata": {},
   "outputs": [],
   "source": [
    "data = pd.DataFrame({'input':[[1,2,3,4,5,6,7]], 'target':[[0.3, 0.2, 0.5]]})"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 47,
   "id": "5f61d638-cd64-40f4-acf8-8731f3a23eb3",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>input</th>\n",
       "      <th>target</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>[1, 2, 3, 4, 5, 6, 7]</td>\n",
       "      <td>[0.3, 0.2, 0.5]</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "                   input           target\n",
       "0  [1, 2, 3, 4, 5, 6, 7]  [0.3, 0.2, 0.5]"
      ]
     },
     "execution_count": 47,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 48,
   "id": "5795fbc8-4ea6-4e30-8a48-ed42ca13632b",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[0.28774223 0.93055318 0.97242199 0.03802172 0.02316869 0.55997353\n",
      " 0.31022708]\n",
      "[0.32624764 0.934366   0.9731646  0.03937754 0.02372883 0.61250566\n",
      " 0.35203202]\n",
      "[0.3723987  0.93798458 0.97390845 0.040896   0.02434385 0.66304824\n",
      " 0.40146021]\n",
      "[0.42533956 0.94133974 0.974635   0.04256423 0.02500458 0.70857172\n",
      " 0.45703705]\n",
      "[0.48263649 0.94438772 0.97532802 0.04436098 0.02569877 0.74740563\n",
      " 0.51563934]\n",
      "[0.54056869 0.94711076 0.97597523 0.04625922 0.02641262 0.77930747\n",
      " 0.57315706]\n",
      "[0.59528364 0.94951558 0.97656977 0.04823166 0.02713326 0.80498951\n",
      " 0.62590939]\n",
      "[0.64407398 0.95162789 0.97711036 0.05025661 0.02785116 0.82555303\n",
      " 0.67178082]\n",
      "[0.68585933 0.95348361 0.9775999  0.05232074 0.02856078 0.84210074\n",
      " 0.7103296 ]\n",
      "[0.72082658 0.95512056 0.97804348 0.05441814 0.02925991 0.8555622\n",
      " 0.74218232]\n",
      "[0.7498064  0.9565734  0.97844676 0.05654782 0.02994831 0.86665883\n",
      " 0.76838289]\n",
      "[0.77380522 0.95787155 0.97881508 0.05871135 0.03062672 0.87593026\n",
      " 0.78999802]\n",
      "[0.79376691 0.95903915 0.97915307 0.06091137 0.03129617 0.88377573\n",
      " 0.80795412]\n",
      "[0.8104887  0.96009572 0.97946467 0.06315074 0.0319577  0.89049144\n",
      " 0.82300099]\n",
      "[0.82461239 0.96105703 0.97975312 0.06543214 0.03261221 0.89629939\n",
      " 0.83572696]\n",
      "[0.8366438  0.9619359  0.98002113 0.06775794 0.03326043 0.90136812\n",
      " 0.84658846]\n",
      "[0.84697869 0.96274282 0.98027096 0.0701301  0.0339029  0.90582739\n",
      " 0.85593919]\n"
     ]
    }
   ],
   "source": [
    "DeelLearning(data)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "5580bc67-5bac-4af2-817c-4b54f45de923",
   "metadata": {},
   "source": [
    "Problem3:\n",
    "Because the sigmoid function is just to transfer a number to a number, so the dimensions of the output as well as input. For example, if you have a 1X10 input, you will get 1X10 output after you applying a sigmoid function."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "b50a792f-46b5-47b8-b6b7-4641e1888784",
   "metadata": {},
   "source": [
    "Problem4: Because in (𝑜𝑎𝑐𝑡𝑖𝑣𝑎𝑡𝑒𝑑−𝑡)𝑇(𝑜𝑎𝑐𝑡𝑖𝑣𝑎𝑡𝑒𝑑−𝑡), the transpose of vector times itself means square. So no matter using a-b or b-a. They will have the same result."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "2f280e6b-b27b-42fe-ab9c-7546c63faea2",
   "metadata": {},
   "source": [
    "Problem11:"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "60db87af-e1e3-4e6f-b8f7-b271acfd5f61",
   "metadata": {},
   "source": [
    "We just need the final Wij and Wjk."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "82fbf808-30f2-46c0-a179-45c62e1fa796",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.0"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
