{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "d0258b5b-5840-4b91-86fd-2362ccd27f6f",
   "metadata": {},
   "source": [
    "## 22.1 (a)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 256,
   "id": "39c07257-0af0-4841-9290-112b1172e7e6",
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "import numpy as np\n",
    "import matplotlib.pyplot as plt\n",
    "import statsmodels.api as sm"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 257,
   "id": "28db2da3-f1db-4a0a-b2af-10f4d3f2f09e",
   "metadata": {},
   "outputs": [],
   "source": [
    "variable  = {}\n",
    "for i in range(101):\n",
    "    variable[i] = np.random.normal(size = 500)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 258,
   "id": "12f260eb-74a2-4bde-9207-b209cb15085f",
   "metadata": {},
   "outputs": [],
   "source": [
    "y = variable[0]\n",
    "y = np.array(y)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 259,
   "id": "44a96c8a-acad-4b73-b27e-51d9daa0b3a7",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>1</th>\n",
       "      <th>2</th>\n",
       "      <th>3</th>\n",
       "      <th>4</th>\n",
       "      <th>5</th>\n",
       "      <th>6</th>\n",
       "      <th>7</th>\n",
       "      <th>8</th>\n",
       "      <th>9</th>\n",
       "      <th>10</th>\n",
       "      <th>...</th>\n",
       "      <th>91</th>\n",
       "      <th>92</th>\n",
       "      <th>93</th>\n",
       "      <th>94</th>\n",
       "      <th>95</th>\n",
       "      <th>96</th>\n",
       "      <th>97</th>\n",
       "      <th>98</th>\n",
       "      <th>99</th>\n",
       "      <th>100</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>-1.418848</td>\n",
       "      <td>1.652891</td>\n",
       "      <td>-0.711933</td>\n",
       "      <td>0.415107</td>\n",
       "      <td>-0.775506</td>\n",
       "      <td>1.628612</td>\n",
       "      <td>-0.811707</td>\n",
       "      <td>1.298218</td>\n",
       "      <td>0.648467</td>\n",
       "      <td>-1.465283</td>\n",
       "      <td>...</td>\n",
       "      <td>-0.927395</td>\n",
       "      <td>0.716864</td>\n",
       "      <td>-0.359686</td>\n",
       "      <td>0.997417</td>\n",
       "      <td>0.723951</td>\n",
       "      <td>0.333542</td>\n",
       "      <td>0.446894</td>\n",
       "      <td>-1.281881</td>\n",
       "      <td>-0.540011</td>\n",
       "      <td>2.090971</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>-1.604875</td>\n",
       "      <td>0.765258</td>\n",
       "      <td>0.653771</td>\n",
       "      <td>-1.023393</td>\n",
       "      <td>-0.288880</td>\n",
       "      <td>1.750810</td>\n",
       "      <td>-0.828682</td>\n",
       "      <td>1.400171</td>\n",
       "      <td>0.150650</td>\n",
       "      <td>-0.341355</td>\n",
       "      <td>...</td>\n",
       "      <td>-1.254468</td>\n",
       "      <td>0.439190</td>\n",
       "      <td>0.926780</td>\n",
       "      <td>-1.063760</td>\n",
       "      <td>-1.400821</td>\n",
       "      <td>-0.016600</td>\n",
       "      <td>0.205276</td>\n",
       "      <td>-1.447556</td>\n",
       "      <td>-1.314368</td>\n",
       "      <td>-0.772864</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>1.353727</td>\n",
       "      <td>-0.910888</td>\n",
       "      <td>0.488934</td>\n",
       "      <td>-0.974900</td>\n",
       "      <td>-0.557525</td>\n",
       "      <td>1.259756</td>\n",
       "      <td>0.675357</td>\n",
       "      <td>1.837731</td>\n",
       "      <td>-0.379372</td>\n",
       "      <td>-0.629892</td>\n",
       "      <td>...</td>\n",
       "      <td>-0.524092</td>\n",
       "      <td>0.599300</td>\n",
       "      <td>-2.581049</td>\n",
       "      <td>-1.700898</td>\n",
       "      <td>0.156484</td>\n",
       "      <td>0.266981</td>\n",
       "      <td>-0.777045</td>\n",
       "      <td>-0.335480</td>\n",
       "      <td>1.029099</td>\n",
       "      <td>-1.218808</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>1.164852</td>\n",
       "      <td>-1.381252</td>\n",
       "      <td>0.592303</td>\n",
       "      <td>-0.352381</td>\n",
       "      <td>0.590977</td>\n",
       "      <td>0.788547</td>\n",
       "      <td>-0.775881</td>\n",
       "      <td>-0.018200</td>\n",
       "      <td>-0.489651</td>\n",
       "      <td>0.473272</td>\n",
       "      <td>...</td>\n",
       "      <td>0.095619</td>\n",
       "      <td>-0.194784</td>\n",
       "      <td>-0.237642</td>\n",
       "      <td>0.474299</td>\n",
       "      <td>-1.243211</td>\n",
       "      <td>1.041420</td>\n",
       "      <td>0.324263</td>\n",
       "      <td>-1.010733</td>\n",
       "      <td>1.096016</td>\n",
       "      <td>-2.104659</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>-1.595184</td>\n",
       "      <td>-1.015838</td>\n",
       "      <td>0.768042</td>\n",
       "      <td>1.176636</td>\n",
       "      <td>1.419326</td>\n",
       "      <td>0.445146</td>\n",
       "      <td>0.136474</td>\n",
       "      <td>-0.684657</td>\n",
       "      <td>0.254179</td>\n",
       "      <td>-0.448212</td>\n",
       "      <td>...</td>\n",
       "      <td>-0.763450</td>\n",
       "      <td>1.241487</td>\n",
       "      <td>1.021744</td>\n",
       "      <td>-0.135176</td>\n",
       "      <td>-0.108881</td>\n",
       "      <td>-1.507169</td>\n",
       "      <td>0.263478</td>\n",
       "      <td>1.723327</td>\n",
       "      <td>-0.670796</td>\n",
       "      <td>-1.604238</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>...</th>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>495</th>\n",
       "      <td>0.601428</td>\n",
       "      <td>-0.154113</td>\n",
       "      <td>-1.069733</td>\n",
       "      <td>1.018843</td>\n",
       "      <td>0.030527</td>\n",
       "      <td>-0.052758</td>\n",
       "      <td>0.045072</td>\n",
       "      <td>-0.781771</td>\n",
       "      <td>1.182619</td>\n",
       "      <td>0.460204</td>\n",
       "      <td>...</td>\n",
       "      <td>-0.389122</td>\n",
       "      <td>0.693417</td>\n",
       "      <td>-0.360475</td>\n",
       "      <td>-0.268561</td>\n",
       "      <td>-1.787627</td>\n",
       "      <td>1.147774</td>\n",
       "      <td>0.781285</td>\n",
       "      <td>0.313749</td>\n",
       "      <td>-0.026026</td>\n",
       "      <td>-2.402718</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>496</th>\n",
       "      <td>0.297190</td>\n",
       "      <td>0.381272</td>\n",
       "      <td>-0.980909</td>\n",
       "      <td>-0.860495</td>\n",
       "      <td>-0.546541</td>\n",
       "      <td>1.105258</td>\n",
       "      <td>-0.096239</td>\n",
       "      <td>0.425241</td>\n",
       "      <td>1.110108</td>\n",
       "      <td>-0.104640</td>\n",
       "      <td>...</td>\n",
       "      <td>-0.230952</td>\n",
       "      <td>-1.326943</td>\n",
       "      <td>0.105162</td>\n",
       "      <td>0.187601</td>\n",
       "      <td>1.325339</td>\n",
       "      <td>-1.581838</td>\n",
       "      <td>0.084509</td>\n",
       "      <td>0.941433</td>\n",
       "      <td>0.148154</td>\n",
       "      <td>-0.424026</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>497</th>\n",
       "      <td>0.575944</td>\n",
       "      <td>0.240785</td>\n",
       "      <td>-0.205182</td>\n",
       "      <td>-0.193221</td>\n",
       "      <td>-0.159087</td>\n",
       "      <td>0.022000</td>\n",
       "      <td>0.782640</td>\n",
       "      <td>0.366384</td>\n",
       "      <td>-1.896019</td>\n",
       "      <td>-0.362922</td>\n",
       "      <td>...</td>\n",
       "      <td>1.732077</td>\n",
       "      <td>0.122814</td>\n",
       "      <td>-0.123820</td>\n",
       "      <td>-0.929078</td>\n",
       "      <td>-1.197462</td>\n",
       "      <td>-0.465532</td>\n",
       "      <td>-0.089252</td>\n",
       "      <td>0.482199</td>\n",
       "      <td>-0.526520</td>\n",
       "      <td>1.464054</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>498</th>\n",
       "      <td>0.042110</td>\n",
       "      <td>-1.902657</td>\n",
       "      <td>0.528573</td>\n",
       "      <td>0.556847</td>\n",
       "      <td>-0.301401</td>\n",
       "      <td>-0.862552</td>\n",
       "      <td>0.016394</td>\n",
       "      <td>1.029248</td>\n",
       "      <td>-0.213428</td>\n",
       "      <td>1.762523</td>\n",
       "      <td>...</td>\n",
       "      <td>1.700988</td>\n",
       "      <td>0.312196</td>\n",
       "      <td>-0.609407</td>\n",
       "      <td>-0.331232</td>\n",
       "      <td>-0.806243</td>\n",
       "      <td>0.484627</td>\n",
       "      <td>-2.539264</td>\n",
       "      <td>-0.819181</td>\n",
       "      <td>0.367736</td>\n",
       "      <td>0.482759</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>499</th>\n",
       "      <td>-0.758632</td>\n",
       "      <td>1.307810</td>\n",
       "      <td>-0.895995</td>\n",
       "      <td>-0.318282</td>\n",
       "      <td>-0.559736</td>\n",
       "      <td>0.937294</td>\n",
       "      <td>-0.262522</td>\n",
       "      <td>0.187211</td>\n",
       "      <td>-0.519183</td>\n",
       "      <td>-1.811888</td>\n",
       "      <td>...</td>\n",
       "      <td>0.162416</td>\n",
       "      <td>-0.364867</td>\n",
       "      <td>-0.001937</td>\n",
       "      <td>0.425824</td>\n",
       "      <td>0.480691</td>\n",
       "      <td>-0.237187</td>\n",
       "      <td>-1.167345</td>\n",
       "      <td>-0.101200</td>\n",
       "      <td>0.892941</td>\n",
       "      <td>-0.513664</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>500 rows × 100 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "          1         2         3         4         5         6         7    \\\n",
       "0   -1.418848  1.652891 -0.711933  0.415107 -0.775506  1.628612 -0.811707   \n",
       "1   -1.604875  0.765258  0.653771 -1.023393 -0.288880  1.750810 -0.828682   \n",
       "2    1.353727 -0.910888  0.488934 -0.974900 -0.557525  1.259756  0.675357   \n",
       "3    1.164852 -1.381252  0.592303 -0.352381  0.590977  0.788547 -0.775881   \n",
       "4   -1.595184 -1.015838  0.768042  1.176636  1.419326  0.445146  0.136474   \n",
       "..        ...       ...       ...       ...       ...       ...       ...   \n",
       "495  0.601428 -0.154113 -1.069733  1.018843  0.030527 -0.052758  0.045072   \n",
       "496  0.297190  0.381272 -0.980909 -0.860495 -0.546541  1.105258 -0.096239   \n",
       "497  0.575944  0.240785 -0.205182 -0.193221 -0.159087  0.022000  0.782640   \n",
       "498  0.042110 -1.902657  0.528573  0.556847 -0.301401 -0.862552  0.016394   \n",
       "499 -0.758632  1.307810 -0.895995 -0.318282 -0.559736  0.937294 -0.262522   \n",
       "\n",
       "          8         9         10   ...       91        92        93   \\\n",
       "0    1.298218  0.648467 -1.465283  ... -0.927395  0.716864 -0.359686   \n",
       "1    1.400171  0.150650 -0.341355  ... -1.254468  0.439190  0.926780   \n",
       "2    1.837731 -0.379372 -0.629892  ... -0.524092  0.599300 -2.581049   \n",
       "3   -0.018200 -0.489651  0.473272  ...  0.095619 -0.194784 -0.237642   \n",
       "4   -0.684657  0.254179 -0.448212  ... -0.763450  1.241487  1.021744   \n",
       "..        ...       ...       ...  ...       ...       ...       ...   \n",
       "495 -0.781771  1.182619  0.460204  ... -0.389122  0.693417 -0.360475   \n",
       "496  0.425241  1.110108 -0.104640  ... -0.230952 -1.326943  0.105162   \n",
       "497  0.366384 -1.896019 -0.362922  ...  1.732077  0.122814 -0.123820   \n",
       "498  1.029248 -0.213428  1.762523  ...  1.700988  0.312196 -0.609407   \n",
       "499  0.187211 -0.519183 -1.811888  ...  0.162416 -0.364867 -0.001937   \n",
       "\n",
       "          94        95        96        97        98        99        100  \n",
       "0    0.997417  0.723951  0.333542  0.446894 -1.281881 -0.540011  2.090971  \n",
       "1   -1.063760 -1.400821 -0.016600  0.205276 -1.447556 -1.314368 -0.772864  \n",
       "2   -1.700898  0.156484  0.266981 -0.777045 -0.335480  1.029099 -1.218808  \n",
       "3    0.474299 -1.243211  1.041420  0.324263 -1.010733  1.096016 -2.104659  \n",
       "4   -0.135176 -0.108881 -1.507169  0.263478  1.723327 -0.670796 -1.604238  \n",
       "..        ...       ...       ...       ...       ...       ...       ...  \n",
       "495 -0.268561 -1.787627  1.147774  0.781285  0.313749 -0.026026 -2.402718  \n",
       "496  0.187601  1.325339 -1.581838  0.084509  0.941433  0.148154 -0.424026  \n",
       "497 -0.929078 -1.197462 -0.465532 -0.089252  0.482199 -0.526520  1.464054  \n",
       "498 -0.331232 -0.806243  0.484627 -2.539264 -0.819181  0.367736  0.482759  \n",
       "499  0.425824  0.480691 -0.237187 -1.167345 -0.101200  0.892941 -0.513664  \n",
       "\n",
       "[500 rows x 100 columns]"
      ]
     },
     "execution_count": 259,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "del variable[0]\n",
    "variable = pd.DataFrame(variable)\n",
    "variable"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 260,
   "id": "4533c5da-fe31-462d-b5ac-25579739d333",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<table class=\"simpletable\">\n",
       "<caption>OLS Regression Results</caption>\n",
       "<tr>\n",
       "  <th>Dep. Variable:</th>            <td>y</td>        <th>  R-squared:         </th> <td>   0.253</td>\n",
       "</tr>\n",
       "<tr>\n",
       "  <th>Model:</th>                   <td>OLS</td>       <th>  Adj. R-squared:    </th> <td>   0.066</td>\n",
       "</tr>\n",
       "<tr>\n",
       "  <th>Method:</th>             <td>Least Squares</td>  <th>  F-statistic:       </th> <td>   1.354</td>\n",
       "</tr>\n",
       "<tr>\n",
       "  <th>Date:</th>             <td>Sun, 20 Jun 2021</td> <th>  Prob (F-statistic):</th>  <td>0.0227</td> \n",
       "</tr>\n",
       "<tr>\n",
       "  <th>Time:</th>                 <td>22:29:56</td>     <th>  Log-Likelihood:    </th> <td> -643.58</td>\n",
       "</tr>\n",
       "<tr>\n",
       "  <th>No. Observations:</th>      <td>   500</td>      <th>  AIC:               </th> <td>   1489.</td>\n",
       "</tr>\n",
       "<tr>\n",
       "  <th>Df Residuals:</th>          <td>   399</td>      <th>  BIC:               </th> <td>   1915.</td>\n",
       "</tr>\n",
       "<tr>\n",
       "  <th>Df Model:</th>              <td>   100</td>      <th>                     </th>     <td> </td>   \n",
       "</tr>\n",
       "<tr>\n",
       "  <th>Covariance Type:</th>      <td>nonrobust</td>    <th>                     </th>     <td> </td>   \n",
       "</tr>\n",
       "</table>\n",
       "<table class=\"simpletable\">\n",
       "<tr>\n",
       "    <td></td>       <th>coef</th>     <th>std err</th>      <th>t</th>      <th>P>|t|</th>  <th>[0.025</th>    <th>0.975]</th>  \n",
       "</tr>\n",
       "<tr>\n",
       "  <th>const</th> <td>    0.0288</td> <td>    0.050</td> <td>    0.582</td> <td> 0.561</td> <td>   -0.069</td> <td>    0.126</td>\n",
       "</tr>\n",
       "<tr>\n",
       "  <th>1</th>     <td>    0.0483</td> <td>    0.053</td> <td>    0.908</td> <td> 0.364</td> <td>   -0.056</td> <td>    0.153</td>\n",
       "</tr>\n",
       "<tr>\n",
       "  <th>2</th>     <td>    0.0165</td> <td>    0.050</td> <td>    0.332</td> <td> 0.740</td> <td>   -0.081</td> <td>    0.114</td>\n",
       "</tr>\n",
       "<tr>\n",
       "  <th>3</th>     <td>   -0.0985</td> <td>    0.048</td> <td>   -2.068</td> <td> 0.039</td> <td>   -0.192</td> <td>   -0.005</td>\n",
       "</tr>\n",
       "<tr>\n",
       "  <th>4</th>     <td>   -0.0051</td> <td>    0.050</td> <td>   -0.101</td> <td> 0.919</td> <td>   -0.104</td> <td>    0.094</td>\n",
       "</tr>\n",
       "<tr>\n",
       "  <th>5</th>     <td>    0.1272</td> <td>    0.052</td> <td>    2.454</td> <td> 0.015</td> <td>    0.025</td> <td>    0.229</td>\n",
       "</tr>\n",
       "<tr>\n",
       "  <th>6</th>     <td>    0.0248</td> <td>    0.052</td> <td>    0.477</td> <td> 0.633</td> <td>   -0.077</td> <td>    0.127</td>\n",
       "</tr>\n",
       "<tr>\n",
       "  <th>7</th>     <td>    0.0695</td> <td>    0.050</td> <td>    1.401</td> <td> 0.162</td> <td>   -0.028</td> <td>    0.167</td>\n",
       "</tr>\n",
       "<tr>\n",
       "  <th>8</th>     <td>   -0.0049</td> <td>    0.047</td> <td>   -0.106</td> <td> 0.916</td> <td>   -0.096</td> <td>    0.087</td>\n",
       "</tr>\n",
       "<tr>\n",
       "  <th>9</th>     <td>   -0.0007</td> <td>    0.049</td> <td>   -0.015</td> <td> 0.988</td> <td>   -0.096</td> <td>    0.095</td>\n",
       "</tr>\n",
       "<tr>\n",
       "  <th>10</th>    <td>    0.1001</td> <td>    0.052</td> <td>    1.915</td> <td> 0.056</td> <td>   -0.003</td> <td>    0.203</td>\n",
       "</tr>\n",
       "<tr>\n",
       "  <th>11</th>    <td>    0.0422</td> <td>    0.049</td> <td>    0.866</td> <td> 0.387</td> <td>   -0.053</td> <td>    0.138</td>\n",
       "</tr>\n",
       "<tr>\n",
       "  <th>12</th>    <td>    0.1186</td> <td>    0.048</td> <td>    2.495</td> <td> 0.013</td> <td>    0.025</td> <td>    0.212</td>\n",
       "</tr>\n",
       "<tr>\n",
       "  <th>13</th>    <td>    0.0325</td> <td>    0.048</td> <td>    0.675</td> <td> 0.500</td> <td>   -0.062</td> <td>    0.127</td>\n",
       "</tr>\n",
       "<tr>\n",
       "  <th>14</th>    <td>   -0.0186</td> <td>    0.047</td> <td>   -0.399</td> <td> 0.690</td> <td>   -0.110</td> <td>    0.073</td>\n",
       "</tr>\n",
       "<tr>\n",
       "  <th>15</th>    <td>    0.0616</td> <td>    0.047</td> <td>    1.313</td> <td> 0.190</td> <td>   -0.031</td> <td>    0.154</td>\n",
       "</tr>\n",
       "<tr>\n",
       "  <th>16</th>    <td>   -0.0111</td> <td>    0.051</td> <td>   -0.218</td> <td> 0.827</td> <td>   -0.111</td> <td>    0.089</td>\n",
       "</tr>\n",
       "<tr>\n",
       "  <th>17</th>    <td>   -0.0017</td> <td>    0.048</td> <td>   -0.037</td> <td> 0.971</td> <td>   -0.095</td> <td>    0.092</td>\n",
       "</tr>\n",
       "<tr>\n",
       "  <th>18</th>    <td>    0.1005</td> <td>    0.047</td> <td>    2.137</td> <td> 0.033</td> <td>    0.008</td> <td>    0.193</td>\n",
       "</tr>\n",
       "<tr>\n",
       "  <th>19</th>    <td>    0.0324</td> <td>    0.049</td> <td>    0.669</td> <td> 0.504</td> <td>   -0.063</td> <td>    0.128</td>\n",
       "</tr>\n",
       "<tr>\n",
       "  <th>20</th>    <td>    0.0536</td> <td>    0.051</td> <td>    1.048</td> <td> 0.295</td> <td>   -0.047</td> <td>    0.154</td>\n",
       "</tr>\n",
       "<tr>\n",
       "  <th>21</th>    <td>   -0.0346</td> <td>    0.050</td> <td>   -0.690</td> <td> 0.490</td> <td>   -0.133</td> <td>    0.064</td>\n",
       "</tr>\n",
       "<tr>\n",
       "  <th>22</th>    <td>    0.0154</td> <td>    0.055</td> <td>    0.280</td> <td> 0.780</td> <td>   -0.092</td> <td>    0.123</td>\n",
       "</tr>\n",
       "<tr>\n",
       "  <th>23</th>    <td>    0.0335</td> <td>    0.049</td> <td>    0.687</td> <td> 0.492</td> <td>   -0.062</td> <td>    0.129</td>\n",
       "</tr>\n",
       "<tr>\n",
       "  <th>24</th>    <td>    0.0498</td> <td>    0.050</td> <td>    0.991</td> <td> 0.322</td> <td>   -0.049</td> <td>    0.149</td>\n",
       "</tr>\n",
       "<tr>\n",
       "  <th>25</th>    <td>    0.0164</td> <td>    0.049</td> <td>    0.333</td> <td> 0.739</td> <td>   -0.080</td> <td>    0.113</td>\n",
       "</tr>\n",
       "<tr>\n",
       "  <th>26</th>    <td>   -0.0225</td> <td>    0.048</td> <td>   -0.472</td> <td> 0.637</td> <td>   -0.116</td> <td>    0.071</td>\n",
       "</tr>\n",
       "<tr>\n",
       "  <th>27</th>    <td>    0.0312</td> <td>    0.048</td> <td>    0.645</td> <td> 0.519</td> <td>   -0.064</td> <td>    0.126</td>\n",
       "</tr>\n",
       "<tr>\n",
       "  <th>28</th>    <td>    0.0803</td> <td>    0.051</td> <td>    1.574</td> <td> 0.116</td> <td>   -0.020</td> <td>    0.181</td>\n",
       "</tr>\n",
       "<tr>\n",
       "  <th>29</th>    <td>   -0.0092</td> <td>    0.051</td> <td>   -0.180</td> <td> 0.858</td> <td>   -0.109</td> <td>    0.091</td>\n",
       "</tr>\n",
       "<tr>\n",
       "  <th>30</th>    <td>    0.0058</td> <td>    0.047</td> <td>    0.123</td> <td> 0.902</td> <td>   -0.086</td> <td>    0.098</td>\n",
       "</tr>\n",
       "<tr>\n",
       "  <th>31</th>    <td>    0.0382</td> <td>    0.050</td> <td>    0.764</td> <td> 0.445</td> <td>   -0.060</td> <td>    0.137</td>\n",
       "</tr>\n",
       "<tr>\n",
       "  <th>32</th>    <td>   -0.0118</td> <td>    0.051</td> <td>   -0.234</td> <td> 0.815</td> <td>   -0.111</td> <td>    0.088</td>\n",
       "</tr>\n",
       "<tr>\n",
       "  <th>33</th>    <td>   -0.0356</td> <td>    0.051</td> <td>   -0.694</td> <td> 0.488</td> <td>   -0.137</td> <td>    0.065</td>\n",
       "</tr>\n",
       "<tr>\n",
       "  <th>34</th>    <td>   -0.0343</td> <td>    0.049</td> <td>   -0.701</td> <td> 0.484</td> <td>   -0.130</td> <td>    0.062</td>\n",
       "</tr>\n",
       "<tr>\n",
       "  <th>35</th>    <td>   -0.0960</td> <td>    0.051</td> <td>   -1.888</td> <td> 0.060</td> <td>   -0.196</td> <td>    0.004</td>\n",
       "</tr>\n",
       "<tr>\n",
       "  <th>36</th>    <td>    0.0782</td> <td>    0.049</td> <td>    1.584</td> <td> 0.114</td> <td>   -0.019</td> <td>    0.175</td>\n",
       "</tr>\n",
       "<tr>\n",
       "  <th>37</th>    <td>    0.0645</td> <td>    0.048</td> <td>    1.340</td> <td> 0.181</td> <td>   -0.030</td> <td>    0.159</td>\n",
       "</tr>\n",
       "<tr>\n",
       "  <th>38</th>    <td>   -0.0079</td> <td>    0.047</td> <td>   -0.169</td> <td> 0.866</td> <td>   -0.100</td> <td>    0.084</td>\n",
       "</tr>\n",
       "<tr>\n",
       "  <th>39</th>    <td>   -0.0275</td> <td>    0.049</td> <td>   -0.566</td> <td> 0.572</td> <td>   -0.123</td> <td>    0.068</td>\n",
       "</tr>\n",
       "<tr>\n",
       "  <th>40</th>    <td>   -0.0148</td> <td>    0.050</td> <td>   -0.293</td> <td> 0.770</td> <td>   -0.114</td> <td>    0.084</td>\n",
       "</tr>\n",
       "<tr>\n",
       "  <th>41</th>    <td>    0.0999</td> <td>    0.048</td> <td>    2.073</td> <td> 0.039</td> <td>    0.005</td> <td>    0.195</td>\n",
       "</tr>\n",
       "<tr>\n",
       "  <th>42</th>    <td>    0.0073</td> <td>    0.047</td> <td>    0.156</td> <td> 0.876</td> <td>   -0.085</td> <td>    0.100</td>\n",
       "</tr>\n",
       "<tr>\n",
       "  <th>43</th>    <td>   -0.0688</td> <td>    0.051</td> <td>   -1.359</td> <td> 0.175</td> <td>   -0.168</td> <td>    0.031</td>\n",
       "</tr>\n",
       "<tr>\n",
       "  <th>44</th>    <td>   -0.0147</td> <td>    0.049</td> <td>   -0.299</td> <td> 0.765</td> <td>   -0.111</td> <td>    0.082</td>\n",
       "</tr>\n",
       "<tr>\n",
       "  <th>45</th>    <td>   -0.0255</td> <td>    0.049</td> <td>   -0.517</td> <td> 0.606</td> <td>   -0.122</td> <td>    0.071</td>\n",
       "</tr>\n",
       "<tr>\n",
       "  <th>46</th>    <td>   -0.1150</td> <td>    0.048</td> <td>   -2.375</td> <td> 0.018</td> <td>   -0.210</td> <td>   -0.020</td>\n",
       "</tr>\n",
       "<tr>\n",
       "  <th>47</th>    <td>    0.0596</td> <td>    0.047</td> <td>    1.265</td> <td> 0.207</td> <td>   -0.033</td> <td>    0.152</td>\n",
       "</tr>\n",
       "<tr>\n",
       "  <th>48</th>    <td>    0.0168</td> <td>    0.049</td> <td>    0.341</td> <td> 0.733</td> <td>   -0.080</td> <td>    0.113</td>\n",
       "</tr>\n",
       "<tr>\n",
       "  <th>49</th>    <td>    0.0337</td> <td>    0.046</td> <td>    0.726</td> <td> 0.468</td> <td>   -0.057</td> <td>    0.125</td>\n",
       "</tr>\n",
       "<tr>\n",
       "  <th>50</th>    <td>    0.0870</td> <td>    0.052</td> <td>    1.669</td> <td> 0.096</td> <td>   -0.016</td> <td>    0.189</td>\n",
       "</tr>\n",
       "<tr>\n",
       "  <th>51</th>    <td>    0.0669</td> <td>    0.049</td> <td>    1.354</td> <td> 0.177</td> <td>   -0.030</td> <td>    0.164</td>\n",
       "</tr>\n",
       "<tr>\n",
       "  <th>52</th>    <td>    0.0101</td> <td>    0.052</td> <td>    0.193</td> <td> 0.847</td> <td>   -0.093</td> <td>    0.113</td>\n",
       "</tr>\n",
       "<tr>\n",
       "  <th>53</th>    <td>    0.0146</td> <td>    0.047</td> <td>    0.312</td> <td> 0.755</td> <td>   -0.077</td> <td>    0.106</td>\n",
       "</tr>\n",
       "<tr>\n",
       "  <th>54</th>    <td>    0.0338</td> <td>    0.051</td> <td>    0.660</td> <td> 0.510</td> <td>   -0.067</td> <td>    0.134</td>\n",
       "</tr>\n",
       "<tr>\n",
       "  <th>55</th>    <td>    0.0293</td> <td>    0.049</td> <td>    0.597</td> <td> 0.551</td> <td>   -0.067</td> <td>    0.126</td>\n",
       "</tr>\n",
       "<tr>\n",
       "  <th>56</th>    <td>   -0.0255</td> <td>    0.049</td> <td>   -0.523</td> <td> 0.601</td> <td>   -0.121</td> <td>    0.070</td>\n",
       "</tr>\n",
       "<tr>\n",
       "  <th>57</th>    <td>    0.0972</td> <td>    0.049</td> <td>    1.983</td> <td> 0.048</td> <td>    0.001</td> <td>    0.194</td>\n",
       "</tr>\n",
       "<tr>\n",
       "  <th>58</th>    <td>    0.0040</td> <td>    0.050</td> <td>    0.080</td> <td> 0.936</td> <td>   -0.094</td> <td>    0.102</td>\n",
       "</tr>\n",
       "<tr>\n",
       "  <th>59</th>    <td>    0.0641</td> <td>    0.049</td> <td>    1.297</td> <td> 0.195</td> <td>   -0.033</td> <td>    0.161</td>\n",
       "</tr>\n",
       "<tr>\n",
       "  <th>60</th>    <td>   -0.0052</td> <td>    0.049</td> <td>   -0.107</td> <td> 0.915</td> <td>   -0.102</td> <td>    0.091</td>\n",
       "</tr>\n",
       "<tr>\n",
       "  <th>61</th>    <td>   -0.0096</td> <td>    0.049</td> <td>   -0.195</td> <td> 0.846</td> <td>   -0.107</td> <td>    0.088</td>\n",
       "</tr>\n",
       "<tr>\n",
       "  <th>62</th>    <td>    0.0059</td> <td>    0.050</td> <td>    0.117</td> <td> 0.907</td> <td>   -0.093</td> <td>    0.104</td>\n",
       "</tr>\n",
       "<tr>\n",
       "  <th>63</th>    <td>    0.0241</td> <td>    0.047</td> <td>    0.515</td> <td> 0.607</td> <td>   -0.068</td> <td>    0.116</td>\n",
       "</tr>\n",
       "<tr>\n",
       "  <th>64</th>    <td>   -0.0462</td> <td>    0.050</td> <td>   -0.926</td> <td> 0.355</td> <td>   -0.144</td> <td>    0.052</td>\n",
       "</tr>\n",
       "<tr>\n",
       "  <th>65</th>    <td>    0.0694</td> <td>    0.048</td> <td>    1.443</td> <td> 0.150</td> <td>   -0.025</td> <td>    0.164</td>\n",
       "</tr>\n",
       "<tr>\n",
       "  <th>66</th>    <td>   -0.0384</td> <td>    0.050</td> <td>   -0.772</td> <td> 0.440</td> <td>   -0.136</td> <td>    0.059</td>\n",
       "</tr>\n",
       "<tr>\n",
       "  <th>67</th>    <td>    0.0672</td> <td>    0.049</td> <td>    1.360</td> <td> 0.175</td> <td>   -0.030</td> <td>    0.164</td>\n",
       "</tr>\n",
       "<tr>\n",
       "  <th>68</th>    <td>   -0.0070</td> <td>    0.050</td> <td>   -0.141</td> <td> 0.888</td> <td>   -0.104</td> <td>    0.091</td>\n",
       "</tr>\n",
       "<tr>\n",
       "  <th>69</th>    <td>    0.0741</td> <td>    0.047</td> <td>    1.590</td> <td> 0.113</td> <td>   -0.018</td> <td>    0.166</td>\n",
       "</tr>\n",
       "<tr>\n",
       "  <th>70</th>    <td>   -0.0801</td> <td>    0.049</td> <td>   -1.651</td> <td> 0.100</td> <td>   -0.175</td> <td>    0.015</td>\n",
       "</tr>\n",
       "<tr>\n",
       "  <th>71</th>    <td>    0.0118</td> <td>    0.049</td> <td>    0.242</td> <td> 0.809</td> <td>   -0.084</td> <td>    0.108</td>\n",
       "</tr>\n",
       "<tr>\n",
       "  <th>72</th>    <td>   -0.0042</td> <td>    0.047</td> <td>   -0.091</td> <td> 0.928</td> <td>   -0.096</td> <td>    0.088</td>\n",
       "</tr>\n",
       "<tr>\n",
       "  <th>73</th>    <td>   -0.0696</td> <td>    0.048</td> <td>   -1.437</td> <td> 0.151</td> <td>   -0.165</td> <td>    0.026</td>\n",
       "</tr>\n",
       "<tr>\n",
       "  <th>74</th>    <td>   -0.0449</td> <td>    0.052</td> <td>   -0.865</td> <td> 0.388</td> <td>   -0.147</td> <td>    0.057</td>\n",
       "</tr>\n",
       "<tr>\n",
       "  <th>75</th>    <td>   -0.0474</td> <td>    0.049</td> <td>   -0.965</td> <td> 0.335</td> <td>   -0.144</td> <td>    0.049</td>\n",
       "</tr>\n",
       "<tr>\n",
       "  <th>76</th>    <td>   -0.0024</td> <td>    0.051</td> <td>   -0.047</td> <td> 0.962</td> <td>   -0.102</td> <td>    0.097</td>\n",
       "</tr>\n",
       "<tr>\n",
       "  <th>77</th>    <td>   -0.0094</td> <td>    0.049</td> <td>   -0.190</td> <td> 0.850</td> <td>   -0.106</td> <td>    0.088</td>\n",
       "</tr>\n",
       "<tr>\n",
       "  <th>78</th>    <td>   -0.0172</td> <td>    0.051</td> <td>   -0.337</td> <td> 0.736</td> <td>   -0.118</td> <td>    0.083</td>\n",
       "</tr>\n",
       "<tr>\n",
       "  <th>79</th>    <td>   -0.1382</td> <td>    0.049</td> <td>   -2.818</td> <td> 0.005</td> <td>   -0.235</td> <td>   -0.042</td>\n",
       "</tr>\n",
       "<tr>\n",
       "  <th>80</th>    <td>    0.0602</td> <td>    0.048</td> <td>    1.256</td> <td> 0.210</td> <td>   -0.034</td> <td>    0.154</td>\n",
       "</tr>\n",
       "<tr>\n",
       "  <th>81</th>    <td>    0.0054</td> <td>    0.048</td> <td>    0.112</td> <td> 0.911</td> <td>   -0.089</td> <td>    0.099</td>\n",
       "</tr>\n",
       "<tr>\n",
       "  <th>82</th>    <td>    0.0391</td> <td>    0.047</td> <td>    0.824</td> <td> 0.411</td> <td>   -0.054</td> <td>    0.132</td>\n",
       "</tr>\n",
       "<tr>\n",
       "  <th>83</th>    <td>    0.0371</td> <td>    0.049</td> <td>    0.763</td> <td> 0.446</td> <td>   -0.059</td> <td>    0.133</td>\n",
       "</tr>\n",
       "<tr>\n",
       "  <th>84</th>    <td>   -0.0803</td> <td>    0.045</td> <td>   -1.781</td> <td> 0.076</td> <td>   -0.169</td> <td>    0.008</td>\n",
       "</tr>\n",
       "<tr>\n",
       "  <th>85</th>    <td>   -0.0038</td> <td>    0.047</td> <td>   -0.081</td> <td> 0.935</td> <td>   -0.097</td> <td>    0.089</td>\n",
       "</tr>\n",
       "<tr>\n",
       "  <th>86</th>    <td>   -0.0907</td> <td>    0.050</td> <td>   -1.814</td> <td> 0.070</td> <td>   -0.189</td> <td>    0.008</td>\n",
       "</tr>\n",
       "<tr>\n",
       "  <th>87</th>    <td>   -0.0315</td> <td>    0.052</td> <td>   -0.611</td> <td> 0.541</td> <td>   -0.133</td> <td>    0.070</td>\n",
       "</tr>\n",
       "<tr>\n",
       "  <th>88</th>    <td>    0.0826</td> <td>    0.049</td> <td>    1.671</td> <td> 0.096</td> <td>   -0.015</td> <td>    0.180</td>\n",
       "</tr>\n",
       "<tr>\n",
       "  <th>89</th>    <td>   -0.0484</td> <td>    0.050</td> <td>   -0.972</td> <td> 0.332</td> <td>   -0.146</td> <td>    0.049</td>\n",
       "</tr>\n",
       "<tr>\n",
       "  <th>90</th>    <td>    0.0259</td> <td>    0.050</td> <td>    0.524</td> <td> 0.600</td> <td>   -0.071</td> <td>    0.123</td>\n",
       "</tr>\n",
       "<tr>\n",
       "  <th>91</th>    <td>   -0.0433</td> <td>    0.048</td> <td>   -0.900</td> <td> 0.369</td> <td>   -0.138</td> <td>    0.051</td>\n",
       "</tr>\n",
       "<tr>\n",
       "  <th>92</th>    <td>   -0.0449</td> <td>    0.051</td> <td>   -0.880</td> <td> 0.379</td> <td>   -0.145</td> <td>    0.055</td>\n",
       "</tr>\n",
       "<tr>\n",
       "  <th>93</th>    <td>    0.0482</td> <td>    0.052</td> <td>    0.933</td> <td> 0.352</td> <td>   -0.053</td> <td>    0.150</td>\n",
       "</tr>\n",
       "<tr>\n",
       "  <th>94</th>    <td>    0.1287</td> <td>    0.050</td> <td>    2.566</td> <td> 0.011</td> <td>    0.030</td> <td>    0.227</td>\n",
       "</tr>\n",
       "<tr>\n",
       "  <th>95</th>    <td>    0.0163</td> <td>    0.049</td> <td>    0.330</td> <td> 0.742</td> <td>   -0.081</td> <td>    0.113</td>\n",
       "</tr>\n",
       "<tr>\n",
       "  <th>96</th>    <td>   -0.0369</td> <td>    0.049</td> <td>   -0.756</td> <td> 0.450</td> <td>   -0.133</td> <td>    0.059</td>\n",
       "</tr>\n",
       "<tr>\n",
       "  <th>97</th>    <td>    0.0500</td> <td>    0.051</td> <td>    0.988</td> <td> 0.324</td> <td>   -0.049</td> <td>    0.149</td>\n",
       "</tr>\n",
       "<tr>\n",
       "  <th>98</th>    <td>    0.0016</td> <td>    0.050</td> <td>    0.032</td> <td> 0.974</td> <td>   -0.096</td> <td>    0.099</td>\n",
       "</tr>\n",
       "<tr>\n",
       "  <th>99</th>    <td>   -0.0337</td> <td>    0.050</td> <td>   -0.668</td> <td> 0.505</td> <td>   -0.133</td> <td>    0.065</td>\n",
       "</tr>\n",
       "<tr>\n",
       "  <th>100</th>   <td>    0.0984</td> <td>    0.049</td> <td>    2.001</td> <td> 0.046</td> <td>    0.002</td> <td>    0.195</td>\n",
       "</tr>\n",
       "</table>\n",
       "<table class=\"simpletable\">\n",
       "<tr>\n",
       "  <th>Omnibus:</th>       <td> 1.434</td> <th>  Durbin-Watson:     </th> <td>   1.983</td>\n",
       "</tr>\n",
       "<tr>\n",
       "  <th>Prob(Omnibus):</th> <td> 0.488</td> <th>  Jarque-Bera (JB):  </th> <td>   1.513</td>\n",
       "</tr>\n",
       "<tr>\n",
       "  <th>Skew:</th>          <td> 0.123</td> <th>  Prob(JB):          </th> <td>   0.469</td>\n",
       "</tr>\n",
       "<tr>\n",
       "  <th>Kurtosis:</th>      <td> 2.889</td> <th>  Cond. No.          </th> <td>    2.46</td>\n",
       "</tr>\n",
       "</table><br/><br/>Notes:<br/>[1] Standard Errors assume that the covariance matrix of the errors is correctly specified."
      ],
      "text/plain": [
       "<class 'statsmodels.iolib.summary.Summary'>\n",
       "\"\"\"\n",
       "                            OLS Regression Results                            \n",
       "==============================================================================\n",
       "Dep. Variable:                      y   R-squared:                       0.253\n",
       "Model:                            OLS   Adj. R-squared:                  0.066\n",
       "Method:                 Least Squares   F-statistic:                     1.354\n",
       "Date:                Sun, 20 Jun 2021   Prob (F-statistic):             0.0227\n",
       "Time:                        22:29:56   Log-Likelihood:                -643.58\n",
       "No. Observations:                 500   AIC:                             1489.\n",
       "Df Residuals:                     399   BIC:                             1915.\n",
       "Df Model:                         100                                         \n",
       "Covariance Type:            nonrobust                                         \n",
       "==============================================================================\n",
       "                 coef    std err          t      P>|t|      [0.025      0.975]\n",
       "------------------------------------------------------------------------------\n",
       "const          0.0288      0.050      0.582      0.561      -0.069       0.126\n",
       "1              0.0483      0.053      0.908      0.364      -0.056       0.153\n",
       "2              0.0165      0.050      0.332      0.740      -0.081       0.114\n",
       "3             -0.0985      0.048     -2.068      0.039      -0.192      -0.005\n",
       "4             -0.0051      0.050     -0.101      0.919      -0.104       0.094\n",
       "5              0.1272      0.052      2.454      0.015       0.025       0.229\n",
       "6              0.0248      0.052      0.477      0.633      -0.077       0.127\n",
       "7              0.0695      0.050      1.401      0.162      -0.028       0.167\n",
       "8             -0.0049      0.047     -0.106      0.916      -0.096       0.087\n",
       "9             -0.0007      0.049     -0.015      0.988      -0.096       0.095\n",
       "10             0.1001      0.052      1.915      0.056      -0.003       0.203\n",
       "11             0.0422      0.049      0.866      0.387      -0.053       0.138\n",
       "12             0.1186      0.048      2.495      0.013       0.025       0.212\n",
       "13             0.0325      0.048      0.675      0.500      -0.062       0.127\n",
       "14            -0.0186      0.047     -0.399      0.690      -0.110       0.073\n",
       "15             0.0616      0.047      1.313      0.190      -0.031       0.154\n",
       "16            -0.0111      0.051     -0.218      0.827      -0.111       0.089\n",
       "17            -0.0017      0.048     -0.037      0.971      -0.095       0.092\n",
       "18             0.1005      0.047      2.137      0.033       0.008       0.193\n",
       "19             0.0324      0.049      0.669      0.504      -0.063       0.128\n",
       "20             0.0536      0.051      1.048      0.295      -0.047       0.154\n",
       "21            -0.0346      0.050     -0.690      0.490      -0.133       0.064\n",
       "22             0.0154      0.055      0.280      0.780      -0.092       0.123\n",
       "23             0.0335      0.049      0.687      0.492      -0.062       0.129\n",
       "24             0.0498      0.050      0.991      0.322      -0.049       0.149\n",
       "25             0.0164      0.049      0.333      0.739      -0.080       0.113\n",
       "26            -0.0225      0.048     -0.472      0.637      -0.116       0.071\n",
       "27             0.0312      0.048      0.645      0.519      -0.064       0.126\n",
       "28             0.0803      0.051      1.574      0.116      -0.020       0.181\n",
       "29            -0.0092      0.051     -0.180      0.858      -0.109       0.091\n",
       "30             0.0058      0.047      0.123      0.902      -0.086       0.098\n",
       "31             0.0382      0.050      0.764      0.445      -0.060       0.137\n",
       "32            -0.0118      0.051     -0.234      0.815      -0.111       0.088\n",
       "33            -0.0356      0.051     -0.694      0.488      -0.137       0.065\n",
       "34            -0.0343      0.049     -0.701      0.484      -0.130       0.062\n",
       "35            -0.0960      0.051     -1.888      0.060      -0.196       0.004\n",
       "36             0.0782      0.049      1.584      0.114      -0.019       0.175\n",
       "37             0.0645      0.048      1.340      0.181      -0.030       0.159\n",
       "38            -0.0079      0.047     -0.169      0.866      -0.100       0.084\n",
       "39            -0.0275      0.049     -0.566      0.572      -0.123       0.068\n",
       "40            -0.0148      0.050     -0.293      0.770      -0.114       0.084\n",
       "41             0.0999      0.048      2.073      0.039       0.005       0.195\n",
       "42             0.0073      0.047      0.156      0.876      -0.085       0.100\n",
       "43            -0.0688      0.051     -1.359      0.175      -0.168       0.031\n",
       "44            -0.0147      0.049     -0.299      0.765      -0.111       0.082\n",
       "45            -0.0255      0.049     -0.517      0.606      -0.122       0.071\n",
       "46            -0.1150      0.048     -2.375      0.018      -0.210      -0.020\n",
       "47             0.0596      0.047      1.265      0.207      -0.033       0.152\n",
       "48             0.0168      0.049      0.341      0.733      -0.080       0.113\n",
       "49             0.0337      0.046      0.726      0.468      -0.057       0.125\n",
       "50             0.0870      0.052      1.669      0.096      -0.016       0.189\n",
       "51             0.0669      0.049      1.354      0.177      -0.030       0.164\n",
       "52             0.0101      0.052      0.193      0.847      -0.093       0.113\n",
       "53             0.0146      0.047      0.312      0.755      -0.077       0.106\n",
       "54             0.0338      0.051      0.660      0.510      -0.067       0.134\n",
       "55             0.0293      0.049      0.597      0.551      -0.067       0.126\n",
       "56            -0.0255      0.049     -0.523      0.601      -0.121       0.070\n",
       "57             0.0972      0.049      1.983      0.048       0.001       0.194\n",
       "58             0.0040      0.050      0.080      0.936      -0.094       0.102\n",
       "59             0.0641      0.049      1.297      0.195      -0.033       0.161\n",
       "60            -0.0052      0.049     -0.107      0.915      -0.102       0.091\n",
       "61            -0.0096      0.049     -0.195      0.846      -0.107       0.088\n",
       "62             0.0059      0.050      0.117      0.907      -0.093       0.104\n",
       "63             0.0241      0.047      0.515      0.607      -0.068       0.116\n",
       "64            -0.0462      0.050     -0.926      0.355      -0.144       0.052\n",
       "65             0.0694      0.048      1.443      0.150      -0.025       0.164\n",
       "66            -0.0384      0.050     -0.772      0.440      -0.136       0.059\n",
       "67             0.0672      0.049      1.360      0.175      -0.030       0.164\n",
       "68            -0.0070      0.050     -0.141      0.888      -0.104       0.091\n",
       "69             0.0741      0.047      1.590      0.113      -0.018       0.166\n",
       "70            -0.0801      0.049     -1.651      0.100      -0.175       0.015\n",
       "71             0.0118      0.049      0.242      0.809      -0.084       0.108\n",
       "72            -0.0042      0.047     -0.091      0.928      -0.096       0.088\n",
       "73            -0.0696      0.048     -1.437      0.151      -0.165       0.026\n",
       "74            -0.0449      0.052     -0.865      0.388      -0.147       0.057\n",
       "75            -0.0474      0.049     -0.965      0.335      -0.144       0.049\n",
       "76            -0.0024      0.051     -0.047      0.962      -0.102       0.097\n",
       "77            -0.0094      0.049     -0.190      0.850      -0.106       0.088\n",
       "78            -0.0172      0.051     -0.337      0.736      -0.118       0.083\n",
       "79            -0.1382      0.049     -2.818      0.005      -0.235      -0.042\n",
       "80             0.0602      0.048      1.256      0.210      -0.034       0.154\n",
       "81             0.0054      0.048      0.112      0.911      -0.089       0.099\n",
       "82             0.0391      0.047      0.824      0.411      -0.054       0.132\n",
       "83             0.0371      0.049      0.763      0.446      -0.059       0.133\n",
       "84            -0.0803      0.045     -1.781      0.076      -0.169       0.008\n",
       "85            -0.0038      0.047     -0.081      0.935      -0.097       0.089\n",
       "86            -0.0907      0.050     -1.814      0.070      -0.189       0.008\n",
       "87            -0.0315      0.052     -0.611      0.541      -0.133       0.070\n",
       "88             0.0826      0.049      1.671      0.096      -0.015       0.180\n",
       "89            -0.0484      0.050     -0.972      0.332      -0.146       0.049\n",
       "90             0.0259      0.050      0.524      0.600      -0.071       0.123\n",
       "91            -0.0433      0.048     -0.900      0.369      -0.138       0.051\n",
       "92            -0.0449      0.051     -0.880      0.379      -0.145       0.055\n",
       "93             0.0482      0.052      0.933      0.352      -0.053       0.150\n",
       "94             0.1287      0.050      2.566      0.011       0.030       0.227\n",
       "95             0.0163      0.049      0.330      0.742      -0.081       0.113\n",
       "96            -0.0369      0.049     -0.756      0.450      -0.133       0.059\n",
       "97             0.0500      0.051      0.988      0.324      -0.049       0.149\n",
       "98             0.0016      0.050      0.032      0.974      -0.096       0.099\n",
       "99            -0.0337      0.050     -0.668      0.505      -0.133       0.065\n",
       "100            0.0984      0.049      2.001      0.046       0.002       0.195\n",
       "==============================================================================\n",
       "Omnibus:                        1.434   Durbin-Watson:                   1.983\n",
       "Prob(Omnibus):                  0.488   Jarque-Bera (JB):                1.513\n",
       "Skew:                           0.123   Prob(JB):                        0.469\n",
       "Kurtosis:                       2.889   Cond. No.                         2.46\n",
       "==============================================================================\n",
       "\n",
       "Notes:\n",
       "[1] Standard Errors assume that the covariance matrix of the errors is correctly specified.\n",
       "\"\"\""
      ]
     },
     "execution_count": 260,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "x = sm.add_constant(variable)\n",
    "result = sm.OLS(y,x).fit()\n",
    "result.summary()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "d388b34d-6daf-4ddd-856d-8f40350031f0",
   "metadata": {},
   "source": [
    "### Are any of the individual regression coefficients ‘‘statistically significant’’?"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "cdd838dc-49df-4825-9004-b8601298cba4",
   "metadata": {},
   "source": [
    "We assume that H0:variable didn't have statistically significant. Ha:variable have statistically significant.\n",
    "We also assume that alpha = 0.05. If P_value is less than alpha, we reject H0 and think that regression coefficients has statistically significant."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 261,
   "id": "906f8832-3dca-479c-af5e-dd26e80a95ed",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "const    False\n",
       "1        False\n",
       "2        False\n",
       "3         True\n",
       "4        False\n",
       "         ...  \n",
       "96       False\n",
       "97       False\n",
       "98       False\n",
       "99       False\n",
       "100       True\n",
       "Length: 101, dtype: bool"
      ]
     },
     "execution_count": 261,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "result.pvalues<0.05"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 262,
   "id": "709787d0-a850-4884-81a9-15c07b29baf8",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "3      0.039328\n",
       "5      0.014563\n",
       "12     0.012981\n",
       "18     0.033187\n",
       "41     0.038784\n",
       "46     0.018005\n",
       "57     0.048062\n",
       "79     0.005071\n",
       "94     0.010651\n",
       "100    0.046077\n",
       "dtype: float64"
      ]
     },
     "execution_count": 262,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "result.pvalues[result.pvalues<0.05]"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "8dc1943d-7476-47d0-ae64-fbee2210ae51",
   "metadata": {},
   "source": [
    "Yes, there are 10 variable have statistically significant."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "ec932a6a-1c9a-4c83-a018-fc5d5f08cb6f",
   "metadata": {},
   "source": [
    "### Is the omnibus F-statistic for the regression ‘‘statistically significant’’?"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "0263ba9c-8d90-46f4-a423-53095a74debe",
   "metadata": {},
   "source": [
    "Because the F-statistic values is 0.488 which is greater than alpha, it isn't statistically significant."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "60867306-c1ec-41dc-a8da-f1438755e487",
   "metadata": {},
   "source": [
    "### Is this what you expected to observe?"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "ab30b1f3-78f1-42f7-9a88-2219dd160459",
   "metadata": {},
   "source": [
    "Yes, it is."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "0c2b172c-f583-4e9a-8cd2-4f83bcb0001e",
   "metadata": {},
   "source": [
    "## (B)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 263,
   "id": "60bfe768-cd15-47f0-a897-636c2b1443e8",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>0</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>79</th>\n",
       "      <td>2.818127</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>94</th>\n",
       "      <td>2.566029</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>12</th>\n",
       "      <td>2.495491</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "           0\n",
       "79  2.818127\n",
       "94  2.566029\n",
       "12  2.495491"
      ]
     },
     "execution_count": 263,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "tvalue = np.abs(result.tvalues)\n",
    "df_t = pd.DataFrame(tvalue)\n",
    "df_t.nlargest(3,0)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 264,
   "id": "ba0fd703-38de-4454-a056-6046f5b7eeae",
   "metadata": {},
   "outputs": [],
   "source": [
    "x1 = variable[85]\n",
    "x2 = variable[26]\n",
    "x3 = variable[11]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 265,
   "id": "d1d2019e-979f-4fbc-8028-b067ad337f80",
   "metadata": {},
   "outputs": [],
   "source": [
    "df1 = pd.DataFrame(list(zip(x1, x2, x3)))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 266,
   "id": "5ecb9f05-4aae-4153-b6c6-7e5602b33369",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>0</th>\n",
       "      <th>1</th>\n",
       "      <th>2</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>0.930934</td>\n",
       "      <td>-1.125765</td>\n",
       "      <td>-1.126913</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>-1.287767</td>\n",
       "      <td>-0.291119</td>\n",
       "      <td>2.465474</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>1.447364</td>\n",
       "      <td>-0.114974</td>\n",
       "      <td>0.110616</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>0.869305</td>\n",
       "      <td>-2.157168</td>\n",
       "      <td>0.226826</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>0.071862</td>\n",
       "      <td>-0.107178</td>\n",
       "      <td>-0.208000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>...</th>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>495</th>\n",
       "      <td>-0.296997</td>\n",
       "      <td>-0.166106</td>\n",
       "      <td>2.197508</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>496</th>\n",
       "      <td>-1.095302</td>\n",
       "      <td>0.461182</td>\n",
       "      <td>1.187563</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>497</th>\n",
       "      <td>0.241763</td>\n",
       "      <td>0.468538</td>\n",
       "      <td>-2.288667</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>498</th>\n",
       "      <td>-0.297603</td>\n",
       "      <td>0.237073</td>\n",
       "      <td>-0.599472</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>499</th>\n",
       "      <td>1.916206</td>\n",
       "      <td>0.792166</td>\n",
       "      <td>-1.970795</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>500 rows × 3 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "            0         1         2\n",
       "0    0.930934 -1.125765 -1.126913\n",
       "1   -1.287767 -0.291119  2.465474\n",
       "2    1.447364 -0.114974  0.110616\n",
       "3    0.869305 -2.157168  0.226826\n",
       "4    0.071862 -0.107178 -0.208000\n",
       "..        ...       ...       ...\n",
       "495 -0.296997 -0.166106  2.197508\n",
       "496 -1.095302  0.461182  1.187563\n",
       "497  0.241763  0.468538 -2.288667\n",
       "498 -0.297603  0.237073 -0.599472\n",
       "499  1.916206  0.792166 -1.970795\n",
       "\n",
       "[500 rows x 3 columns]"
      ]
     },
     "execution_count": 266,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df1"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 267,
   "id": "2c40c672-cb11-467c-ba24-faa57a2864e5",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<table class=\"simpletable\">\n",
       "<caption>OLS Regression Results</caption>\n",
       "<tr>\n",
       "  <th>Dep. Variable:</th>            <td>y</td>        <th>  R-squared:         </th> <td>   0.001</td>\n",
       "</tr>\n",
       "<tr>\n",
       "  <th>Model:</th>                   <td>OLS</td>       <th>  Adj. R-squared:    </th> <td>  -0.005</td>\n",
       "</tr>\n",
       "<tr>\n",
       "  <th>Method:</th>             <td>Least Squares</td>  <th>  F-statistic:       </th> <td>  0.1443</td>\n",
       "</tr>\n",
       "<tr>\n",
       "  <th>Date:</th>             <td>Sun, 20 Jun 2021</td> <th>  Prob (F-statistic):</th>  <td> 0.933</td> \n",
       "</tr>\n",
       "<tr>\n",
       "  <th>Time:</th>                 <td>22:30:13</td>     <th>  Log-Likelihood:    </th> <td> -716.40</td>\n",
       "</tr>\n",
       "<tr>\n",
       "  <th>No. Observations:</th>      <td>   500</td>      <th>  AIC:               </th> <td>   1441.</td>\n",
       "</tr>\n",
       "<tr>\n",
       "  <th>Df Residuals:</th>          <td>   496</td>      <th>  BIC:               </th> <td>   1458.</td>\n",
       "</tr>\n",
       "<tr>\n",
       "  <th>Df Model:</th>              <td>     3</td>      <th>                     </th>     <td> </td>   \n",
       "</tr>\n",
       "<tr>\n",
       "  <th>Covariance Type:</th>      <td>nonrobust</td>    <th>                     </th>     <td> </td>   \n",
       "</tr>\n",
       "</table>\n",
       "<table class=\"simpletable\">\n",
       "<tr>\n",
       "    <td></td>       <th>coef</th>     <th>std err</th>      <th>t</th>      <th>P>|t|</th>  <th>[0.025</th>    <th>0.975]</th>  \n",
       "</tr>\n",
       "<tr>\n",
       "  <th>const</th> <td>    0.0158</td> <td>    0.046</td> <td>    0.346</td> <td> 0.730</td> <td>   -0.074</td> <td>    0.105</td>\n",
       "</tr>\n",
       "<tr>\n",
       "  <th>0</th>     <td>   -0.0189</td> <td>    0.045</td> <td>   -0.423</td> <td> 0.673</td> <td>   -0.107</td> <td>    0.069</td>\n",
       "</tr>\n",
       "<tr>\n",
       "  <th>1</th>     <td>    0.0114</td> <td>    0.043</td> <td>    0.262</td> <td> 0.793</td> <td>   -0.074</td> <td>    0.096</td>\n",
       "</tr>\n",
       "<tr>\n",
       "  <th>2</th>     <td>    0.0194</td> <td>    0.045</td> <td>    0.434</td> <td> 0.664</td> <td>   -0.068</td> <td>    0.107</td>\n",
       "</tr>\n",
       "</table>\n",
       "<table class=\"simpletable\">\n",
       "<tr>\n",
       "  <th>Omnibus:</th>       <td> 2.163</td> <th>  Durbin-Watson:     </th> <td>   1.972</td>\n",
       "</tr>\n",
       "<tr>\n",
       "  <th>Prob(Omnibus):</th> <td> 0.339</td> <th>  Jarque-Bera (JB):  </th> <td>   2.113</td>\n",
       "</tr>\n",
       "<tr>\n",
       "  <th>Skew:</th>          <td> 0.159</td> <th>  Prob(JB):          </th> <td>   0.348</td>\n",
       "</tr>\n",
       "<tr>\n",
       "  <th>Kurtosis:</th>      <td> 2.992</td> <th>  Cond. No.          </th> <td>    1.10</td>\n",
       "</tr>\n",
       "</table><br/><br/>Notes:<br/>[1] Standard Errors assume that the covariance matrix of the errors is correctly specified."
      ],
      "text/plain": [
       "<class 'statsmodels.iolib.summary.Summary'>\n",
       "\"\"\"\n",
       "                            OLS Regression Results                            \n",
       "==============================================================================\n",
       "Dep. Variable:                      y   R-squared:                       0.001\n",
       "Model:                            OLS   Adj. R-squared:                 -0.005\n",
       "Method:                 Least Squares   F-statistic:                    0.1443\n",
       "Date:                Sun, 20 Jun 2021   Prob (F-statistic):              0.933\n",
       "Time:                        22:30:13   Log-Likelihood:                -716.40\n",
       "No. Observations:                 500   AIC:                             1441.\n",
       "Df Residuals:                     496   BIC:                             1458.\n",
       "Df Model:                           3                                         \n",
       "Covariance Type:            nonrobust                                         \n",
       "==============================================================================\n",
       "                 coef    std err          t      P>|t|      [0.025      0.975]\n",
       "------------------------------------------------------------------------------\n",
       "const          0.0158      0.046      0.346      0.730      -0.074       0.105\n",
       "0             -0.0189      0.045     -0.423      0.673      -0.107       0.069\n",
       "1              0.0114      0.043      0.262      0.793      -0.074       0.096\n",
       "2              0.0194      0.045      0.434      0.664      -0.068       0.107\n",
       "==============================================================================\n",
       "Omnibus:                        2.163   Durbin-Watson:                   1.972\n",
       "Prob(Omnibus):                  0.339   Jarque-Bera (JB):                2.113\n",
       "Skew:                           0.159   Prob(JB):                        0.348\n",
       "Kurtosis:                       2.992   Cond. No.                         1.10\n",
       "==============================================================================\n",
       "\n",
       "Notes:\n",
       "[1] Standard Errors assume that the covariance matrix of the errors is correctly specified.\n",
       "\"\"\""
      ]
     },
     "execution_count": 267,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "x1 = sm.add_constant(df1)\n",
    "result1 = sm.OLS(y,x1).fit()\n",
    "result1.summary()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 268,
   "id": "8577fed7-1a59-459f-844c-944de1bc14e7",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "const    0.729654\n",
       "0        0.672729\n",
       "1        0.793199\n",
       "2        0.664207\n",
       "dtype: float64"
      ]
     },
     "execution_count": 268,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "result1.pvalues"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "cbb58bab-778a-436d-88ec-678d8bd1a2dc",
   "metadata": {},
   "source": [
    "### Are the individual coefficients ‘‘statistically significant’’? "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 269,
   "id": "de87ad8a-b49c-4f6f-9099-f188da1a46ca",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "const    False\n",
       "0        False\n",
       "1        False\n",
       "2        False\n",
       "dtype: bool"
      ]
     },
     "execution_count": 269,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "result1.pvalues<0.05"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "65a566d9-8d85-48f2-8f3d-dd7a64548de5",
   "metadata": {},
   "source": [
    "Two variables are statistically significant and one isn't statistically significant."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "1d4b5b2d-19f7-4da7-88e9-ff7e48f8ee8f",
   "metadata": {},
   "source": [
    "### What about the omnibus F?"
   ]
  },
  {
   "cell_type": "raw",
   "id": "1229ec0e-52f6-4f03-855e-9bf199c8e00b",
   "metadata": {},
   "source": [
    "It is 0.339 great than 0.05, and it isn't statistically significant."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "90d448d9-cdb1-43d0-ac52-93f0a717b207",
   "metadata": {},
   "source": [
    "### What happens to the p-values compared to part (a)?"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "b090542b-2ff9-423c-b9ad-9924e10a6ed6",
   "metadata": {},
   "source": [
    "p-values because smaller."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "5b3d6c31-fae5-4643-bbad-245eacfc0626",
   "metadata": {},
   "source": [
    "## (c)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 285,
   "id": "8e98fce0-18a4-4f76-b1a1-3808ed32f52f",
   "metadata": {},
   "outputs": [],
   "source": [
    "xx = {}\n",
    "for i in range(100):\n",
    "    j = i+1 \n",
    "    xx[j] = variable[j]\n",
    "    xxpd = pd.DataFrame(xx)\n",
    "    x2 = sm.add_constant(xxpd)\n",
    "    result2 = sm.OLS(y,x2).fit()\n",
    "    if result2.fvalue<9.2:\n",
    "        xx.pop(j)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 286,
   "id": "f07df67c-0c7b-484d-bee5-33e5fff9e72b",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<table class=\"simpletable\">\n",
       "<caption>OLS Regression Results</caption>\n",
       "<tr>\n",
       "  <th>Dep. Variable:</th>            <td>y</td>        <th>  R-squared:         </th> <td>   0.043</td>\n",
       "</tr>\n",
       "<tr>\n",
       "  <th>Model:</th>                   <td>OLS</td>       <th>  Adj. R-squared:    </th> <td>   0.038</td>\n",
       "</tr>\n",
       "<tr>\n",
       "  <th>Method:</th>             <td>Least Squares</td>  <th>  F-statistic:       </th> <td>   7.496</td>\n",
       "</tr>\n",
       "<tr>\n",
       "  <th>Date:</th>             <td>Sun, 20 Jun 2021</td> <th>  Prob (F-statistic):</th> <td>6.48e-05</td>\n",
       "</tr>\n",
       "<tr>\n",
       "  <th>Time:</th>                 <td>22:31:02</td>     <th>  Log-Likelihood:    </th> <td> -705.53</td>\n",
       "</tr>\n",
       "<tr>\n",
       "  <th>No. Observations:</th>      <td>   500</td>      <th>  AIC:               </th> <td>   1419.</td>\n",
       "</tr>\n",
       "<tr>\n",
       "  <th>Df Residuals:</th>          <td>   496</td>      <th>  BIC:               </th> <td>   1436.</td>\n",
       "</tr>\n",
       "<tr>\n",
       "  <th>Df Model:</th>              <td>     3</td>      <th>                     </th>     <td> </td>   \n",
       "</tr>\n",
       "<tr>\n",
       "  <th>Covariance Type:</th>      <td>nonrobust</td>    <th>                     </th>     <td> </td>   \n",
       "</tr>\n",
       "</table>\n",
       "<table class=\"simpletable\">\n",
       "<tr>\n",
       "    <td></td>       <th>coef</th>     <th>std err</th>      <th>t</th>      <th>P>|t|</th>  <th>[0.025</th>    <th>0.975]</th>  \n",
       "</tr>\n",
       "<tr>\n",
       "  <th>const</th> <td>    0.0041</td> <td>    0.045</td> <td>    0.092</td> <td> 0.927</td> <td>   -0.084</td> <td>    0.092</td>\n",
       "</tr>\n",
       "<tr>\n",
       "  <th>3</th>     <td>   -0.1395</td> <td>    0.043</td> <td>   -3.272</td> <td> 0.001</td> <td>   -0.223</td> <td>   -0.056</td>\n",
       "</tr>\n",
       "<tr>\n",
       "  <th>12</th>    <td>    0.1342</td> <td>    0.044</td> <td>    3.063</td> <td> 0.002</td> <td>    0.048</td> <td>    0.220</td>\n",
       "</tr>\n",
       "<tr>\n",
       "  <th>100</th>   <td>    0.0817</td> <td>    0.045</td> <td>    1.832</td> <td> 0.067</td> <td>   -0.006</td> <td>    0.169</td>\n",
       "</tr>\n",
       "</table>\n",
       "<table class=\"simpletable\">\n",
       "<tr>\n",
       "  <th>Omnibus:</th>       <td> 2.650</td> <th>  Durbin-Watson:     </th> <td>   1.953</td>\n",
       "</tr>\n",
       "<tr>\n",
       "  <th>Prob(Omnibus):</th> <td> 0.266</td> <th>  Jarque-Bera (JB):  </th> <td>   2.635</td>\n",
       "</tr>\n",
       "<tr>\n",
       "  <th>Skew:</th>          <td> 0.177</td> <th>  Prob(JB):          </th> <td>   0.268</td>\n",
       "</tr>\n",
       "<tr>\n",
       "  <th>Kurtosis:</th>      <td> 2.968</td> <th>  Cond. No.          </th> <td>    1.10</td>\n",
       "</tr>\n",
       "</table><br/><br/>Notes:<br/>[1] Standard Errors assume that the covariance matrix of the errors is correctly specified."
      ],
      "text/plain": [
       "<class 'statsmodels.iolib.summary.Summary'>\n",
       "\"\"\"\n",
       "                            OLS Regression Results                            \n",
       "==============================================================================\n",
       "Dep. Variable:                      y   R-squared:                       0.043\n",
       "Model:                            OLS   Adj. R-squared:                  0.038\n",
       "Method:                 Least Squares   F-statistic:                     7.496\n",
       "Date:                Sun, 20 Jun 2021   Prob (F-statistic):           6.48e-05\n",
       "Time:                        22:31:02   Log-Likelihood:                -705.53\n",
       "No. Observations:                 500   AIC:                             1419.\n",
       "Df Residuals:                     496   BIC:                             1436.\n",
       "Df Model:                           3                                         \n",
       "Covariance Type:            nonrobust                                         \n",
       "==============================================================================\n",
       "                 coef    std err          t      P>|t|      [0.025      0.975]\n",
       "------------------------------------------------------------------------------\n",
       "const          0.0041      0.045      0.092      0.927      -0.084       0.092\n",
       "3             -0.1395      0.043     -3.272      0.001      -0.223      -0.056\n",
       "12             0.1342      0.044      3.063      0.002       0.048       0.220\n",
       "100            0.0817      0.045      1.832      0.067      -0.006       0.169\n",
       "==============================================================================\n",
       "Omnibus:                        2.650   Durbin-Watson:                   1.953\n",
       "Prob(Omnibus):                  0.266   Jarque-Bera (JB):                2.635\n",
       "Skew:                           0.177   Prob(JB):                        0.268\n",
       "Kurtosis:                       2.968   Cond. No.                         1.10\n",
       "==============================================================================\n",
       "\n",
       "Notes:\n",
       "[1] Standard Errors assume that the covariance matrix of the errors is correctly specified.\n",
       "\"\"\""
      ]
     },
     "execution_count": 286,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "result2.summary()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 287,
   "id": "c6b750a7-0893-481f-a781-3971c10db4b9",
   "metadata": {},
   "outputs": [],
   "source": [
    "model = result2"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "532d8e39-f2d6-483f-84b7-e51898859f1b",
   "metadata": {},
   "source": [
    "Model is the best model after I use stepwise regression. "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 288,
   "id": "a5a1065e-9de5-4215-9336-d23e4203325e",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "const    0.091726\n",
       "3       -3.272340\n",
       "12       3.063474\n",
       "100      1.832346\n",
       "dtype: float64"
      ]
     },
     "execution_count": 288,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "model.tvalues"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "6ede7198-6ddb-467a-91fd-ca356b7f0936",
   "metadata": {},
   "source": [
    "This is individual t-statistics."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "1eb22b5e-cf6b-4291-b0e8-bc633aa9f531",
   "metadata": {},
   "source": [
    "Omnibus F for this model is 0.878."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 289,
   "id": "418116cd-6650-47b6-ba27-24fa8c9a7964",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "-0.2180710877214318"
      ]
     },
     "execution_count": 289,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "list(result.tvalues)[16]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 290,
   "id": "83662fcf-3f77-4ac8-a5ff-85bea9c00bf1",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "-0.9654953639307728"
      ]
     },
     "execution_count": 290,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "list(result.tvalues)[75]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 291,
   "id": "85c265e7-ab76-46a1-adad-63fadcc8edf2",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "2.000925203275272"
      ]
     },
     "execution_count": 291,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "list(result.tvalues)[100]"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "e3cc011b-b16e-492b-8347-19c670886ef0",
   "metadata": {},
   "source": [
    "The omnibus F in (a) is 0.488 which is great than 0.266. The t-statistics is greater than (a)."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "3b6e4f1b-8e87-49bc-9565-28638290e742",
   "metadata": {},
   "source": [
    "## (d)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "65ed92cd-0dfd-43b3-82ca-cc19be98a1de",
   "metadata": {},
   "source": [
    "(c) uses the method in this week to find a best model for these data. So C's model is also suit to d."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "60aecf0c-7544-427e-84ac-3cec364f1dfe",
   "metadata": {},
   "source": [
    "I think this best model is better because it has smaller pvalues and so on."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "5a3a195b-f8c6-4f85-b23a-9e4e2003c5da",
   "metadata": {},
   "source": [
    "## (e)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 297,
   "id": "7de94003-0366-416f-878c-51f984c1c97e",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<table class=\"simpletable\">\n",
       "<caption>OLS Regression Results</caption>\n",
       "<tr>\n",
       "  <th>Dep. Variable:</th>            <td>y</td>        <th>  R-squared:         </th> <td>   0.180</td>\n",
       "</tr>\n",
       "<tr>\n",
       "  <th>Model:</th>                   <td>OLS</td>       <th>  Adj. R-squared:    </th> <td>  -0.026</td>\n",
       "</tr>\n",
       "<tr>\n",
       "  <th>Method:</th>             <td>Least Squares</td>  <th>  F-statistic:       </th> <td>  0.8730</td>\n",
       "</tr>\n",
       "<tr>\n",
       "  <th>Date:</th>             <td>Sun, 20 Jun 2021</td> <th>  Prob (F-statistic):</th>  <td> 0.792</td> \n",
       "</tr>\n",
       "<tr>\n",
       "  <th>Time:</th>                 <td>22:53:45</td>     <th>  Log-Likelihood:    </th> <td> -649.85</td>\n",
       "</tr>\n",
       "<tr>\n",
       "  <th>No. Observations:</th>      <td>   500</td>      <th>  AIC:               </th> <td>   1502.</td>\n",
       "</tr>\n",
       "<tr>\n",
       "  <th>Df Residuals:</th>          <td>   399</td>      <th>  BIC:               </th> <td>   1927.</td>\n",
       "</tr>\n",
       "<tr>\n",
       "  <th>Df Model:</th>              <td>   100</td>      <th>                     </th>     <td> </td>   \n",
       "</tr>\n",
       "<tr>\n",
       "  <th>Covariance Type:</th>      <td>nonrobust</td>    <th>                     </th>     <td> </td>   \n",
       "</tr>\n",
       "</table>\n",
       "<table class=\"simpletable\">\n",
       "<tr>\n",
       "    <td></td>       <th>coef</th>     <th>std err</th>      <th>t</th>      <th>P>|t|</th>  <th>[0.025</th>    <th>0.975]</th>  \n",
       "</tr>\n",
       "<tr>\n",
       "  <th>const</th> <td>   -0.0053</td> <td>    0.049</td> <td>   -0.110</td> <td> 0.913</td> <td>   -0.101</td> <td>    0.090</td>\n",
       "</tr>\n",
       "<tr>\n",
       "  <th>1</th>     <td>    0.0226</td> <td>    0.054</td> <td>    0.420</td> <td> 0.675</td> <td>   -0.083</td> <td>    0.128</td>\n",
       "</tr>\n",
       "<tr>\n",
       "  <th>2</th>     <td>    0.0008</td> <td>    0.048</td> <td>    0.018</td> <td> 0.986</td> <td>   -0.093</td> <td>    0.095</td>\n",
       "</tr>\n",
       "<tr>\n",
       "  <th>3</th>     <td>    0.0611</td> <td>    0.048</td> <td>    1.263</td> <td> 0.207</td> <td>   -0.034</td> <td>    0.156</td>\n",
       "</tr>\n",
       "<tr>\n",
       "  <th>4</th>     <td>    0.0172</td> <td>    0.050</td> <td>    0.343</td> <td> 0.732</td> <td>   -0.081</td> <td>    0.116</td>\n",
       "</tr>\n",
       "<tr>\n",
       "  <th>5</th>     <td>   -0.0186</td> <td>    0.049</td> <td>   -0.380</td> <td> 0.704</td> <td>   -0.115</td> <td>    0.078</td>\n",
       "</tr>\n",
       "<tr>\n",
       "  <th>6</th>     <td>   -0.0174</td> <td>    0.048</td> <td>   -0.364</td> <td> 0.716</td> <td>   -0.112</td> <td>    0.077</td>\n",
       "</tr>\n",
       "<tr>\n",
       "  <th>7</th>     <td>   -0.0489</td> <td>    0.046</td> <td>   -1.074</td> <td> 0.284</td> <td>   -0.138</td> <td>    0.041</td>\n",
       "</tr>\n",
       "<tr>\n",
       "  <th>8</th>     <td>   -0.0497</td> <td>    0.050</td> <td>   -0.991</td> <td> 0.322</td> <td>   -0.148</td> <td>    0.049</td>\n",
       "</tr>\n",
       "<tr>\n",
       "  <th>9</th>     <td>   -0.0065</td> <td>    0.049</td> <td>   -0.133</td> <td> 0.894</td> <td>   -0.102</td> <td>    0.089</td>\n",
       "</tr>\n",
       "<tr>\n",
       "  <th>10</th>    <td>    0.0476</td> <td>    0.049</td> <td>    0.980</td> <td> 0.328</td> <td>   -0.048</td> <td>    0.143</td>\n",
       "</tr>\n",
       "<tr>\n",
       "  <th>11</th>    <td>   -0.0082</td> <td>    0.050</td> <td>   -0.162</td> <td> 0.871</td> <td>   -0.107</td> <td>    0.091</td>\n",
       "</tr>\n",
       "<tr>\n",
       "  <th>12</th>    <td>    0.0370</td> <td>    0.052</td> <td>    0.713</td> <td> 0.476</td> <td>   -0.065</td> <td>    0.139</td>\n",
       "</tr>\n",
       "<tr>\n",
       "  <th>13</th>    <td>   -0.0612</td> <td>    0.050</td> <td>   -1.233</td> <td> 0.218</td> <td>   -0.159</td> <td>    0.036</td>\n",
       "</tr>\n",
       "<tr>\n",
       "  <th>14</th>    <td>    0.0273</td> <td>    0.055</td> <td>    0.494</td> <td> 0.622</td> <td>   -0.081</td> <td>    0.136</td>\n",
       "</tr>\n",
       "<tr>\n",
       "  <th>15</th>    <td>   -0.0089</td> <td>    0.053</td> <td>   -0.168</td> <td> 0.866</td> <td>   -0.113</td> <td>    0.095</td>\n",
       "</tr>\n",
       "<tr>\n",
       "  <th>16</th>    <td>    0.0348</td> <td>    0.049</td> <td>    0.703</td> <td> 0.482</td> <td>   -0.062</td> <td>    0.132</td>\n",
       "</tr>\n",
       "<tr>\n",
       "  <th>17</th>    <td>   -0.0183</td> <td>    0.048</td> <td>   -0.377</td> <td> 0.707</td> <td>   -0.114</td> <td>    0.077</td>\n",
       "</tr>\n",
       "<tr>\n",
       "  <th>18</th>    <td>    0.0499</td> <td>    0.052</td> <td>    0.966</td> <td> 0.334</td> <td>   -0.052</td> <td>    0.151</td>\n",
       "</tr>\n",
       "<tr>\n",
       "  <th>19</th>    <td>    0.0216</td> <td>    0.048</td> <td>    0.450</td> <td> 0.653</td> <td>   -0.073</td> <td>    0.116</td>\n",
       "</tr>\n",
       "<tr>\n",
       "  <th>20</th>    <td>   -0.0554</td> <td>    0.048</td> <td>   -1.153</td> <td> 0.249</td> <td>   -0.150</td> <td>    0.039</td>\n",
       "</tr>\n",
       "<tr>\n",
       "  <th>21</th>    <td>   -0.0703</td> <td>    0.052</td> <td>   -1.348</td> <td> 0.178</td> <td>   -0.173</td> <td>    0.032</td>\n",
       "</tr>\n",
       "<tr>\n",
       "  <th>22</th>    <td>    0.0278</td> <td>    0.051</td> <td>    0.544</td> <td> 0.587</td> <td>   -0.073</td> <td>    0.128</td>\n",
       "</tr>\n",
       "<tr>\n",
       "  <th>23</th>    <td>    0.0092</td> <td>    0.053</td> <td>    0.174</td> <td> 0.862</td> <td>   -0.095</td> <td>    0.113</td>\n",
       "</tr>\n",
       "<tr>\n",
       "  <th>24</th>    <td>    0.0110</td> <td>    0.051</td> <td>    0.218</td> <td> 0.827</td> <td>   -0.088</td> <td>    0.110</td>\n",
       "</tr>\n",
       "<tr>\n",
       "  <th>25</th>    <td>    0.0580</td> <td>    0.047</td> <td>    1.245</td> <td> 0.214</td> <td>   -0.034</td> <td>    0.150</td>\n",
       "</tr>\n",
       "<tr>\n",
       "  <th>26</th>    <td>    0.0261</td> <td>    0.051</td> <td>    0.516</td> <td> 0.606</td> <td>   -0.073</td> <td>    0.125</td>\n",
       "</tr>\n",
       "<tr>\n",
       "  <th>27</th>    <td>    0.0273</td> <td>    0.048</td> <td>    0.568</td> <td> 0.571</td> <td>   -0.067</td> <td>    0.122</td>\n",
       "</tr>\n",
       "<tr>\n",
       "  <th>28</th>    <td>    0.0630</td> <td>    0.049</td> <td>    1.281</td> <td> 0.201</td> <td>   -0.034</td> <td>    0.160</td>\n",
       "</tr>\n",
       "<tr>\n",
       "  <th>29</th>    <td>   -0.0355</td> <td>    0.051</td> <td>   -0.701</td> <td> 0.484</td> <td>   -0.135</td> <td>    0.064</td>\n",
       "</tr>\n",
       "<tr>\n",
       "  <th>30</th>    <td>    0.0398</td> <td>    0.053</td> <td>    0.758</td> <td> 0.449</td> <td>   -0.063</td> <td>    0.143</td>\n",
       "</tr>\n",
       "<tr>\n",
       "  <th>31</th>    <td>    0.0523</td> <td>    0.046</td> <td>    1.130</td> <td> 0.259</td> <td>   -0.039</td> <td>    0.143</td>\n",
       "</tr>\n",
       "<tr>\n",
       "  <th>32</th>    <td>   -0.0949</td> <td>    0.049</td> <td>   -1.945</td> <td> 0.053</td> <td>   -0.191</td> <td>    0.001</td>\n",
       "</tr>\n",
       "<tr>\n",
       "  <th>33</th>    <td>    0.0254</td> <td>    0.050</td> <td>    0.506</td> <td> 0.613</td> <td>   -0.073</td> <td>    0.124</td>\n",
       "</tr>\n",
       "<tr>\n",
       "  <th>34</th>    <td>   -0.0257</td> <td>    0.047</td> <td>   -0.542</td> <td> 0.588</td> <td>   -0.119</td> <td>    0.068</td>\n",
       "</tr>\n",
       "<tr>\n",
       "  <th>35</th>    <td>   -0.0144</td> <td>    0.049</td> <td>   -0.294</td> <td> 0.769</td> <td>   -0.111</td> <td>    0.082</td>\n",
       "</tr>\n",
       "<tr>\n",
       "  <th>36</th>    <td>    0.0258</td> <td>    0.053</td> <td>    0.482</td> <td> 0.630</td> <td>   -0.079</td> <td>    0.131</td>\n",
       "</tr>\n",
       "<tr>\n",
       "  <th>37</th>    <td>   -0.0292</td> <td>    0.049</td> <td>   -0.592</td> <td> 0.554</td> <td>   -0.126</td> <td>    0.068</td>\n",
       "</tr>\n",
       "<tr>\n",
       "  <th>38</th>    <td>   -0.0771</td> <td>    0.051</td> <td>   -1.517</td> <td> 0.130</td> <td>   -0.177</td> <td>    0.023</td>\n",
       "</tr>\n",
       "<tr>\n",
       "  <th>39</th>    <td>    0.0237</td> <td>    0.048</td> <td>    0.493</td> <td> 0.622</td> <td>   -0.071</td> <td>    0.118</td>\n",
       "</tr>\n",
       "<tr>\n",
       "  <th>40</th>    <td>   -0.0731</td> <td>    0.051</td> <td>   -1.421</td> <td> 0.156</td> <td>   -0.174</td> <td>    0.028</td>\n",
       "</tr>\n",
       "<tr>\n",
       "  <th>41</th>    <td>   -0.0230</td> <td>    0.049</td> <td>   -0.469</td> <td> 0.639</td> <td>   -0.119</td> <td>    0.073</td>\n",
       "</tr>\n",
       "<tr>\n",
       "  <th>42</th>    <td>    0.0028</td> <td>    0.052</td> <td>    0.055</td> <td> 0.956</td> <td>   -0.099</td> <td>    0.104</td>\n",
       "</tr>\n",
       "<tr>\n",
       "  <th>43</th>    <td>   -0.0453</td> <td>    0.051</td> <td>   -0.880</td> <td> 0.379</td> <td>   -0.146</td> <td>    0.056</td>\n",
       "</tr>\n",
       "<tr>\n",
       "  <th>44</th>    <td>    0.0302</td> <td>    0.052</td> <td>    0.587</td> <td> 0.558</td> <td>   -0.071</td> <td>    0.132</td>\n",
       "</tr>\n",
       "<tr>\n",
       "  <th>45</th>    <td>    0.0440</td> <td>    0.049</td> <td>    0.906</td> <td> 0.365</td> <td>   -0.051</td> <td>    0.139</td>\n",
       "</tr>\n",
       "<tr>\n",
       "  <th>46</th>    <td>   -0.0487</td> <td>    0.050</td> <td>   -0.973</td> <td> 0.331</td> <td>   -0.147</td> <td>    0.050</td>\n",
       "</tr>\n",
       "<tr>\n",
       "  <th>47</th>    <td>    0.0686</td> <td>    0.050</td> <td>    1.374</td> <td> 0.170</td> <td>   -0.030</td> <td>    0.167</td>\n",
       "</tr>\n",
       "<tr>\n",
       "  <th>48</th>    <td>   -0.0713</td> <td>    0.052</td> <td>   -1.380</td> <td> 0.168</td> <td>   -0.173</td> <td>    0.030</td>\n",
       "</tr>\n",
       "<tr>\n",
       "  <th>49</th>    <td>   -0.0951</td> <td>    0.048</td> <td>   -1.992</td> <td> 0.047</td> <td>   -0.189</td> <td>   -0.001</td>\n",
       "</tr>\n",
       "<tr>\n",
       "  <th>50</th>    <td>    0.0393</td> <td>    0.050</td> <td>    0.784</td> <td> 0.433</td> <td>   -0.059</td> <td>    0.138</td>\n",
       "</tr>\n",
       "<tr>\n",
       "  <th>51</th>    <td>   -0.0626</td> <td>    0.049</td> <td>   -1.286</td> <td> 0.199</td> <td>   -0.158</td> <td>    0.033</td>\n",
       "</tr>\n",
       "<tr>\n",
       "  <th>52</th>    <td>   -0.0665</td> <td>    0.052</td> <td>   -1.288</td> <td> 0.198</td> <td>   -0.168</td> <td>    0.035</td>\n",
       "</tr>\n",
       "<tr>\n",
       "  <th>53</th>    <td>   -0.0397</td> <td>    0.049</td> <td>   -0.807</td> <td> 0.420</td> <td>   -0.136</td> <td>    0.057</td>\n",
       "</tr>\n",
       "<tr>\n",
       "  <th>54</th>    <td>    0.0031</td> <td>    0.049</td> <td>    0.063</td> <td> 0.950</td> <td>   -0.094</td> <td>    0.100</td>\n",
       "</tr>\n",
       "<tr>\n",
       "  <th>55</th>    <td>    0.0047</td> <td>    0.048</td> <td>    0.098</td> <td> 0.922</td> <td>   -0.089</td> <td>    0.099</td>\n",
       "</tr>\n",
       "<tr>\n",
       "  <th>56</th>    <td>    0.0057</td> <td>    0.051</td> <td>    0.113</td> <td> 0.910</td> <td>   -0.095</td> <td>    0.106</td>\n",
       "</tr>\n",
       "<tr>\n",
       "  <th>57</th>    <td>    0.0248</td> <td>    0.052</td> <td>    0.476</td> <td> 0.635</td> <td>   -0.078</td> <td>    0.127</td>\n",
       "</tr>\n",
       "<tr>\n",
       "  <th>58</th>    <td>    0.0219</td> <td>    0.049</td> <td>    0.444</td> <td> 0.657</td> <td>   -0.075</td> <td>    0.119</td>\n",
       "</tr>\n",
       "<tr>\n",
       "  <th>59</th>    <td>    0.0166</td> <td>    0.048</td> <td>    0.349</td> <td> 0.727</td> <td>   -0.077</td> <td>    0.110</td>\n",
       "</tr>\n",
       "<tr>\n",
       "  <th>60</th>    <td>   -0.0761</td> <td>    0.048</td> <td>   -1.578</td> <td> 0.115</td> <td>   -0.171</td> <td>    0.019</td>\n",
       "</tr>\n",
       "<tr>\n",
       "  <th>61</th>    <td>    0.0030</td> <td>    0.054</td> <td>    0.055</td> <td> 0.956</td> <td>   -0.104</td> <td>    0.110</td>\n",
       "</tr>\n",
       "<tr>\n",
       "  <th>62</th>    <td>    0.0955</td> <td>    0.050</td> <td>    1.930</td> <td> 0.054</td> <td>   -0.002</td> <td>    0.193</td>\n",
       "</tr>\n",
       "<tr>\n",
       "  <th>63</th>    <td>   -0.0329</td> <td>    0.051</td> <td>   -0.651</td> <td> 0.516</td> <td>   -0.132</td> <td>    0.066</td>\n",
       "</tr>\n",
       "<tr>\n",
       "  <th>64</th>    <td>    0.1056</td> <td>    0.055</td> <td>    1.936</td> <td> 0.054</td> <td>   -0.002</td> <td>    0.213</td>\n",
       "</tr>\n",
       "<tr>\n",
       "  <th>65</th>    <td>   -0.0157</td> <td>    0.049</td> <td>   -0.324</td> <td> 0.746</td> <td>   -0.111</td> <td>    0.080</td>\n",
       "</tr>\n",
       "<tr>\n",
       "  <th>66</th>    <td>   -0.0492</td> <td>    0.050</td> <td>   -0.990</td> <td> 0.323</td> <td>   -0.147</td> <td>    0.048</td>\n",
       "</tr>\n",
       "<tr>\n",
       "  <th>67</th>    <td>    0.0028</td> <td>    0.050</td> <td>    0.057</td> <td> 0.954</td> <td>   -0.095</td> <td>    0.101</td>\n",
       "</tr>\n",
       "<tr>\n",
       "  <th>68</th>    <td>    0.0525</td> <td>    0.051</td> <td>    1.036</td> <td> 0.301</td> <td>   -0.047</td> <td>    0.152</td>\n",
       "</tr>\n",
       "<tr>\n",
       "  <th>69</th>    <td>   -0.0526</td> <td>    0.048</td> <td>   -1.088</td> <td> 0.277</td> <td>   -0.148</td> <td>    0.042</td>\n",
       "</tr>\n",
       "<tr>\n",
       "  <th>70</th>    <td>   -0.0584</td> <td>    0.049</td> <td>   -1.182</td> <td> 0.238</td> <td>   -0.156</td> <td>    0.039</td>\n",
       "</tr>\n",
       "<tr>\n",
       "  <th>71</th>    <td>   -0.0172</td> <td>    0.052</td> <td>   -0.332</td> <td> 0.740</td> <td>   -0.119</td> <td>    0.085</td>\n",
       "</tr>\n",
       "<tr>\n",
       "  <th>72</th>    <td>    0.0205</td> <td>    0.052</td> <td>    0.397</td> <td> 0.692</td> <td>   -0.081</td> <td>    0.122</td>\n",
       "</tr>\n",
       "<tr>\n",
       "  <th>73</th>    <td>   -0.0294</td> <td>    0.051</td> <td>   -0.571</td> <td> 0.568</td> <td>   -0.131</td> <td>    0.072</td>\n",
       "</tr>\n",
       "<tr>\n",
       "  <th>74</th>    <td>   -0.0838</td> <td>    0.051</td> <td>   -1.648</td> <td> 0.100</td> <td>   -0.184</td> <td>    0.016</td>\n",
       "</tr>\n",
       "<tr>\n",
       "  <th>75</th>    <td>    0.0532</td> <td>    0.050</td> <td>    1.066</td> <td> 0.287</td> <td>   -0.045</td> <td>    0.151</td>\n",
       "</tr>\n",
       "<tr>\n",
       "  <th>76</th>    <td>    0.0125</td> <td>    0.047</td> <td>    0.267</td> <td> 0.790</td> <td>   -0.080</td> <td>    0.105</td>\n",
       "</tr>\n",
       "<tr>\n",
       "  <th>77</th>    <td>    0.0372</td> <td>    0.049</td> <td>    0.764</td> <td> 0.445</td> <td>   -0.059</td> <td>    0.133</td>\n",
       "</tr>\n",
       "<tr>\n",
       "  <th>78</th>    <td>   -0.0922</td> <td>    0.051</td> <td>   -1.812</td> <td> 0.071</td> <td>   -0.192</td> <td>    0.008</td>\n",
       "</tr>\n",
       "<tr>\n",
       "  <th>79</th>    <td>    0.0016</td> <td>    0.053</td> <td>    0.030</td> <td> 0.976</td> <td>   -0.103</td> <td>    0.106</td>\n",
       "</tr>\n",
       "<tr>\n",
       "  <th>80</th>    <td>   -0.1000</td> <td>    0.050</td> <td>   -1.995</td> <td> 0.047</td> <td>   -0.198</td> <td>   -0.001</td>\n",
       "</tr>\n",
       "<tr>\n",
       "  <th>81</th>    <td>   -0.0145</td> <td>    0.050</td> <td>   -0.287</td> <td> 0.774</td> <td>   -0.114</td> <td>    0.085</td>\n",
       "</tr>\n",
       "<tr>\n",
       "  <th>82</th>    <td>   -0.0201</td> <td>    0.050</td> <td>   -0.401</td> <td> 0.689</td> <td>   -0.118</td> <td>    0.078</td>\n",
       "</tr>\n",
       "<tr>\n",
       "  <th>83</th>    <td>   -0.0164</td> <td>    0.055</td> <td>   -0.296</td> <td> 0.767</td> <td>   -0.126</td> <td>    0.093</td>\n",
       "</tr>\n",
       "<tr>\n",
       "  <th>84</th>    <td>   -0.0251</td> <td>    0.050</td> <td>   -0.499</td> <td> 0.618</td> <td>   -0.124</td> <td>    0.074</td>\n",
       "</tr>\n",
       "<tr>\n",
       "  <th>85</th>    <td>   -0.0130</td> <td>    0.049</td> <td>   -0.264</td> <td> 0.792</td> <td>   -0.110</td> <td>    0.084</td>\n",
       "</tr>\n",
       "<tr>\n",
       "  <th>86</th>    <td>    0.0059</td> <td>    0.047</td> <td>    0.126</td> <td> 0.900</td> <td>   -0.086</td> <td>    0.097</td>\n",
       "</tr>\n",
       "<tr>\n",
       "  <th>87</th>    <td>   -0.0365</td> <td>    0.049</td> <td>   -0.753</td> <td> 0.452</td> <td>   -0.132</td> <td>    0.059</td>\n",
       "</tr>\n",
       "<tr>\n",
       "  <th>88</th>    <td>   -0.0076</td> <td>    0.049</td> <td>   -0.154</td> <td> 0.878</td> <td>   -0.104</td> <td>    0.089</td>\n",
       "</tr>\n",
       "<tr>\n",
       "  <th>89</th>    <td>    0.0028</td> <td>    0.051</td> <td>    0.056</td> <td> 0.956</td> <td>   -0.097</td> <td>    0.102</td>\n",
       "</tr>\n",
       "<tr>\n",
       "  <th>90</th>    <td>   -0.0260</td> <td>    0.050</td> <td>   -0.518</td> <td> 0.605</td> <td>   -0.125</td> <td>    0.073</td>\n",
       "</tr>\n",
       "<tr>\n",
       "  <th>91</th>    <td>    0.0547</td> <td>    0.046</td> <td>    1.179</td> <td> 0.239</td> <td>   -0.037</td> <td>    0.146</td>\n",
       "</tr>\n",
       "<tr>\n",
       "  <th>92</th>    <td>    0.0147</td> <td>    0.048</td> <td>    0.307</td> <td> 0.759</td> <td>   -0.079</td> <td>    0.109</td>\n",
       "</tr>\n",
       "<tr>\n",
       "  <th>93</th>    <td>   -0.0173</td> <td>    0.046</td> <td>   -0.377</td> <td> 0.707</td> <td>   -0.108</td> <td>    0.073</td>\n",
       "</tr>\n",
       "<tr>\n",
       "  <th>94</th>    <td>    0.0283</td> <td>    0.049</td> <td>    0.575</td> <td> 0.566</td> <td>   -0.068</td> <td>    0.125</td>\n",
       "</tr>\n",
       "<tr>\n",
       "  <th>95</th>    <td>    0.0313</td> <td>    0.050</td> <td>    0.623</td> <td> 0.534</td> <td>   -0.068</td> <td>    0.130</td>\n",
       "</tr>\n",
       "<tr>\n",
       "  <th>96</th>    <td>   -0.0007</td> <td>    0.051</td> <td>   -0.013</td> <td> 0.990</td> <td>   -0.102</td> <td>    0.100</td>\n",
       "</tr>\n",
       "<tr>\n",
       "  <th>97</th>    <td>    0.1500</td> <td>    0.049</td> <td>    3.074</td> <td> 0.002</td> <td>    0.054</td> <td>    0.246</td>\n",
       "</tr>\n",
       "<tr>\n",
       "  <th>98</th>    <td>    0.0229</td> <td>    0.048</td> <td>    0.474</td> <td> 0.636</td> <td>   -0.072</td> <td>    0.118</td>\n",
       "</tr>\n",
       "<tr>\n",
       "  <th>99</th>    <td>   -0.0039</td> <td>    0.049</td> <td>   -0.079</td> <td> 0.937</td> <td>   -0.101</td> <td>    0.093</td>\n",
       "</tr>\n",
       "<tr>\n",
       "  <th>100</th>   <td>    0.0387</td> <td>    0.051</td> <td>    0.754</td> <td> 0.451</td> <td>   -0.062</td> <td>    0.140</td>\n",
       "</tr>\n",
       "</table>\n",
       "<table class=\"simpletable\">\n",
       "<tr>\n",
       "  <th>Omnibus:</th>       <td> 0.358</td> <th>  Durbin-Watson:     </th> <td>   2.070</td>\n",
       "</tr>\n",
       "<tr>\n",
       "  <th>Prob(Omnibus):</th> <td> 0.836</td> <th>  Jarque-Bera (JB):  </th> <td>   0.203</td>\n",
       "</tr>\n",
       "<tr>\n",
       "  <th>Skew:</th>          <td>-0.001</td> <th>  Prob(JB):          </th> <td>   0.903</td>\n",
       "</tr>\n",
       "<tr>\n",
       "  <th>Kurtosis:</th>      <td> 3.099</td> <th>  Cond. No.          </th> <td>    2.60</td>\n",
       "</tr>\n",
       "</table><br/><br/>Notes:<br/>[1] Standard Errors assume that the covariance matrix of the errors is correctly specified."
      ],
      "text/plain": [
       "<class 'statsmodels.iolib.summary.Summary'>\n",
       "\"\"\"\n",
       "                            OLS Regression Results                            \n",
       "==============================================================================\n",
       "Dep. Variable:                      y   R-squared:                       0.180\n",
       "Model:                            OLS   Adj. R-squared:                 -0.026\n",
       "Method:                 Least Squares   F-statistic:                    0.8730\n",
       "Date:                Sun, 20 Jun 2021   Prob (F-statistic):              0.792\n",
       "Time:                        22:53:45   Log-Likelihood:                -649.85\n",
       "No. Observations:                 500   AIC:                             1502.\n",
       "Df Residuals:                     399   BIC:                             1927.\n",
       "Df Model:                         100                                         \n",
       "Covariance Type:            nonrobust                                         \n",
       "==============================================================================\n",
       "                 coef    std err          t      P>|t|      [0.025      0.975]\n",
       "------------------------------------------------------------------------------\n",
       "const         -0.0053      0.049     -0.110      0.913      -0.101       0.090\n",
       "1              0.0226      0.054      0.420      0.675      -0.083       0.128\n",
       "2              0.0008      0.048      0.018      0.986      -0.093       0.095\n",
       "3              0.0611      0.048      1.263      0.207      -0.034       0.156\n",
       "4              0.0172      0.050      0.343      0.732      -0.081       0.116\n",
       "5             -0.0186      0.049     -0.380      0.704      -0.115       0.078\n",
       "6             -0.0174      0.048     -0.364      0.716      -0.112       0.077\n",
       "7             -0.0489      0.046     -1.074      0.284      -0.138       0.041\n",
       "8             -0.0497      0.050     -0.991      0.322      -0.148       0.049\n",
       "9             -0.0065      0.049     -0.133      0.894      -0.102       0.089\n",
       "10             0.0476      0.049      0.980      0.328      -0.048       0.143\n",
       "11            -0.0082      0.050     -0.162      0.871      -0.107       0.091\n",
       "12             0.0370      0.052      0.713      0.476      -0.065       0.139\n",
       "13            -0.0612      0.050     -1.233      0.218      -0.159       0.036\n",
       "14             0.0273      0.055      0.494      0.622      -0.081       0.136\n",
       "15            -0.0089      0.053     -0.168      0.866      -0.113       0.095\n",
       "16             0.0348      0.049      0.703      0.482      -0.062       0.132\n",
       "17            -0.0183      0.048     -0.377      0.707      -0.114       0.077\n",
       "18             0.0499      0.052      0.966      0.334      -0.052       0.151\n",
       "19             0.0216      0.048      0.450      0.653      -0.073       0.116\n",
       "20            -0.0554      0.048     -1.153      0.249      -0.150       0.039\n",
       "21            -0.0703      0.052     -1.348      0.178      -0.173       0.032\n",
       "22             0.0278      0.051      0.544      0.587      -0.073       0.128\n",
       "23             0.0092      0.053      0.174      0.862      -0.095       0.113\n",
       "24             0.0110      0.051      0.218      0.827      -0.088       0.110\n",
       "25             0.0580      0.047      1.245      0.214      -0.034       0.150\n",
       "26             0.0261      0.051      0.516      0.606      -0.073       0.125\n",
       "27             0.0273      0.048      0.568      0.571      -0.067       0.122\n",
       "28             0.0630      0.049      1.281      0.201      -0.034       0.160\n",
       "29            -0.0355      0.051     -0.701      0.484      -0.135       0.064\n",
       "30             0.0398      0.053      0.758      0.449      -0.063       0.143\n",
       "31             0.0523      0.046      1.130      0.259      -0.039       0.143\n",
       "32            -0.0949      0.049     -1.945      0.053      -0.191       0.001\n",
       "33             0.0254      0.050      0.506      0.613      -0.073       0.124\n",
       "34            -0.0257      0.047     -0.542      0.588      -0.119       0.068\n",
       "35            -0.0144      0.049     -0.294      0.769      -0.111       0.082\n",
       "36             0.0258      0.053      0.482      0.630      -0.079       0.131\n",
       "37            -0.0292      0.049     -0.592      0.554      -0.126       0.068\n",
       "38            -0.0771      0.051     -1.517      0.130      -0.177       0.023\n",
       "39             0.0237      0.048      0.493      0.622      -0.071       0.118\n",
       "40            -0.0731      0.051     -1.421      0.156      -0.174       0.028\n",
       "41            -0.0230      0.049     -0.469      0.639      -0.119       0.073\n",
       "42             0.0028      0.052      0.055      0.956      -0.099       0.104\n",
       "43            -0.0453      0.051     -0.880      0.379      -0.146       0.056\n",
       "44             0.0302      0.052      0.587      0.558      -0.071       0.132\n",
       "45             0.0440      0.049      0.906      0.365      -0.051       0.139\n",
       "46            -0.0487      0.050     -0.973      0.331      -0.147       0.050\n",
       "47             0.0686      0.050      1.374      0.170      -0.030       0.167\n",
       "48            -0.0713      0.052     -1.380      0.168      -0.173       0.030\n",
       "49            -0.0951      0.048     -1.992      0.047      -0.189      -0.001\n",
       "50             0.0393      0.050      0.784      0.433      -0.059       0.138\n",
       "51            -0.0626      0.049     -1.286      0.199      -0.158       0.033\n",
       "52            -0.0665      0.052     -1.288      0.198      -0.168       0.035\n",
       "53            -0.0397      0.049     -0.807      0.420      -0.136       0.057\n",
       "54             0.0031      0.049      0.063      0.950      -0.094       0.100\n",
       "55             0.0047      0.048      0.098      0.922      -0.089       0.099\n",
       "56             0.0057      0.051      0.113      0.910      -0.095       0.106\n",
       "57             0.0248      0.052      0.476      0.635      -0.078       0.127\n",
       "58             0.0219      0.049      0.444      0.657      -0.075       0.119\n",
       "59             0.0166      0.048      0.349      0.727      -0.077       0.110\n",
       "60            -0.0761      0.048     -1.578      0.115      -0.171       0.019\n",
       "61             0.0030      0.054      0.055      0.956      -0.104       0.110\n",
       "62             0.0955      0.050      1.930      0.054      -0.002       0.193\n",
       "63            -0.0329      0.051     -0.651      0.516      -0.132       0.066\n",
       "64             0.1056      0.055      1.936      0.054      -0.002       0.213\n",
       "65            -0.0157      0.049     -0.324      0.746      -0.111       0.080\n",
       "66            -0.0492      0.050     -0.990      0.323      -0.147       0.048\n",
       "67             0.0028      0.050      0.057      0.954      -0.095       0.101\n",
       "68             0.0525      0.051      1.036      0.301      -0.047       0.152\n",
       "69            -0.0526      0.048     -1.088      0.277      -0.148       0.042\n",
       "70            -0.0584      0.049     -1.182      0.238      -0.156       0.039\n",
       "71            -0.0172      0.052     -0.332      0.740      -0.119       0.085\n",
       "72             0.0205      0.052      0.397      0.692      -0.081       0.122\n",
       "73            -0.0294      0.051     -0.571      0.568      -0.131       0.072\n",
       "74            -0.0838      0.051     -1.648      0.100      -0.184       0.016\n",
       "75             0.0532      0.050      1.066      0.287      -0.045       0.151\n",
       "76             0.0125      0.047      0.267      0.790      -0.080       0.105\n",
       "77             0.0372      0.049      0.764      0.445      -0.059       0.133\n",
       "78            -0.0922      0.051     -1.812      0.071      -0.192       0.008\n",
       "79             0.0016      0.053      0.030      0.976      -0.103       0.106\n",
       "80            -0.1000      0.050     -1.995      0.047      -0.198      -0.001\n",
       "81            -0.0145      0.050     -0.287      0.774      -0.114       0.085\n",
       "82            -0.0201      0.050     -0.401      0.689      -0.118       0.078\n",
       "83            -0.0164      0.055     -0.296      0.767      -0.126       0.093\n",
       "84            -0.0251      0.050     -0.499      0.618      -0.124       0.074\n",
       "85            -0.0130      0.049     -0.264      0.792      -0.110       0.084\n",
       "86             0.0059      0.047      0.126      0.900      -0.086       0.097\n",
       "87            -0.0365      0.049     -0.753      0.452      -0.132       0.059\n",
       "88            -0.0076      0.049     -0.154      0.878      -0.104       0.089\n",
       "89             0.0028      0.051      0.056      0.956      -0.097       0.102\n",
       "90            -0.0260      0.050     -0.518      0.605      -0.125       0.073\n",
       "91             0.0547      0.046      1.179      0.239      -0.037       0.146\n",
       "92             0.0147      0.048      0.307      0.759      -0.079       0.109\n",
       "93            -0.0173      0.046     -0.377      0.707      -0.108       0.073\n",
       "94             0.0283      0.049      0.575      0.566      -0.068       0.125\n",
       "95             0.0313      0.050      0.623      0.534      -0.068       0.130\n",
       "96            -0.0007      0.051     -0.013      0.990      -0.102       0.100\n",
       "97             0.1500      0.049      3.074      0.002       0.054       0.246\n",
       "98             0.0229      0.048      0.474      0.636      -0.072       0.118\n",
       "99            -0.0039      0.049     -0.079      0.937      -0.101       0.093\n",
       "100            0.0387      0.051      0.754      0.451      -0.062       0.140\n",
       "==============================================================================\n",
       "Omnibus:                        0.358   Durbin-Watson:                   2.070\n",
       "Prob(Omnibus):                  0.836   Jarque-Bera (JB):                0.203\n",
       "Skew:                          -0.001   Prob(JB):                        0.903\n",
       "Kurtosis:                       3.099   Cond. No.                         2.60\n",
       "==============================================================================\n",
       "\n",
       "Notes:\n",
       "[1] Standard Errors assume that the covariance matrix of the errors is correctly specified.\n",
       "\"\"\""
      ]
     },
     "execution_count": 297,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "variable  = {}\n",
    "for i in range(101):\n",
    "    variable[i] = np.random.normal(size = 500)\n",
    "y = variable[0]\n",
    "y = np.array(y)\n",
    "del variable[0]\n",
    "variable = pd.DataFrame(variable)\n",
    "variable\n",
    "x = sm.add_constant(variable)\n",
    "result = sm.OLS(y,x).fit()\n",
    "result.summary()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 301,
   "id": "77dbe75f-28e1-4040-bcd8-e8099ff9bb57",
   "metadata": {},
   "outputs": [],
   "source": [
    "#(b)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 309,
   "id": "d18e370f-0251-4fe4-bd6d-19f374203554",
   "metadata": {},
   "outputs": [],
   "source": [
    "#code comes from https://stackoverflow.com/questions/41045752/using-statsmodel-estimations-with-scikit-learn-cross-validation-is-it-possible\n",
    "# I need it to help me do cross validation\n",
    "import statsmodels.api as sm\n",
    "from sklearn.base import BaseEstimator, RegressorMixin\n",
    "\n",
    "class SMWrapper(BaseEstimator, RegressorMixin):\n",
    "    \"\"\" A universal sklearn-style wrapper for statsmodels regressors \"\"\"\n",
    "    def __init__(self, model_class, fit_intercept=True):\n",
    "        self.model_class = model_class\n",
    "        self.fit_intercept = fit_intercept\n",
    "    def fit(self, X, y):\n",
    "        if self.fit_intercept:\n",
    "            X = sm.add_constant(X)\n",
    "        self.model_ = self.model_class(y, X)\n",
    "        self.results_ = self.model_.fit()\n",
    "    def predict(self, X):\n",
    "        if self.fit_intercept:\n",
    "            X = sm.add_constant(X)\n",
    "        return self.results_.predict(X)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 311,
   "id": "6a148ad6-189f-4836-876d-185ea1ba3a55",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[-0.016123   -0.00997023 -0.02867774 -0.05519776 -0.03422912]\n"
     ]
    }
   ],
   "source": [
    "from sklearn.datasets import make_regression\n",
    "from sklearn.model_selection import cross_val_score\n",
    "from sklearn.linear_model import LinearRegression\n",
    "print(cross_val_score(LinearRegression(), df1, y, scoring='r2'))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 314,
   "id": "efad6ad4-5ec5-4993-be1d-1d2fd662a854",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[ 0.03820332 -0.01780628 -0.10186873 -0.00859121  0.03980746]\n"
     ]
    }
   ],
   "source": [
    "#（c/d）\n",
    "print(cross_val_score(LinearRegression(), pd.DataFrame(xx), y, scoring='r2'))"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "d2bc8581-178a-4070-8344-592acb53906f",
   "metadata": {},
   "source": [
    "Stepwise regression method is better than choose 3 largest t values model."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "b7a7cd9d-2ee7-40b4-a449-bde2183e9a83",
   "metadata": {},
   "source": [
    "(f)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 322,
   "id": "b39e399a-df3f-43a5-ba2d-6b69897c8d67",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[-0.01052976 -0.00646448 -0.02216755 -0.02854327 -0.00872976]\n",
      "[-0.01780578  0.00573239 -0.01005248 -0.03226904 -0.00429196]\n"
     ]
    }
   ],
   "source": [
    "variable  = {}\n",
    "for i in range(101):\n",
    "    variable[i] = np.random.normal(size = 500)\n",
    "y = variable[0]\n",
    "y = np.array(y)\n",
    "del variable[0]\n",
    "variable = pd.DataFrame(variable)\n",
    "variable\n",
    "x = sm.add_constant(variable)\n",
    "result = sm.OLS(y,x).fit()\n",
    "result.summary()\n",
    "result.pvalues<0.05\n",
    "result.pvalues[result.pvalues<0.05]\n",
    "tvalue = np.abs(result.tvalues)\n",
    "df_t = pd.DataFrame(tvalue)\n",
    "df_t.nlargest(3,0)\n",
    "x1 = variable[85]\n",
    "x2 = variable[26]\n",
    "x3 = variable[11]\n",
    "df1 = pd.DataFrame(list(zip(x1, x2, x3)))\n",
    "df1\n",
    "x1 = sm.add_constant(df1)\n",
    "result1 = sm.OLS(y,x1).fit()\n",
    "result1.summary()\n",
    "result1.pvalues\n",
    "result1.pvalues<0.05\n",
    "xx = {}\n",
    "for i in range(100):\n",
    "    j = i+1 \n",
    "    xx[j] = variable[j]\n",
    "    xxpd = pd.DataFrame(xx)\n",
    "    x2 = sm.add_constant(xxpd)\n",
    "    result2 = sm.OLS(y,x2).fit()\n",
    "    if result2.fvalue<9.2:\n",
    "        xx.pop(j)\n",
    "result2.summary()\n",
    "model = result2\n",
    "model.tvalues\n",
    "list(result.tvalues)[16]\n",
    "list(result.tvalues)[75]\n",
    "list(result.tvalues)[100]\n",
    "variable  = {}\n",
    "for i in range(101):\n",
    "    variable[i] = np.random.normal(size = 500)\n",
    "y = variable[0]\n",
    "y = np.array(y)\n",
    "del variable[0]\n",
    "variable = pd.DataFrame(variable)\n",
    "variable\n",
    "x = sm.add_constant(variable)\n",
    "result = sm.OLS(y,x).fit()\n",
    "result.summary()\n",
    "#code comes from https://stackoverflow.com/questions/41045752/using-statsmodel-estimations-with-scikit-learn-cross-validation-is-it-possible\n",
    "# I need it to help me do cross validation\n",
    "import statsmodels.api as sm\n",
    "from sklearn.base import BaseEstimator, RegressorMixin\n",
    "\n",
    "class SMWrapper(BaseEstimator, RegressorMixin):\n",
    "    \"\"\" A universal sklearn-style wrapper for statsmodels regressors \"\"\"\n",
    "    def __init__(self, model_class, fit_intercept=True):\n",
    "        self.model_class = model_class\n",
    "        self.fit_intercept = fit_intercept\n",
    "    def fit(self, X, y):\n",
    "        if self.fit_intercept:\n",
    "            X = sm.add_constant(X)\n",
    "        self.model_ = self.model_class(y, X)\n",
    "        self.results_ = self.model_.fit()\n",
    "    def predict(self, X):\n",
    "        if self.fit_intercept:\n",
    "            X = sm.add_constant(X)\n",
    "        return self.results_.predict(X)\n",
    "from sklearn.datasets import make_regression\n",
    "from sklearn.model_selection import cross_val_score\n",
    "from sklearn.linear_model import LinearRegression\n",
    "print(cross_val_score(LinearRegression(), df1, y, scoring='r2'))\n",
    "#（c/d）\n",
    "print(cross_val_score(LinearRegression(), pd.DataFrame(xx), y, scoring='r2'))"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.11"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
